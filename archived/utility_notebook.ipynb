{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548da984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Notebook cell: count atoms from a .inp file\n",
    "\n",
    "from collections import Counter\n",
    "from typing import Iterable, Tuple, Dict, List, Union\n",
    "import pandas as pd\n",
    "\n",
    "# Periodic table: index == atomic number\n",
    "_PT = [\n",
    "    None,\n",
    "    \"H\",\"He\",\"Li\",\"Be\",\"B\",\"C\",\"N\",\"O\",\"F\",\"Ne\",\n",
    "    \"Na\",\"Mg\",\"Al\",\"Si\",\"P\",\"S\",\"Cl\",\"Ar\",\n",
    "    \"K\",\"Ca\",\"Sc\",\"Ti\",\"V\",\"Cr\",\"Mn\",\"Fe\",\"Co\",\"Ni\",\"Cu\",\"Zn\",\n",
    "    \"Ga\",\"Ge\",\"As\",\"Se\",\"Br\",\"Kr\",\n",
    "    \"Rb\",\"Sr\",\"Y\",\"Zr\",\"Nb\",\"Mo\",\"Tc\",\"Ru\",\"Rh\",\"Pd\",\"Ag\",\"Cd\",\n",
    "    \"In\",\"Sn\",\"Sb\",\"Te\",\"I\",\"Xe\",\n",
    "    \"Cs\",\"Ba\",\"La\",\"Ce\",\"Pr\",\"Nd\",\"Pm\",\"Sm\",\"Eu\",\"Gd\",\"Tb\",\"Dy\",\"Ho\",\"Er\",\"Tm\",\"Yb\",\"Lu\",\n",
    "    \"Hf\",\"Ta\",\"W\",\"Re\",\"Os\",\"Ir\",\"Pt\",\"Au\",\"Hg\",\n",
    "    \"Tl\",\"Pb\",\"Bi\",\"Po\",\"At\",\"Rn\",\n",
    "    \"Fr\",\"Ra\",\"Ac\",\"Th\",\"Pa\",\"U\",\"Np\",\"Pu\",\"Am\",\"Cm\",\"Bk\",\"Cf\",\"Es\",\"Fm\",\"Md\",\"No\",\"Lr\",\n",
    "    \"Rf\",\"Db\",\"Sg\",\"Bh\",\"Hs\",\"Mt\",\"Ds\",\"Rg\",\"Cn\",\"Nh\",\"Fl\",\"Mc\",\"Lv\",\"Ts\",\"Og\"\n",
    "]\n",
    "\n",
    "def _z_to_symbol(z: int) -> str:\n",
    "    return _PT[z] if 0 < z < len(_PT) else f\"Z{z}\"\n",
    "\n",
    "def _parse_species(token: str) -> str:\n",
    "    \"\"\"Normalize species token to a symbol; accepts atomic number or symbol.\"\"\"\n",
    "    t = token.strip()\n",
    "    try:\n",
    "        return _z_to_symbol(int(t))\n",
    "    except ValueError:\n",
    "        return t\n",
    "\n",
    "def _is_comment_or_blank(line: str, comment_chars: str = \"#;!\") -> bool:\n",
    "    s = line.strip()\n",
    "    return (not s) or any(s.startswith(c) for c in comment_chars)\n",
    "\n",
    "def count_atoms_from_lines(\n",
    "    lines: Iterable[str],\n",
    "    species_col: int = 0,\n",
    "    comment_chars: str = \"#;!\"\n",
    ") -> Tuple[int, Counter]:\n",
    "    \"\"\"\n",
    "    Count total atoms and per-species counts from an iterable of lines.\n",
    "    - species_col: 0-based index of the column containing species (default: first column)\n",
    "    - comment_chars: lines starting with any of these are ignored\n",
    "    \"\"\"\n",
    "    counts = Counter()\n",
    "    total = 0\n",
    "    for line in lines:\n",
    "        if _is_comment_or_blank(line, comment_chars):\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        if not parts or len(parts) <= species_col:\n",
    "            continue\n",
    "        sp = _parse_species(parts[species_col])\n",
    "        counts[sp] += 1\n",
    "        total += 1\n",
    "    return total, counts\n",
    "\n",
    "def count_atoms_from_file(\n",
    "    path: str,\n",
    "    species_col: int = 0,\n",
    "    comment_chars: str = \"#;!\"\n",
    ") -> Tuple[int, Counter]:\n",
    "    \"\"\"Convenience wrapper to read from a file path.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return count_atoms_from_lines(f, species_col=species_col, comment_chars=comment_chars)\n",
    "\n",
    "def counts_to_dataframe(counts: Counter) -> pd.DataFrame:\n",
    "    \"\"\"Convert counts to a sorted DataFrame.\"\"\"\n",
    "    items = sorted(counts.items(), key=lambda kv: (-kv[1], kv[0]))\n",
    "    df = pd.DataFrame(items, columns=[\"Species\", \"Count\"])\n",
    "    df[\"Fraction\"] = df[\"Count\"] / df[\"Count\"].sum()\n",
    "    return df\n",
    "\n",
    "def summarize_counts(\n",
    "    counts: Counter,\n",
    "    title: str = \"Per-species counts\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a DataFrame with Species, Count, Fraction, total atoms and a 'Cumulative' column.\n",
    "    \"\"\"\n",
    "    df = counts_to_dataframe(counts)\n",
    "    df[\"Cumulative\"] = df[\"Fraction\"].cumsum()\n",
    "    df.attrs[\"title\"] = title\n",
    "    df.attrs[\"total_atoms\"] = df[\"Count\"].sum()\n",
    "    return df\n",
    "    # to return total as well, use: return df, df[\"Count\"].sum()\n",
    "    # here is the code for that\n",
    "# --------------------------\n",
    "# Example usage (uncomment and set your file path):\n",
    "# path = \"your_file.inp\"\n",
    "# total, counts = count_atoms_from_file(path, species_col=0)  # change species_col if needed\n",
    "# print(f\"Total atoms: {total}\")\n",
    "# display(summarize_counts(counts))\n",
    "# --------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4c1333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Formula unit from a .inp file (extension of the count code)\n",
    "\n",
    "from collections import Counter\n",
    "from typing import Iterable, Tuple, Dict, List, Union, Optional\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Periodic Table + parser (same as before) ----------\n",
    "_PT = [\n",
    "    None,\n",
    "    \"H\",\"He\",\"Li\",\"Be\",\"B\",\"C\",\"N\",\"O\",\"F\",\"Ne\",\n",
    "    \"Na\",\"Mg\",\"Al\",\"Si\",\"P\",\"S\",\"Cl\",\"Ar\",\n",
    "    \"K\",\"Ca\",\"Sc\",\"Ti\",\"V\",\"Cr\",\"Mn\",\"Fe\",\"Co\",\"Ni\",\"Cu\",\"Zn\",\n",
    "    \"Ga\",\"Ge\",\"As\",\"Se\",\"Br\",\"Kr\",\n",
    "    \"Rb\",\"Sr\",\"Y\",\"Zr\",\"Nb\",\"Mo\",\"Tc\",\"Ru\",\"Rh\",\"Pd\",\"Ag\",\"Cd\",\n",
    "    \"In\",\"Sn\",\"Sb\",\"Te\",\"I\",\"Xe\",\n",
    "    \"Cs\",\"Ba\",\"La\",\"Ce\",\"Pr\",\"Nd\",\"Pm\",\"Sm\",\"Eu\",\"Gd\",\"Tb\",\"Dy\",\"Ho\",\"Er\",\"Tm\",\"Yb\",\"Lu\",\n",
    "    \"Hf\",\"Ta\",\"W\",\"Re\",\"Os\",\"Ir\",\"Pt\",\"Au\",\"Hg\",\n",
    "    \"Tl\",\"Pb\",\"Bi\",\"Po\",\"At\",\"Rn\",\n",
    "    \"Fr\",\"Ra\",\"Ac\",\"Th\",\"Pa\",\"U\",\"Np\",\"Pu\",\"Am\",\"Cm\",\"Bk\",\"Cf\",\"Es\",\"Fm\",\"Md\",\"No\",\"Lr\",\n",
    "    \"Rf\",\"Db\",\"Sg\",\"Bh\",\"Hs\",\"Mt\",\"Ds\",\"Rg\",\"Cn\",\"Nh\",\"Fl\",\"Mc\",\"Lv\",\"Ts\",\"Og\"\n",
    "]\n",
    "\n",
    "def _z_to_symbol(z: int) -> str:\n",
    "    return _PT[z] if 0 < z < len(_PT) else f\"Z{z}\"\n",
    "\n",
    "def _parse_species(token: str) -> str:\n",
    "    t = token.strip()\n",
    "    try:\n",
    "        return _z_to_symbol(int(t))\n",
    "    except ValueError:\n",
    "        return t\n",
    "\n",
    "def _is_comment_or_blank(line: str, comment_chars: str = \"#;!\") -> bool:\n",
    "    s = line.strip()\n",
    "    return (not s) or any(s.startswith(c) for c in comment_chars)\n",
    "\n",
    "# ---------- Counting helpers (as before) ----------\n",
    "def count_atoms_from_lines(\n",
    "    lines: Iterable[str],\n",
    "    species_col: int = 0,\n",
    "    comment_chars: str = \"#;!\"\n",
    ") -> Tuple[int, Counter]:\n",
    "    counts = Counter()\n",
    "    total = 0\n",
    "    for line in lines:\n",
    "        if _is_comment_or_blank(line, comment_chars):\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        if not parts or len(parts) <= species_col:\n",
    "            continue\n",
    "        sp = _parse_species(parts[species_col])\n",
    "        counts[sp] += 1\n",
    "        total += 1\n",
    "    return total, counts\n",
    "\n",
    "def count_atoms_from_file(\n",
    "    path: str,\n",
    "    species_col: int = 0,\n",
    "    comment_chars: str = \"#;!\"\n",
    ") -> Tuple[int, Counter]:\n",
    "    with open(path, \"r\") as f:\n",
    "        return count_atoms_from_lines(f, species_col=species_col, comment_chars=comment_chars)\n",
    "\n",
    "def counts_to_dataframe(counts: Counter) -> pd.DataFrame:\n",
    "    items = sorted(counts.items(), key=lambda kv: (-kv[1], kv[0]))\n",
    "    df = pd.DataFrame(items, columns=[\"Species\", \"Count\"])\n",
    "    df[\"Fraction\"] = df[\"Count\"] / df[\"Count\"].sum()\n",
    "    return df\n",
    "\n",
    "def summarize_counts(counts: Counter, title: str = \"Per-species counts\") -> pd.DataFrame:\n",
    "    df = counts_to_dataframe(counts)\n",
    "    df[\"Cumulative\"] = df[\"Fraction\"].cumsum()\n",
    "    df.attrs[\"title\"] = title\n",
    "    return df\n",
    "\n",
    "# ---------- NEW: formula unit computation ----------\n",
    "def _gcd_list(ints: List[int]) -> int:\n",
    "    g = 0\n",
    "    for x in ints:\n",
    "        g = math.gcd(g, int(x))\n",
    "    return max(g, 1)\n",
    "\n",
    "def _order_species(species: List[str], hill: bool = True, custom_order: Optional[List[str]] = None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Ordering for pretty formula strings:\n",
    "      - If custom_order given, use that order first; remaining species follow after alphabetically.\n",
    "      - Else if hill=True: C, H first (if present), then others alphabetical.\n",
    "      - Else alphabetical.\n",
    "    \"\"\"\n",
    "    sp_set = set(species)\n",
    "    if custom_order:\n",
    "        used = [s for s in custom_order if s in sp_set]\n",
    "        rest = sorted([s for s in species if s not in used])\n",
    "        return used + rest\n",
    "    if hill:\n",
    "        head = [s for s in [\"C\", \"H\"] if s in sp_set]\n",
    "        tail = sorted([s for s in species if s not in {\"C\",\"H\"}])\n",
    "        return head + tail\n",
    "    return sorted(species)\n",
    "\n",
    "def empirical_formula_from_counts(\n",
    "    counts: Counter,\n",
    "    hill: bool = True,\n",
    "    custom_order: Optional[List[str]] = None\n",
    ") -> Tuple[Dict[str, int], str]:\n",
    "    \"\"\"\n",
    "    Reduce per-species counts to the smallest integer ratio (empirical formula unit).\n",
    "    Returns (dict_of_counts, pretty_string).\n",
    "    \"\"\"\n",
    "    if not counts:\n",
    "        return {}, \"\"\n",
    "\n",
    "    # Reduce by GCD\n",
    "    nums = [int(counts[s]) for s in counts]\n",
    "    g = _gcd_list(nums)\n",
    "    fu = {s: counts[s] // g for s in counts}\n",
    "\n",
    "    # Pretty string\n",
    "    order = _order_species(list(fu.keys()), hill=hill, custom_order=custom_order)\n",
    "    def _fmt(spec, n): return f\"{spec}{'' if n==1 else int(n)}\"\n",
    "    formula_str = \"\".join(_fmt(s, fu[s]) for s in order)\n",
    "\n",
    "    return fu, formula_str\n",
    "\n",
    "def number_of_formula_units(total_counts: Counter, fu_counts: Dict[str, int]) -> float:\n",
    "    \"\"\"\n",
    "    Compute how many formula units are present in the supercell.\n",
    "    Returns a float; if the supercell is an exact multiple of the formula unit,\n",
    "    this will be an integer (within numerical tolerance).\n",
    "    \"\"\"\n",
    "    # Use only species present in the formula unit (fu_counts should include all species)\n",
    "    ratios = []\n",
    "    for s, n_fu in fu_counts.items():\n",
    "        if n_fu == 0:\n",
    "            continue\n",
    "        ratios.append(total_counts[s] / n_fu)\n",
    "    if not ratios:\n",
    "        return 0.0\n",
    "    # Check consistency (all ratios equal)\n",
    "    r0 = ratios[0]\n",
    "    if any(abs(r - r0) > 1e-8 for r in ratios[1:]):\n",
    "        # Not an exact multiple; still return average to indicate scale\n",
    "        return sum(ratios) / len(ratios)\n",
    "    return r0\n",
    "\n",
    "def formula_unit_report(\n",
    "    counts: Counter,\n",
    "    hill: bool = True,\n",
    "    custom_order: Optional[List[str]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a compact report with total counts, empirical formula counts, and per-FU normalization.\n",
    "    \"\"\"\n",
    "    fu_counts, formula_str = empirical_formula_from_counts(counts, hill=hill, custom_order=custom_order)\n",
    "    n_fu = number_of_formula_units(counts, fu_counts) if fu_counts else 0.0\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Species\": list(counts.keys()),\n",
    "        \"TotalCount\": [int(counts[s]) for s in counts],\n",
    "        \"PerFU\": [fu_counts.get(s, 0) for s in counts],\n",
    "    })\n",
    "    df[\"Fraction\"] = df[\"TotalCount\"] / df[\"TotalCount\"].sum()\n",
    "    df.attrs[\"formula_str\"] = formula_str\n",
    "    df.attrs[\"n_formula_units\"] = n_fu\n",
    "    return df\n",
    "\n",
    "# --------------------------\n",
    "# Example usage (uncomment and set your file path):\n",
    "# path = \"your_file.inp\"\n",
    "# total, counts = count_atoms_from_file(path, species_col=1)  # e.g., second column holds Z\n",
    "# print(f\"Total atoms: {total}\")\n",
    "# display(summarize_counts(counts))\n",
    "# rep = formula_unit_report(counts, hill=False, custom_order=[\"Li\",\"La\",\"Zr\",\"O\"])  # nice order for LLZO\n",
    "# print(\"Empirical formula:\", rep.attrs[\"formula_str\"])\n",
    "# print(\"Number of formula units in supercell:\", rep.attrs[\"n_formula_units\"])\n",
    "# display(rep.sort_values(\"Species\"))\n",
    "# --------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26cc4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/e3nn/o3/_wigner.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n",
      "Error while loading libcue_ops.so: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "usage: mace_run_train [-h] [--config CONFIG] --name NAME [--seed SEED]\n",
      "                      [--work_dir WORK_DIR] [--log_dir LOG_DIR]\n",
      "                      [--model_dir MODEL_DIR]\n",
      "                      [--checkpoints_dir CHECKPOINTS_DIR]\n",
      "                      [--results_dir RESULTS_DIR]\n",
      "                      [--downloads_dir DOWNLOADS_DIR]\n",
      "                      [--device {cpu,cuda,mps,xpu}]\n",
      "                      [--default_dtype {float32,float64}] [--distributed]\n",
      "                      [--launcher {slurm,torchrun,mpi,none}]\n",
      "                      [--log_level LOG_LEVEL] [--plot PLOT]\n",
      "                      [--plot_frequency PLOT_FREQUENCY]\n",
      "                      [--error_table {PerAtomRMSE,TotalRMSE,PerAtomRMSEstressvirials,PerAtomMAEstressvirials,PerAtomMAE,TotalMAE,DipoleRMSE,DipoleMAE,EnergyDipoleRMSE}]\n",
      "                      [--model {BOTNet,MACE,ScaleShiftMACE,ScaleShiftBOTNet,AtomicDipolesMACE,EnergyDipolesMACE}]\n",
      "                      [--r_max R_MAX]\n",
      "                      [--radial_type {bessel,gaussian,chebyshev}]\n",
      "                      [--num_radial_basis NUM_RADIAL_BASIS]\n",
      "                      [--num_cutoff_basis NUM_CUTOFF_BASIS] [--pair_repulsion]\n",
      "                      [--distance_transform {None,Agnesi,Soft}]\n",
      "                      [--apply_cutoff APPLY_CUTOFF]\n",
      "                      [--interaction {RealAgnosticResidualInteractionBlock,RealAgnosticAttResidualInteractionBlock,RealAgnosticInteractionBlock,RealAgnosticDensityInteractionBlock,RealAgnosticDensityResidualInteractionBlock,RealAgnosticResidualNonLinearInteractionBlock}]\n",
      "                      [--interaction_first {RealAgnosticResidualInteractionBlock,RealAgnosticInteractionBlock,RealAgnosticDensityInteractionBlock,RealAgnosticDensityResidualInteractionBlock,RealAgnosticResidualNonLinearInteractionBlock}]\n",
      "                      [--max_ell MAX_ELL] [--correlation CORRELATION]\n",
      "                      [--use_reduced_cg USE_REDUCED_CG] [--use_so3 USE_SO3]\n",
      "                      [--use_agnostic_product USE_AGNOSTIC_PRODUCT]\n",
      "                      [--num_interactions NUM_INTERACTIONS]\n",
      "                      [--MLP_irreps MLP_IRREPS] [--radial_MLP RADIAL_MLP]\n",
      "                      [--hidden_irreps HIDDEN_IRREPS]\n",
      "                      [--edge_irreps EDGE_IRREPS]\n",
      "                      [--num_channels NUM_CHANNELS] [--max_L MAX_L]\n",
      "                      [--gate {silu,tanh,abs,None}]\n",
      "                      [--scaling {std_scaling,rms_forces_scaling,no_scaling}]\n",
      "                      [--avg_num_neighbors AVG_NUM_NEIGHBORS]\n",
      "                      [--compute_avg_num_neighbors COMPUTE_AVG_NUM_NEIGHBORS]\n",
      "                      [--compute_stress COMPUTE_STRESS]\n",
      "                      [--compute_forces COMPUTE_FORCES]\n",
      "                      [--train_file TRAIN_FILE] [--valid_file VALID_FILE]\n",
      "                      [--valid_fraction VALID_FRACTION]\n",
      "                      [--test_file TEST_FILE] [--test_dir TEST_DIR]\n",
      "                      [--multi_processed_test MULTI_PROCESSED_TEST]\n",
      "                      [--num_workers NUM_WORKERS] [--pin_memory PIN_MEMORY]\n",
      "                      [--atomic_numbers ATOMIC_NUMBERS] [--mean MEAN]\n",
      "                      [--std STD] [--statistics_file STATISTICS_FILE]\n",
      "                      [--E0s E0S]\n",
      "                      [--foundation_filter_elements FOUNDATION_FILTER_ELEMENTS]\n",
      "                      [--heads HEADS]\n",
      "                      [--multiheads_finetuning MULTIHEADS_FINETUNING]\n",
      "                      [--foundation_head FOUNDATION_HEAD]\n",
      "                      [--weight_pt_head WEIGHT_PT_HEAD]\n",
      "                      [--num_samples_pt NUM_SAMPLES_PT]\n",
      "                      [--force_mh_ft_lr FORCE_MH_FT_LR]\n",
      "                      [--subselect_pt {fps,random}]\n",
      "                      [--filter_type_pt {none,combinations,inclusive,exclusive}]\n",
      "                      [--pt_train_file PT_TRAIN_FILE]\n",
      "                      [--pt_valid_file PT_VALID_FILE]\n",
      "                      [--foundation_model_elements FOUNDATION_MODEL_ELEMENTS]\n",
      "                      [--keep_isolated_atoms KEEP_ISOLATED_ATOMS]\n",
      "                      [--energy_key ENERGY_KEY] [--forces_key FORCES_KEY]\n",
      "                      [--virials_key VIRIALS_KEY] [--stress_key STRESS_KEY]\n",
      "                      [--dipole_key DIPOLE_KEY] [--head_key HEAD_KEY]\n",
      "                      [--charges_key CHARGES_KEY]\n",
      "                      [--elec_temp_key ELEC_TEMP_KEY]\n",
      "                      [--total_spin_key TOTAL_SPIN_KEY]\n",
      "                      [--total_charge_key TOTAL_CHARGE_KEY]\n",
      "                      [--embedding_specs EMBEDDING_SPECS]\n",
      "                      [--skip_evaluate_heads SKIP_EVALUATE_HEADS]\n",
      "                      [--loss {ef,weighted,forces_only,virials,stress,dipole,huber,universal,energy_forces_dipole,l1l2energyforces}]\n",
      "                      [--forces_weight FORCES_WEIGHT]\n",
      "                      [--swa_forces_weight SWA_FORCES_WEIGHT]\n",
      "                      [--energy_weight ENERGY_WEIGHT]\n",
      "                      [--swa_energy_weight SWA_ENERGY_WEIGHT]\n",
      "                      [--virials_weight VIRIALS_WEIGHT]\n",
      "                      [--swa_virials_weight SWA_VIRIALS_WEIGHT]\n",
      "                      [--stress_weight STRESS_WEIGHT]\n",
      "                      [--swa_stress_weight SWA_STRESS_WEIGHT]\n",
      "                      [--dipole_weight DIPOLE_WEIGHT]\n",
      "                      [--swa_dipole_weight SWA_DIPOLE_WEIGHT]\n",
      "                      [--config_type_weights CONFIG_TYPE_WEIGHTS]\n",
      "                      [--huber_delta HUBER_DELTA]\n",
      "                      [--optimizer {adam,adamw,schedulefree}] [--beta BETA]\n",
      "                      [--batch_size BATCH_SIZE]\n",
      "                      [--valid_batch_size VALID_BATCH_SIZE] [--lr LR]\n",
      "                      [--swa_lr SWA_LR] [--weight_decay WEIGHT_DECAY]\n",
      "                      [--amsgrad] [--scheduler SCHEDULER]\n",
      "                      [--lr_factor LR_FACTOR]\n",
      "                      [--scheduler_patience SCHEDULER_PATIENCE]\n",
      "                      [--lr_scheduler_gamma LR_SCHEDULER_GAMMA] [--swa]\n",
      "                      [--start_swa START_SWA] [--lbfgs] [--ema]\n",
      "                      [--ema_decay EMA_DECAY]\n",
      "                      [--max_num_epochs MAX_NUM_EPOCHS] [--patience PATIENCE]\n",
      "                      [--foundation_model FOUNDATION_MODEL]\n",
      "                      [--foundation_model_readout]\n",
      "                      [--eval_interval EVAL_INTERVAL] [--keep_checkpoints]\n",
      "                      [--save_all_checkpoints] [--restart_latest] [--save_cpu]\n",
      "                      [--clip_grad CLIP_GRAD] [--dry_run]\n",
      "                      [--enable_cueq ENABLE_CUEQ] [--only_cueq ONLY_CUEQ]\n",
      "                      [--wandb] [--wandb_dir WANDB_DIR]\n",
      "                      [--wandb_project WANDB_PROJECT]\n",
      "                      [--wandb_entity WANDB_ENTITY] [--wandb_name WANDB_NAME]\n",
      "                      [--wandb_log_hypers WANDB_LOG_HYPERS [WANDB_LOG_HYPERS ...]]\n",
      "mace_run_train: error: unrecognized arguments: -1.882, 8: -4.913, 40: -8.509, 57: -4.894}},pt_head: {train_file: /home/phanim/harshitrawat/summer/dummy.extxyz, E0s: {3: -1.882, 8: -4.913, 40: -8.509, 57: -4.894}}\n"
     ]
    }
   ],
   "source": [
    "# %% Script to make a template model from given hyperparameters and save it\n",
    "# Write E0s JSON\n",
    "\n",
    "!mace_run_train \\\n",
    "  --name mace_T1_w1_template \\\n",
    "  --model MACE \\\n",
    "  --num_interactions 2 \\\n",
    "  --foundation_model /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model \\\n",
    "  --foundation_model_readout \\\n",
    "  --multiheads_finetuning True \\\n",
    "  --heads \"{\"target_head\": {\"train_file\": \"/home/phanim/harshitrawat/summer/dummy.extxyz\", \"E0s\": \"{\"3\": -1.882, \"8\": -4.913, \"40\": -8.509, \"57\": -4.894}\"},\"pt_head\": {\"train_file\": \"/home/phanim/harshitrawat/summer/dummy.extxyz\", \"E0s\": \"{\"3\": -1.882, \"8\": -4.913, \"40\": -8.509, \"57\": -4.894}\"}\" \\\n",
    "  --atomic_numbers \"[3,8,40,57]\" \\\n",
    "  --valid_file /home/phanim/harshitrawat/summer/dummy.extxyz \\\n",
    "  --batch_size 2 \\\n",
    "  --valid_batch_size 1 \\\n",
    "  --device cpu \\\n",
    "  --forces_weight 10 \\\n",
    "  --energy_weight 50 \\\n",
    "  --stress_weight 0 \\\n",
    "  --lr 0.0002 \\\n",
    "  --scheduler_patience 4 \\\n",
    "  --clip_grad 1 \\\n",
    "  --weight_decay 1e-8 \\\n",
    "  --r_max 5.0 \\\n",
    "  --max_num_epochs 1 \\\n",
    "  --seed 10 \\\n",
    "  --patience 8 \\\n",
    "  --restart_latest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c20052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: utils ============================================================\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from pymatgen.core import Lattice, Structure, Element\n",
    "from pymatgen.io.cif import CifWriter\n",
    "\n",
    "BOHR_TO_ANG = 0.529177210903  # Å per Bohr (CODATA 2018)\n",
    "\n",
    "def read_lattice_bohr(path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Read a 3×3 lattice (rows = a, b, c) from domainVectors.inp in Bohr,\n",
    "    return a 3×3 array in Å.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    rows = []\n",
    "    with path.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) != 3:\n",
    "                raise ValueError(f\"{path.name}: expected 3 numbers/line, got {len(parts)} → {line}\")\n",
    "            rows.append([float(x) for x in parts])\n",
    "    if len(rows) != 3:\n",
    "        raise ValueError(f\"{path.name}: expected exactly 3 lines, got {len(rows)}.\")\n",
    "\n",
    "    lattice_bohr = np.array(rows, dtype=float)\n",
    "    lattice_ang = lattice_bohr * BOHR_TO_ANG\n",
    "    return lattice_ang\n",
    "\n",
    "\n",
    "def read_fractional_coords_with_Z(path):\n",
    "    \"\"\"\n",
    "    Read coordinates.inp lines of:  Z  tag  fx  fy  fz\n",
    "    - Z   : atomic number (int)\n",
    "    - tag : ignored (e.g., species index/pseudopotential id)\n",
    "    - fx,fy,fz : fractional coordinates in [0,1) (we keep values as-is)\n",
    "\n",
    "    Returns:\n",
    "      species : list[str]  (element symbols)\n",
    "      frac    : list[list[float]] (fractional coords)\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    species, frac = [], []\n",
    "    with path.open(\"r\") as f:\n",
    "        for i, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) < 5:\n",
    "                raise ValueError(f\"{path.name} line {i}: need ≥5 columns, got {len(parts)} → {line}\")\n",
    "            try:\n",
    "                Z = int(parts[0])\n",
    "                fx, fy, fz = map(float, parts[-3:])\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"{path.name} line {i}: parse error → {e}\\n  line: {line}\")\n",
    "            elem = Element.from_Z(Z).symbol\n",
    "            species.append(elem)\n",
    "            frac.append([fx, fy, fz])\n",
    "\n",
    "    if not species:\n",
    "        raise ValueError(f\"{path.name}: found 0 atoms.\")\n",
    "    return species, frac\n",
    "\n",
    "\n",
    "def build_structure_from_inp(lattice_inp, coords_inp, coords_are_cartesian=False) -> Structure:\n",
    "    \"\"\"\n",
    "    Construct a pymatgen Structure from domainVectors.inp and coordinates.inp.\n",
    "    \"\"\"\n",
    "    lat_ang = read_lattice_bohr(lattice_inp)\n",
    "    species, coords = read_fractional_coords_with_Z(coords_inp)\n",
    "    lattice = Lattice(lat_ang)  # rows are a,b,c\n",
    "\n",
    "    struct = Structure(\n",
    "        lattice=lattice,\n",
    "        species=species,\n",
    "        coords=coords,\n",
    "        coords_are_cartesian=coords_are_cartesian,  # default False since your coords look fractional\n",
    "        to_unit_cell=True,\n",
    "        validate_proximity=False,\n",
    "    )\n",
    "    return struct\n",
    "\n",
    "\n",
    "def write_cif(struct: Structure, out_path):\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    CifWriter(struct, symprec=None).write_file(str(out_path))\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "252e1ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /home/phanim/harshitrawat/summer/llzo_sanity_check_srinibas/Li_Srinibas.cif\n",
      "Formula: Li16\n",
      "a,b,c (Å): 6.987679, 6.987679, 6.987679\n",
      "α,β,γ (°): 90.000000, 90.000000, 90.000000\n",
      "Atoms: 16\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: run conversion ====================================================\n",
    "# Set your paths (relative or absolute)\n",
    "lattice_inp = \"/home/phanim/harshitrawat/summer/llzo_data_srinibas/Li_222/R2SCAN/domainVectors.inp\"     # 3×3 in Bohr\n",
    "coords_inp  = \"/home/phanim/harshitrawat/summer/llzo_data_srinibas/Li_222/R2SCAN/coordinates.inp\"       # Z tag fx fy fz (fractional)\n",
    "out_cif     = \"/home/phanim/harshitrawat/summer/llzo_sanity_check_srinibas/Li_Srinibas.cif\"\n",
    "\n",
    "# If your coordinates were Cartesian (rare for this format), flip to True.\n",
    "coords_are_cartesian = False\n",
    "\n",
    "# Build and write\n",
    "struct = build_structure_from_inp(lattice_inp, coords_inp, coords_are_cartesian=coords_are_cartesian)\n",
    "out = write_cif(struct, out_cif)\n",
    "\n",
    "# Quick summary\n",
    "a, b, c = struct.lattice.abc\n",
    "alpha, beta, gamma = struct.lattice.angles\n",
    "print(f\"Wrote: {out}\")\n",
    "print(f\"Formula: {struct.composition.formula}\")\n",
    "print(f\"a,b,c (Å): {a:.6f}, {b:.6f}, {c:.6f}\")\n",
    "print(f\"α,β,γ (°): {alpha:.6f}, {beta:.6f}, {gamma:.6f}\")\n",
    "print(f\"Atoms: {len(struct)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebd8520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /home/phanim/harshitrawat/summer/llzo_sanity_check_srinibas/La_Srinibas.cif\n",
      "Formula: La32\n",
      "a,b,c (Å): 7.635224, 7.635224, 24.467712\n",
      "α,β,γ (°): 90.000000, 90.000000, 120.001290\n",
      "Atoms: 32\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: run conversion ====================================================\n",
    "# Set your paths (relative or absolute)\n",
    "lattice_inp = \"/home/phanim/harshitrawat/summer/llzo_data_srinibas/La_222/R2SCAN/domainVectors.inp\"     # 3×3 in Bohr\n",
    "coords_inp  = \"/home/phanim/harshitrawat/summer/llzo_data_srinibas/La_222/R2SCAN/coordinates.inp\"       # Z tag fx fy fz (fractional)\n",
    "out_cif     = \"/home/phanim/harshitrawat/summer/llzo_sanity_check_srinibas/La_Srinibas.cif\"\n",
    "\n",
    "# If your coordinates were Cartesian (rare for this format), flip to True.\n",
    "coords_are_cartesian = False\n",
    "\n",
    "# Build and write\n",
    "struct = build_structure_from_inp(lattice_inp, coords_inp, coords_are_cartesian=coords_are_cartesian)\n",
    "out = write_cif(struct, out_cif)\n",
    "\n",
    "# Quick summary\n",
    "a, b, c = struct.lattice.abc\n",
    "alpha, beta, gamma = struct.lattice.angles\n",
    "print(f\"Wrote: {out}\")\n",
    "print(f\"Formula: {struct.composition.formula}\")\n",
    "print(f\"a,b,c (Å): {a:.6f}, {b:.6f}, {c:.6f}\")\n",
    "print(f\"α,β,γ (°): {alpha:.6f}, {beta:.6f}, {gamma:.6f}\")\n",
    "print(f\"Atoms: {len(struct)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "074a630b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /home/phanim/harshitrawat/summer/llzo_sanity_check_srinibas/Zr_Srinibas.cif\n",
      "Formula: Zr16\n",
      "a,b,c (Å): 6.494704, 6.495736, 10.305029\n",
      "α,β,γ (°): 90.000000, 90.000000, 119.994744\n",
      "Atoms: 16\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: run conversion ====================================================\n",
    "# Set your paths (relative or absolute)\n",
    "lattice_inp = \"/home/phanim/harshitrawat/summer/llzo_data_srinibas/Zr_222/R2SCAN/domainVectors.inp\"     # 3×3 in Bohr\n",
    "coords_inp  = \"/home/phanim/harshitrawat/summer/llzo_data_srinibas/Zr_222/R2SCAN/coordinates.inp\"       # Z tag fx fy fz (fractional)\n",
    "out_cif     = \"/home/phanim/harshitrawat/summer/llzo_sanity_check_srinibas/Zr_Srinibas.cif\"\n",
    "\n",
    "# If your coordinates were Cartesian (rare for this format), flip to True.\n",
    "coords_are_cartesian = False\n",
    "\n",
    "# Build and write\n",
    "struct = build_structure_from_inp(lattice_inp, coords_inp, coords_are_cartesian=coords_are_cartesian)\n",
    "out = write_cif(struct, out_cif)\n",
    "\n",
    "# Quick summary\n",
    "a, b, c = struct.lattice.abc\n",
    "alpha, beta, gamma = struct.lattice.angles\n",
    "print(f\"Wrote: {out}\")\n",
    "print(f\"Formula: {struct.composition.formula}\")\n",
    "print(f\"a,b,c (Å): {a:.6f}, {b:.6f}, {c:.6f}\")\n",
    "print(f\"α,β,γ (°): {alpha:.6f}, {beta:.6f}, {gamma:.6f}\")\n",
    "print(f\"Atoms: {len(struct)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286b1ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /home/phanim/harshitrawat/summer/llzo_sanity_check_srinibas/O2_Srinibas.cif\n",
      "Formula: O2\n",
      "a,b,c (Å): 26.458861, 26.458861, 26.458861\n",
      "α,β,γ (°): 90.000000, 90.000000, 90.000000\n",
      "Atoms: 2\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: run conversion ====================================================\n",
    "# Set your paths (relative or absolute)\n",
    "lattice_inp = \"/home/phanim/harshitrawat/summer/llzo_data_srinibas/O2/R2SCAN/domainVectors.inp\"     # 3×3 in Bohr\n",
    "coords_inp  = \"/home/phanim/harshitrawat/summer/llzo_data_srinibas/O2/R2SCAN/coordinates.inp\"       # Z tag fx fy fz (fractional)\n",
    "out_cif     = \"/home/phanim/harshitrawat/summer/llzo_sanity_check_srinibas/O2_Srinibas.cif\"\n",
    "\n",
    "# If your coordinates were Cartesian (rare for this format), flip to True.\n",
    "coords_are_cartesian = False\n",
    "\n",
    "# Build and write\n",
    "struct = build_structure_from_inp(lattice_inp, coords_inp, coords_are_cartesian=coords_are_cartesian)\n",
    "out = write_cif(struct, out_cif)\n",
    "\n",
    "# Quick summary\n",
    "a, b, c = struct.lattice.abc\n",
    "alpha, beta, gamma = struct.lattice.angles\n",
    "print(f\"Wrote: {out}\")\n",
    "print(f\"Formula: {struct.composition.formula}\")\n",
    "print(f\"a,b,c (Å): {a:.6f}, {b:.6f}, {c:.6f}\")\n",
    "print(f\"α,β,γ (°): {alpha:.6f}, {beta:.6f}, {gamma:.6f}\")\n",
    "print(f\"Atoms: {len(struct)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a3cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /home/phanim/harshitrawat/summer/llzo_sanity_check_srinibas/LLZO_Srinibas.cif\n",
      "Formula: Li56 La24 Zr16 O96\n",
      "a,b,c (Å): 13.133798, 13.133815, 12.596967\n",
      "α,β,γ (°): 90.000070, 90.000005, 90.000005\n",
      "Atoms: 192\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: run conversion ====================================================\n",
    "# Set your paths (relative or absolute)\n",
    "lattice_inp = \"/home/phanim/harshitrawat/summer/llzo_data_srinibas/LLZO/R2SCAN/domainVectors.inp\"     # 3×3 in Bohr\n",
    "coords_inp  = \"/home/phanim/harshitrawat/summer/llzo_data_srinibas/LLZO/R2SCAN/coordinates.inp\"       # Z tag fx fy fz (fractional)\n",
    "out_cif     = \"/home/phanim/harshitrawat/summer/llzo_sanity_check_srinibas/LLZO_Srinibas.cif\"\n",
    "\n",
    "# If your coordinates were Cartesian (rare for this format), flip to True.\n",
    "coords_are_cartesian = False\n",
    "\n",
    "# Build and write\n",
    "struct = build_structure_from_inp(lattice_inp, coords_inp, coords_are_cartesian=coords_are_cartesian)\n",
    "out = write_cif(struct, out_cif)\n",
    "\n",
    "# Quick summary\n",
    "a, b, c = struct.lattice.abc\n",
    "alpha, beta, gamma = struct.lattice.angles\n",
    "print(f\"Wrote: {out}\")\n",
    "print(f\"Formula: {struct.composition.formula}\")\n",
    "print(f\"a,b,c (Å): {a:.6f}, {b:.6f}, {c:.6f}\")\n",
    "print(f\"α,β,γ (°): {alpha:.6f}, {beta:.6f}, {gamma:.6f}\")\n",
    "print(f\"Atoms: {len(struct)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fc88a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from checkpoint: checkpoints/checkpoint_1_data_loaded.pkl\n",
      "Loaded 8654 structures.\n",
      "Feature Matrix Shape: (8654, 256)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# Paths\n",
    "DATA_DIR = \"universal_embeddings_results\"\n",
    "FILES = {\n",
    "    \"T1\": os.path.join(DATA_DIR, \"Universal_on_T1.xyz\"),\n",
    "    \"T2\": os.path.join(DATA_DIR, \"Universal_on_T2.xyz\"),\n",
    "    \"T3\": os.path.join(DATA_DIR, \"Universal_on_T3.xyz\")\n",
    "}\n",
    "\n",
    "# Checkpoint Configuration\n",
    "LOAD_FROM_CHECKPOINT = True\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "CP_DATA_LOADED = os.path.join(CHECKPOINT_DIR, \"checkpoint_1_data_loaded.pkl\")\n",
    "CP_OOD_RESULTS = os.path.join(CHECKPOINT_DIR, \"checkpoint_2_ood_results.pkl\")\n",
    "\n",
    "import pandas as pd\n",
    "if LOAD_FROM_CHECKPOINT and os.path.exists(CP_DATA_LOADED):\n",
    "    print(f\"Loading data from checkpoint: {CP_DATA_LOADED}\")\n",
    "    df = pd.read_pickle(CP_DATA_LOADED)\n",
    "    df.head()\n",
    "    # Re-create X if needed\n",
    "    X = np.stack(df['latent'].values)\n",
    "    print(f\"Loaded {len(df)} structures.\")\n",
    "    print(f\"Feature Matrix Shape: {X.shape}\")\n",
    "else:\n",
    "    def parse_filename(filename):\n",
    "        # Regex based on user convention:\n",
    "        # cellrelaxed_LLZO_{cleavingdir}_{termination}_{order}_{sto|offsto}__Li_{facet}_slab_heavy_T{Temp}_{Index}.cif\n",
    "        # Also handling strain: ..._strain{+/-}{val}_perturbed.cif\n",
    "        \n",
    "        meta = {}\n",
    "        meta['filename'] = filename\n",
    "        \n",
    "        # Strain\n",
    "        strain_match = re.search(r\"strain([+-]?[\\d\\.]+)_perturbed\", filename)\n",
    "        if strain_match:\n",
    "            meta['strain'] = float(strain_match.group(1))\n",
    "            meta['is_perturbed'] = True\n",
    "        else:\n",
    "            meta['strain'] = 0.0\n",
    "            meta['is_perturbed'] = False\n",
    "    \n",
    "        # Temperature\n",
    "        temp_match = re.search(r\"_T(\\d+)_\", filename)\n",
    "        if temp_match:\n",
    "            meta['temp'] = int(temp_match.group(1))\n",
    "        else:\n",
    "            meta['temp'] = None\n",
    "    \n",
    "        # Facet (e.g., Li_100_slab)\n",
    "        facet_match = re.search(r\"Li_(\\d+)_slab\", filename)\n",
    "        if facet_match:\n",
    "            meta['facet'] = facet_match.group(1)\n",
    "        else:\n",
    "            meta['facet'] = \"Unknown\"\n",
    "    \n",
    "        # Termination (e.g., LLZO_010_La_order0)\n",
    "        # This is tricky, let's try to capture the block between LLZO_ and __Li\n",
    "        term_match = re.search(r\"LLZO_(.*?)__Li\", filename)\n",
    "        if term_match:\n",
    "            parts = term_match.group(1).split('_')\n",
    "            # Heuristic: usually {cleaving}_{termination}_{order}_{sto}\n",
    "            if len(parts) >= 2:\n",
    "                meta['termination'] = parts[1] # e.g. La\n",
    "            else:\n",
    "                meta['termination'] = \"Unknown\"\n",
    "        else:\n",
    "            meta['termination'] = \"Unknown\"\n",
    "            \n",
    "        return meta\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for dataset_name, filepath in FILES.items():\n",
    "        print(f\"Loading {dataset_name} from {filepath}...\")\n",
    "        atoms_list = ase.io.read(filepath, index=\":\")\n",
    "        \n",
    "        for atoms in atoms_list:\n",
    "            info = atoms.info\n",
    "            arrays = atoms.arrays\n",
    "            \n",
    "            # Extract Latent (256D)\n",
    "            # Note: 'mace_latent' is per-atom. We need a global descriptor.\n",
    "            # Strategy: MEAN of atomic latents.\n",
    "            if 'mace_latent' in arrays:\n",
    "                latent = np.mean(arrays['mace_latent'], axis=0) # Shape (256,)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            # Extract Energy\n",
    "            energy = info.get('mace_energy', np.nan)\n",
    "            \n",
    "            # Parse Filename (stored in info or we assume order?)\n",
    "            # MACE usually preserves info. Let's assume 'filename' or 'comment' holds it.\n",
    "            # If not, we might need to rely on index if filenames weren't saved.\n",
    "            # CHECK: The user's extraction script likely saved filenames in info if they were in the input.\n",
    "            # If input was .extxyz, it might have 'config_type' or similar.\n",
    "            # Let's assume there is a way to identify. For now, we use a placeholder if missing.\n",
    "            fname = info.get('filename', info.get('comment', f\"unknown_{dataset_name}\"))\n",
    "            \n",
    "            entry = parse_filename(fname)\n",
    "            entry['dataset'] = dataset_name\n",
    "            entry['energy'] = energy\n",
    "            entry['latent'] = latent\n",
    "            \n",
    "            data_list.append(entry)\n",
    "    \n",
    "    df = pd.DataFrame(data_list)\n",
    "    print(f\"Loaded {len(df)} structures.\")\n",
    "    \n",
    "    # Create Feature Matrix X\n",
    "    X = np.stack(df['latent'].values)\n",
    "    print(f\"Feature Matrix Shape: {X.shape}\")\n",
    "            \n",
    "\n",
    "    # Save Checkpoint\n",
    "    print(f\"Saving data to checkpoint: {CP_DATA_LOADED}\")\n",
    "    df.to_pickle(CP_DATA_LOADED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f652f5bf-acef-4c64-b27d-670316439904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>strain</th>\n",
       "      <th>is_perturbed</th>\n",
       "      <th>temp</th>\n",
       "      <th>facet</th>\n",
       "      <th>termination</th>\n",
       "      <th>dataset</th>\n",
       "      <th>energy</th>\n",
       "      <th>latent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown_T1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>T1</td>\n",
       "      <td>-2985.323995</td>\n",
       "      <td>[-0.022429647077777785, 0.37030010755555526, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown_T1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>T1</td>\n",
       "      <td>-2918.476146</td>\n",
       "      <td>[-0.030376922312206605, 0.32244097245305237, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown_T1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>T1</td>\n",
       "      <td>-2853.348134</td>\n",
       "      <td>[-0.043781398527315905, 0.28577672785035624, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unknown_T1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>T1</td>\n",
       "      <td>-2677.919980</td>\n",
       "      <td>[-0.0532804312654321, 0.24710180930555542, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unknown_T1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>T1</td>\n",
       "      <td>-2382.882676</td>\n",
       "      <td>[-0.047781491575342436, 0.2694620743493152, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  strain  is_perturbed  temp    facet termination dataset  \\\n",
       "0  unknown_T1     0.0         False  None  Unknown     Unknown      T1   \n",
       "1  unknown_T1     0.0         False  None  Unknown     Unknown      T1   \n",
       "2  unknown_T1     0.0         False  None  Unknown     Unknown      T1   \n",
       "3  unknown_T1     0.0         False  None  Unknown     Unknown      T1   \n",
       "4  unknown_T1     0.0         False  None  Unknown     Unknown      T1   \n",
       "\n",
       "        energy                                             latent  \n",
       "0 -2985.323995  [-0.022429647077777785, 0.37030010755555526, 0...  \n",
       "1 -2918.476146  [-0.030376922312206605, 0.32244097245305237, 0...  \n",
       "2 -2853.348134  [-0.043781398527315905, 0.28577672785035624, -...  \n",
       "3 -2677.919980  [-0.0532804312654321, 0.24710180930555542, -0....  \n",
       "4 -2382.882676  [-0.047781491575342436, 0.2694620743493152, -0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd645f5-1e9c-40a2-9fcf-b2b26e6ece30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read\n",
    "\n",
    "atoms = read(\"home/phanim/harshitrawat/summer/universal_embeddings_results/Universal_on_T2.xyz\")\n",
    "type(atoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8a96b-b1b4-4449-a3f7-b7f44dfeaf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e514a-d4c5-47e0-b8d6-d9b0dbf8c528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU mace_0.3.8)",
   "language": "python",
   "name": "mace_0.3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
