{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfba9ea8-b0ea-4cef-aa13-8cea1dc4e55e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    mace_T1_finetune_h200_cn10 \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz \\\n",
      "    --valid_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz \\\n",
      "    --batch_size \\\n",
      "    2 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --valid_fraction \\\n",
      "    0.1 \\\n",
      "    --device \\\n",
      "    cuda \\\n",
      "    --forces_weight \\\n",
      "    30.0 \\\n",
      "    --restart_latest \\\n",
      "    --energy_weight \\\n",
      "    100.0 \\\n",
      "    --max_num_epochs \\\n",
      "    20 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --E0s \\\n",
      "    average \\\n",
      "    --seed \\\n",
      "    21\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 09:23:28.628 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-07-25 09:23:28.628 INFO: MACE version: 0.3.13\n",
      "2025-07-25 09:23:29.406 INFO: CUDA version: 12.6, CUDA device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:157: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 09:23:29.931 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-07-25 09:23:29.933 WARNING: Using multiheads finetuning with a foundation model that is not a Materials Project model, need to provied a path to a pretraining file with --pt_train_file.\n",
      "2025-07-25 09:23:29.933 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-07-25 09:23:29.933 INFO: Using heads: ['Default']\n",
      "2025-07-25 09:23:29.933 INFO: Using the key specifications to parse data:\n",
      "2025-07-25 09:23:29.933 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-07-25 09:23:29.933 INFO: =============    Processing head Default     ===========\n",
      "2025-07-25 09:23:50.901 INFO: Training set 1/1 [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 09:23:50.918 INFO: Total Training set [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 09:23:53.514 INFO: Validation set 1/1 [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 09:23:53.516 INFO: Total Validation set [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 09:23:53.516 INFO: Total number of configurations: train=6337, valid=705, tests=[],\n",
      "2025-07-25 09:23:53.821 INFO: Atomic Numbers used: [3, 8, 40, 57]\n",
      "2025-07-25 09:23:53.821 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-07-25 09:23:53.821 INFO: Computing average Atomic Energies using least squares regression\n",
      "2025-07-25 09:23:53.862 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\n",
      "2025-07-25 09:23:53.862 INFO: Processing datasets for head 'Default'\n",
      "2025-07-25 09:25:17.053 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-07-25 09:25:26.524 INFO: Combining 1 list datasets for head 'Default_valid'\n",
      "2025-07-25 09:25:26.524 INFO: Combined validation datasets for Default\n",
      "2025-07-25 09:25:26.524 INFO: Head 'Default' training dataset size: 6337\n",
      "2025-07-25 09:25:26.524 INFO: Computing average number of neighbors\n",
      "2025-07-25 09:25:34.864 INFO: Average number of neighbors: 68.51643679748439\n",
      "2025-07-25 09:25:34.865 INFO: During training the following quantities will be reported: energy, forces\n",
      "2025-07-25 09:25:34.865 INFO: ===========MODEL DETAILS===========\n",
      "2025-07-25 09:25:41.719 INFO: Loading FOUNDATION model\n",
      "2025-07-25 09:25:41.721 INFO: Using filtered elements: [3, 8, 40, 57]\n",
      "2025-07-25 09:25:41.721 INFO: Model configuration extracted from foundation model\n",
      "2025-07-25 09:25:41.721 INFO: Using universal loss function for fine-tuning\n",
      "2025-07-25 09:25:41.721 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-07-25 09:25:41.721 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-07-25 09:25:41.721 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-07-25 09:25:41.721 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 09:25:43.096 INFO: Total number of parameters: 894362\n",
      "2025-07-25 09:25:43.096 INFO: \n",
      "2025-07-25 09:25:43.096 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-07-25 09:25:43.096 INFO: Using ADAM as parameter optimizer\n",
      "2025-07-25 09:25:43.097 INFO: Batch size: 2\n",
      "2025-07-25 09:25:43.097 INFO: Number of gradient updates: 63370\n",
      "2025-07-25 09:25:43.097 INFO: Learning rate: 0.01, weight decay: 5e-07\n",
      "2025-07-25 09:25:43.097 INFO: WeightedEnergyForcesLoss(energy_weight=100.000, forces_weight=30.000)\n",
      "2025-07-25 09:25:43.100 WARNING: No SWA checkpoint found, while SWA is enabled. Compare the swa_start parameter and the latest checkpoint.\n",
      "2025-07-25 09:25:43.100 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_h200_cn10_run-21_epoch-7.pt\n",
      "2025-07-25 09:25:43.149 INFO: Using gradient clipping with tolerance=10.000\n",
      "2025-07-25 09:25:43.149 INFO: \n",
      "2025-07-25 09:25:43.149 INFO: ===========TRAINING===========\n",
      "2025-07-25 09:25:43.149 INFO: Started training, reporting errors on validation set\n",
      "2025-07-25 09:25:43.149 INFO: Loss metrics on validation set\n",
      "2025-07-25 09:26:58.064 INFO: Initial: head: Default, loss=14.19357672, RMSE_E_per_atom=  373.39 meV, RMSE_F=   95.31 meV / A\n",
      "2025-07-25 09:58:59.874 INFO: Epoch 7: head: Default, loss=79.54230041, RMSE_E_per_atom=  890.59 meV, RMSE_F=   90.53 meV / A\n",
      "2025-07-25 10:30:59.315 INFO: Epoch 8: head: Default, loss=752.82211118, RMSE_E_per_atom= 2743.30 meV, RMSE_F=   94.61 meV / A\n",
      "2025-07-25 11:02:59.117 INFO: Epoch 9: head: Default, loss=79.94503184, RMSE_E_per_atom=  892.69 meV, RMSE_F=   95.82 meV / A\n",
      "2025-07-25 11:34:58.708 INFO: Epoch 10: head: Default, loss=30.89173708, RMSE_E_per_atom=  553.93 meV, RMSE_F=   86.47 meV / A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/bin/mace_run_train\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m75\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mrun\u001b[0m\u001b[1;31m(args)\u001b[0m\n",
      "    \u001b[31m~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m778\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mtools.train\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<23 lines>...\n",
      "        \u001b[1;31mrank=rank,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m222\u001b[0m, in \u001b[35mtrain\u001b[0m\n",
      "    \u001b[31mtrain_one_epoch\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<11 lines>...\n",
      "        \u001b[1;31mrank=rank,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m370\u001b[0m, in \u001b[35mtrain_one_epoch\u001b[0m\n",
      "    _, opt_metrics = \u001b[31mtake_step\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                     \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model_to_train,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<6 lines>...\n",
      "        \u001b[1;31mdevice=device,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m417\u001b[0m, in \u001b[35mtake_step\u001b[0m\n",
      "    \u001b[31moptimizer.step\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m485\u001b[0m, in \u001b[35mwrapper\u001b[0m\n",
      "    out = func(*args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m79\u001b[0m, in \u001b[35m_use_grad\u001b[0m\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/adam.py\"\u001b[0m, line \u001b[35m246\u001b[0m, in \u001b[35mstep\u001b[0m\n",
      "    \u001b[31madam\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mparams_with_grad,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<19 lines>...\n",
      "        \u001b[1;31mdecoupled_weight_decay=group[\"decoupled_weight_decay\"],\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m147\u001b[0m, in \u001b[35mmaybe_fallback\u001b[0m\n",
      "    return func(*args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/adam.py\"\u001b[0m, line \u001b[35m933\u001b[0m, in \u001b[35madam\u001b[0m\n",
      "    \u001b[31mfunc\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mparams,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^\u001b[0m\n",
      "    ...<17 lines>...\n",
      "        \u001b[1;31mdecoupled_weight_decay=decoupled_weight_decay,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/adam.py\"\u001b[0m, line \u001b[35m739\u001b[0m, in \u001b[35m_multi_tensor_adam\u001b[0m\n",
      "    1 - beta1 ** \u001b[31m_get_value\u001b[0m\u001b[1;31m(step)\u001b[0m for step in device_state_steps\n",
      "                 \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m94\u001b[0m, in \u001b[35m_get_value\u001b[0m\n",
      "    return \u001b[31mx.item\u001b[0m\u001b[1;31m()\u001b[0m if isinstance(x, torch.Tensor) else x\n",
      "           \u001b[31m~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_run_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--name\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_T1_finetune_h200_cn10\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--seed\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m21\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m ]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd), file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m---> 34\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    os.environ[\"PYTHONPATH\"] = \"/home/phanim/harshitrawat/mace/mace\"\n",
    "\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        \"--name\",              \"mace_T1_finetune_h200_cn10\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "        \"--train_file\",        \"/home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz\",\n",
    "        \"--valid_file\",        \"/home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz\",\n",
    "        \"--batch_size\",        \"2\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "        \"--valid_fraction\",    \"0.1\",\n",
    "        \"--device\",            \"cuda\",\n",
    "        \"--forces_weight\",     \"30.0\",\n",
    "        \"--restart_latest\",  # ✅ add this\n",
    "        \"--energy_weight\",     \"100.0\",\n",
    "        \"--max_num_epochs\",    \"20\",\n",
    "        \"--r_max\",             \"5.0\",\n",
    "        \"--E0s\",               \"average\",\n",
    "        \"--seed\",              \"21\"\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a650bbbe-cf44-4971-b15f-747945e7ed61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    mace_T1_finetune_h200_cn10 \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz \\\n",
      "    --valid_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz \\\n",
      "    --batch_size \\\n",
      "    2 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --valid_fraction \\\n",
      "    0.1 \\\n",
      "    --device \\\n",
      "    cuda \\\n",
      "    --forces_weight \\\n",
      "    20 \\\n",
      "    --energy_weight \\\n",
      "    100 \\\n",
      "    --lr \\\n",
      "    0.0003 \\\n",
      "    --scheduler_patience \\\n",
      "    3 \\\n",
      "    --clip_grad \\\n",
      "    30 \\\n",
      "    --weight_decay \\\n",
      "    1e-8 \\\n",
      "    --ema_decay \\\n",
      "    0.999 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --max_num_epochs \\\n",
      "    20 \\\n",
      "    --E0s \\\n",
      "    {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549} \\\n",
      "    --seed \\\n",
      "    21 \\\n",
      "    --patience \\\n",
      "    3 \\\n",
      "    --restart_latest\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 14:03:01.233 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-07-25 14:03:01.233 INFO: MACE version: 0.3.13\n",
      "2025-07-25 14:03:01.939 INFO: CUDA version: 12.6, CUDA device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:157: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 14:03:02.375 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-07-25 14:03:02.378 WARNING: Using multiheads finetuning with a foundation model that is not a Materials Project model, need to provied a path to a pretraining file with --pt_train_file.\n",
      "2025-07-25 14:03:02.379 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-07-25 14:03:02.379 INFO: Using heads: ['Default']\n",
      "2025-07-25 14:03:02.379 INFO: Using the key specifications to parse data:\n",
      "2025-07-25 14:03:02.379 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-07-25 14:03:02.379 INFO: =============    Processing head Default     ===========\n",
      "2025-07-25 14:03:23.386 INFO: Training set 1/1 [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 14:03:23.404 INFO: Total Training set [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 14:03:25.979 INFO: Validation set 1/1 [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 14:03:25.981 INFO: Total Validation set [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 14:03:25.981 INFO: Total number of configurations: train=6337, valid=705, tests=[],\n",
      "2025-07-25 14:03:26.284 INFO: Atomic Numbers used: [3, 8, 40, 57]\n",
      "2025-07-25 14:03:26.284 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-07-25 14:03:26.284 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\n",
      "2025-07-25 14:03:26.284 INFO: Processing datasets for head 'Default'\n",
      "2025-07-25 14:04:49.222 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-07-25 14:04:58.643 INFO: Combining 1 list datasets for head 'Default_valid'\n",
      "2025-07-25 14:04:58.644 INFO: Combined validation datasets for Default\n",
      "2025-07-25 14:04:58.644 INFO: Head 'Default' training dataset size: 6337\n",
      "2025-07-25 14:04:58.644 INFO: Computing average number of neighbors\n",
      "2025-07-25 14:05:06.178 INFO: Average number of neighbors: 68.51643679748439\n",
      "2025-07-25 14:05:06.180 INFO: During training the following quantities will be reported: energy, forces\n",
      "2025-07-25 14:05:06.180 INFO: ===========MODEL DETAILS===========\n",
      "2025-07-25 14:05:13.457 INFO: Loading FOUNDATION model\n",
      "2025-07-25 14:05:13.458 INFO: Using filtered elements: [3, 8, 40, 57]\n",
      "2025-07-25 14:05:13.458 INFO: Model configuration extracted from foundation model\n",
      "2025-07-25 14:05:13.458 INFO: Using universal loss function for fine-tuning\n",
      "2025-07-25 14:05:13.458 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-07-25 14:05:13.458 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-07-25 14:05:13.458 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-07-25 14:05:13.458 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 14:05:14.952 INFO: Total number of parameters: 894362\n",
      "2025-07-25 14:05:14.952 INFO: \n",
      "2025-07-25 14:05:14.952 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-07-25 14:05:14.952 INFO: Using ADAM as parameter optimizer\n",
      "2025-07-25 14:05:14.952 INFO: Batch size: 2\n",
      "2025-07-25 14:05:14.952 INFO: Number of gradient updates: 63370\n",
      "2025-07-25 14:05:14.952 INFO: Learning rate: 0.0003, weight decay: 1e-08\n",
      "2025-07-25 14:05:14.952 INFO: WeightedEnergyForcesLoss(energy_weight=100.000, forces_weight=20.000)\n",
      "2025-07-25 14:05:14.954 WARNING: No SWA checkpoint found, while SWA is enabled. Compare the swa_start parameter and the latest checkpoint.\n",
      "2025-07-25 14:05:14.955 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_h200_cn10_run-21_epoch-10.pt\n",
      "2025-07-25 14:05:14.995 INFO: Using gradient clipping with tolerance=30.000\n",
      "2025-07-25 14:05:14.995 INFO: \n",
      "2025-07-25 14:05:14.995 INFO: ===========TRAINING===========\n",
      "2025-07-25 14:05:14.995 INFO: Started training, reporting errors on validation set\n",
      "2025-07-25 14:05:14.995 INFO: Loss metrics on validation set\n",
      "2025-07-25 14:06:30.290 INFO: Initial: head: Default, loss=3.75295525, RMSE_E_per_atom=  190.91 meV, RMSE_F=   76.92 meV / A\n",
      "2025-07-25 14:38:36.468 INFO: Epoch 10: head: Default, loss=0.23021270, RMSE_E_per_atom=   36.14 meV, RMSE_F=   73.75 meV / A\n",
      "2025-07-25 15:10:38.106 INFO: Epoch 11: head: Default, loss=0.11833722, RMSE_E_per_atom=   15.70 meV, RMSE_F=   71.59 meV / A\n",
      "2025-07-25 15:42:40.814 INFO: Epoch 12: head: Default, loss=0.09542112, RMSE_E_per_atom=    7.87 meV, RMSE_F=   69.90 meV / A\n",
      "2025-07-25 16:14:43.063 INFO: Epoch 13: head: Default, loss=0.08778562, RMSE_E_per_atom=    4.17 meV, RMSE_F=   68.66 meV / A\n",
      "2025-07-25 16:46:44.360 INFO: Epoch 14: head: Default, loss=0.12805158, RMSE_E_per_atom=   21.27 meV, RMSE_F=   67.40 meV / A\n",
      "2025-07-25 17:18:45.570 INFO: Epoch 15: head: Default, loss=0.12677571, RMSE_E_per_atom=   21.56 meV, RMSE_F=   66.41 meV / A\n",
      "2025-07-25 17:50:47.745 INFO: Epoch 16: head: Default, loss=0.15568914, RMSE_E_per_atom=   27.85 meV, RMSE_F=   65.48 meV / A\n",
      "2025-07-25 17:50:47.747 INFO: Stopping optimization after 3 epochs without improvement\n",
      "2025-07-25 17:50:47.747 INFO: Training complete\n",
      "2025-07-25 17:50:47.747 INFO: \n",
      "2025-07-25 17:50:47.747 INFO: ===========RESULTS===========\n",
      "2025-07-25 17:50:47.811 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_h200_cn10_run-21_epoch-13.pt\n",
      "2025-07-25 17:50:47.849 INFO: Loaded Stage one model from epoch 13 for evaluation\n",
      "2025-07-25 17:50:47.849 INFO: Saving model to checkpoints/mace_T1_finetune_h200_cn10_run-21.model\n",
      "2025-07-25 17:50:48.088 INFO: Compiling model, saving metadata to mace_T1_finetune_h200_cn10_compiled.model\n",
      "2025-07-25 17:50:48.904 INFO: Computing metrics for training, validation, and test sets\n",
      "2025-07-25 17:50:48.905 INFO: Skipping evaluation for heads: ['pt_head']\n",
      "2025-07-25 17:50:48.905 INFO: Evaluating train_Default ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/bin/mace_run_train\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m75\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mrun\u001b[0m\u001b[1;31m(args)\u001b[0m\n",
      "    \u001b[31m~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m955\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    table_train_valid = create_error_table(\n",
      "        table_type=args.error_table,\n",
      "    ...<7 lines>...\n",
      "        skip_heads=skip_heads,\n",
      "    )\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/tables_utils.py\"\u001b[0m, line \u001b[35m110\u001b[0m, in \u001b[35mcreate_error_table\u001b[0m\n",
      "    _, metrics = \u001b[31mevaluate\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^\u001b[0m\n",
      "    ...<3 lines>...\n",
      "        \u001b[1;31mdevice=device,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m549\u001b[0m, in \u001b[35mevaluate\u001b[0m\n",
      "    avg_loss, aux = \u001b[31mmetrics\u001b[0m\u001b[1;31m(batch, output)\u001b[0m\n",
      "                    \u001b[31m~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m1751\u001b[0m, in \u001b[35m_wrapped_call_impl\u001b[0m\n",
      "    return \u001b[31mself._call_impl\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m1762\u001b[0m, in \u001b[35m_call_impl\u001b[0m\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torchmetrics/metric.py\"\u001b[0m, line \u001b[35m313\u001b[0m, in \u001b[35mforward\u001b[0m\n",
      "    self._forward_cache = \u001b[31mself._forward_full_state_update\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "                          \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torchmetrics/metric.py\"\u001b[0m, line \u001b[35m328\u001b[0m, in \u001b[35m_forward_full_state_update\u001b[0m\n",
      "    \u001b[31mself.update\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torchmetrics/metric.py\"\u001b[0m, line \u001b[35m549\u001b[0m, in \u001b[35mwrapped_func\u001b[0m\n",
      "    \u001b[31mupdate\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "    \u001b[31m~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m588\u001b[0m, in \u001b[35mupdate\u001b[0m\n",
      "    loss = self.loss_fn(pred=output, ref=batch)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m1751\u001b[0m, in \u001b[35m_wrapped_call_impl\u001b[0m\n",
      "    return \u001b[31mself._call_impl\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m1762\u001b[0m, in \u001b[35m_call_impl\u001b[0m\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/modules/loss.py\"\u001b[0m, line \u001b[35m241\u001b[0m, in \u001b[35mforward\u001b[0m\n",
      "    loss_forces = mean_squared_error_forces(ref, pred, ddp)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/modules/loss.py\"\u001b[0m, line \u001b[35m124\u001b[0m, in \u001b[35mmean_squared_error_forces\u001b[0m\n",
      "    configs_weight = \u001b[31mtorch.repeat_interleave\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mref.weight, ref.ptr[1:] - ref.ptr[:-1]\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m.unsqueeze(-1)\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_run_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--name\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_T1_finetune_h200_cn10\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--restart_latest\u001b[39m\u001b[38;5;124m\"\u001b[39m,                   \u001b[38;5;66;03m# Resumes from checkpoint if available\u001b[39;00m\n\u001b[1;32m     49\u001b[0m ]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd), file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m---> 52\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    os.environ[\"PYTHONPATH\"] = \"/home/phanim/harshitrawat/mace/mace\"\n",
    "\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        \"--name\",              \"mace_T1_finetune_h200_cn10\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "\n",
    "        \"--train_file\",        \"/home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz\",\n",
    "        \"--valid_file\",        \"/home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz\",\n",
    "\n",
    "        \"--batch_size\",        \"2\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "        \"--valid_fraction\",    \"0.1\",\n",
    "\n",
    "        \"--device\",            \"cuda\",\n",
    "\n",
    "        # === Loss function weights ===\n",
    "        \"--forces_weight\",     \"20\",         # Increased force weight to balance energy better\n",
    "        \"--energy_weight\",     \"100\",         # Reduced from 100 → avoid dominance + stabilize energy RMSE\n",
    "\n",
    "        # === Learning setup ===\n",
    "        \"--lr\",                \"0.0003\",      # Explicit learning rate (0.0001 is too low → stagnation)\n",
    "        \"--scheduler_patience\",\"3\",          # Reduce LR if val loss doesn’t improve in 3 epochs\n",
    "        \"--clip_grad\",         \"30\",        # Avoid exploding gradients — essential when energy_weight is high\n",
    "        \"--weight_decay\",      \"1e-8\",       # Mild regularization to prevent overfitting\n",
    "\n",
    "        # === EMA helps smooth loss curve ===\n",
    "        \"--ema_decay\",         \"0.999\",     # Smooths validation loss and helps final convergence\n",
    "\n",
    "        # === Domain + training settings ===\n",
    "        \"--r_max\",             \"5.0\",\n",
    "        \"--max_num_epochs\",    \"20\",\n",
    "        \"--E0s\",               \"{3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\",    # Still allowed — could optionally be replaced by manual E0s\n",
    "        \"--seed\",              \"21\",\n",
    "        \"--patience\",     \"3\",\n",
    "\n",
    "        \"--restart_latest\",                   # Resumes from checkpoint if available\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1716172-c9a6-4ef5-ab0d-3abb0d31d26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    mace_T1_finetune_h200_cn10 \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz \\\n",
      "    --valid_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz \\\n",
      "    --batch_size \\\n",
      "    2 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --valid_fraction \\\n",
      "    0.1 \\\n",
      "    --device \\\n",
      "    cuda \\\n",
      "    --forces_weight \\\n",
      "    100 \\\n",
      "    --energy_weight \\\n",
      "    10 \\\n",
      "    --lr \\\n",
      "    0.0003 \\\n",
      "    --scheduler_patience \\\n",
      "    3 \\\n",
      "    --clip_grad \\\n",
      "    30 \\\n",
      "    --weight_decay \\\n",
      "    1e-8 \\\n",
      "    --ema_decay \\\n",
      "    0.999 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --max_num_epochs \\\n",
      "    30 \\\n",
      "    --E0s \\\n",
      "    {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549} \\\n",
      "    --seed \\\n",
      "    21 \\\n",
      "    --patience \\\n",
      "    3 \\\n",
      "    --restart_latest\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 17:51:52.039 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-07-25 17:51:52.039 INFO: MACE version: 0.3.13\n",
      "2025-07-25 17:51:52.620 INFO: CUDA version: 12.6, CUDA device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:157: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 17:51:53.067 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-07-25 17:51:53.068 WARNING: Using multiheads finetuning with a foundation model that is not a Materials Project model, need to provied a path to a pretraining file with --pt_train_file.\n",
      "2025-07-25 17:51:53.068 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-07-25 17:51:53.069 INFO: Using heads: ['Default']\n",
      "2025-07-25 17:51:53.069 INFO: Using the key specifications to parse data:\n",
      "2025-07-25 17:51:53.069 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-07-25 17:51:53.069 INFO: =============    Processing head Default     ===========\n",
      "2025-07-25 17:52:14.097 INFO: Training set 1/1 [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 17:52:14.115 INFO: Total Training set [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 17:52:16.707 INFO: Validation set 1/1 [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 17:52:16.709 INFO: Total Validation set [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 17:52:16.709 INFO: Total number of configurations: train=6337, valid=705, tests=[],\n",
      "2025-07-25 17:52:17.004 INFO: Atomic Numbers used: [3, 8, 40, 57]\n",
      "2025-07-25 17:52:17.004 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-07-25 17:52:17.004 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\n",
      "2025-07-25 17:52:17.004 INFO: Processing datasets for head 'Default'\n",
      "2025-07-25 17:53:39.864 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-07-25 17:53:49.305 INFO: Combining 1 list datasets for head 'Default_valid'\n",
      "2025-07-25 17:53:49.306 INFO: Combined validation datasets for Default\n",
      "2025-07-25 17:53:49.306 INFO: Head 'Default' training dataset size: 6337\n",
      "2025-07-25 17:53:49.306 INFO: Computing average number of neighbors\n",
      "2025-07-25 17:53:56.930 INFO: Average number of neighbors: 68.51643679748439\n",
      "2025-07-25 17:53:56.931 INFO: During training the following quantities will be reported: energy, forces\n",
      "2025-07-25 17:53:56.931 INFO: ===========MODEL DETAILS===========\n",
      "2025-07-25 17:54:03.936 INFO: Loading FOUNDATION model\n",
      "2025-07-25 17:54:03.937 INFO: Using filtered elements: [3, 8, 40, 57]\n",
      "2025-07-25 17:54:03.938 INFO: Model configuration extracted from foundation model\n",
      "2025-07-25 17:54:03.938 INFO: Using universal loss function for fine-tuning\n",
      "2025-07-25 17:54:03.938 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-07-25 17:54:03.938 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-07-25 17:54:03.938 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-07-25 17:54:03.938 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 17:54:05.397 INFO: Total number of parameters: 894362\n",
      "2025-07-25 17:54:05.397 INFO: \n",
      "2025-07-25 17:54:05.397 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-07-25 17:54:05.397 INFO: Using ADAM as parameter optimizer\n",
      "2025-07-25 17:54:05.397 INFO: Batch size: 2\n",
      "2025-07-25 17:54:05.397 INFO: Number of gradient updates: 95055\n",
      "2025-07-25 17:54:05.397 INFO: Learning rate: 0.0003, weight decay: 1e-08\n",
      "2025-07-25 17:54:05.397 INFO: WeightedEnergyForcesLoss(energy_weight=10.000, forces_weight=100.000)\n",
      "2025-07-25 17:54:05.399 WARNING: No SWA checkpoint found, while SWA is enabled. Compare the swa_start parameter and the latest checkpoint.\n",
      "2025-07-25 17:54:05.400 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_h200_cn10_run-21_epoch-13.pt\n",
      "2025-07-25 17:54:05.441 INFO: Using gradient clipping with tolerance=30.000\n",
      "2025-07-25 17:54:05.441 INFO: \n",
      "2025-07-25 17:54:05.441 INFO: ===========TRAINING===========\n",
      "2025-07-25 17:54:05.441 INFO: Started training, reporting errors on validation set\n",
      "2025-07-25 17:54:05.441 INFO: Loss metrics on validation set\n",
      "2025-07-25 17:55:20.677 INFO: Initial: head: Default, loss=0.43040350, RMSE_E_per_atom=    4.17 meV, RMSE_F=   68.66 meV / A\n",
      "2025-07-25 18:27:26.423 INFO: Epoch 13: head: Default, loss=0.35144456, RMSE_E_per_atom=    6.95 meV, RMSE_F=   62.35 meV / A\n",
      "2025-07-25 18:59:28.836 INFO: Epoch 14: head: Default, loss=0.30883556, RMSE_E_per_atom=   14.07 meV, RMSE_F=   58.27 meV / A\n",
      "2025-07-25 19:31:31.812 INFO: Epoch 15: head: Default, loss=0.27620191, RMSE_E_per_atom=    9.23 meV, RMSE_F=   55.38 meV / A\n",
      "2025-07-25 20:03:34.525 INFO: Epoch 16: head: Default, loss=0.25726939, RMSE_E_per_atom=    6.67 meV, RMSE_F=   53.46 meV / A\n",
      "2025-07-25 20:35:37.730 INFO: Epoch 17: head: Default, loss=0.24050822, RMSE_E_per_atom=    4.17 meV, RMSE_F=   51.76 meV / A\n",
      "2025-07-25 21:07:40.454 INFO: Epoch 18: head: Default, loss=0.22507515, RMSE_E_per_atom=    5.41 meV, RMSE_F=   50.14 meV / A\n",
      "2025-07-25 21:39:45.212 INFO: Epoch 19: head: Default, loss=0.21889112, RMSE_E_per_atom=    5.23 meV, RMSE_F=   49.39 meV / A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/bin/mace_run_train\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m75\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mrun\u001b[0m\u001b[1;31m(args)\u001b[0m\n",
      "    \u001b[31m~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m778\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mtools.train\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<23 lines>...\n",
      "        \u001b[1;31mrank=rank,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m222\u001b[0m, in \u001b[35mtrain\u001b[0m\n",
      "    \u001b[31mtrain_one_epoch\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<11 lines>...\n",
      "        \u001b[1;31mrank=rank,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m370\u001b[0m, in \u001b[35mtrain_one_epoch\u001b[0m\n",
      "    _, opt_metrics = \u001b[31mtake_step\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                     \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model_to_train,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<6 lines>...\n",
      "        \u001b[1;31mdevice=device,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m416\u001b[0m, in \u001b[35mtake_step\u001b[0m\n",
      "    loss = closure()\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m409\u001b[0m, in \u001b[35mclosure\u001b[0m\n",
      "    loss = loss_fn(pred=output, ref=batch)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m1751\u001b[0m, in \u001b[35m_wrapped_call_impl\u001b[0m\n",
      "    return \u001b[31mself._call_impl\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m1762\u001b[0m, in \u001b[35m_call_impl\u001b[0m\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/modules/loss.py\"\u001b[0m, line \u001b[35m241\u001b[0m, in \u001b[35mforward\u001b[0m\n",
      "    loss_forces = mean_squared_error_forces(ref, pred, ddp)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/modules/loss.py\"\u001b[0m, line \u001b[35m124\u001b[0m, in \u001b[35mmean_squared_error_forces\u001b[0m\n",
      "    configs_weight = \u001b[31mtorch.repeat_interleave\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mref.weight, ref.ptr[1:] - ref.ptr[:-1]\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m.unsqueeze(-1)\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 52\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_run_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--name\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_T1_finetune_h200_cn10\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--restart_latest\u001b[39m\u001b[38;5;124m\"\u001b[39m,                   \u001b[38;5;66;03m# Resumes from checkpoint if available\u001b[39;00m\n\u001b[1;32m     49\u001b[0m ]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd), file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m---> 52\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    os.environ[\"PYTHONPATH\"] = \"/home/phanim/harshitrawat/mace/mace\"\n",
    "\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        \"--name\",              \"mace_T1_finetune_h200_cn10\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "\n",
    "        \"--train_file\",        \"/home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz\",\n",
    "        \"--valid_file\",        \"/home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz\",\n",
    "\n",
    "        \"--batch_size\",        \"2\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "        \"--valid_fraction\",    \"0.1\",\n",
    "\n",
    "        \"--device\",            \"cuda\",\n",
    "\n",
    "        # === Loss function weights ===\n",
    "        \"--forces_weight\",     \"100\",         # Increased force weight to balance energy better\n",
    "        \"--energy_weight\",     \"10\",         # Reduced from 100 → avoid dominance + stabilize energy RMSE\n",
    "\n",
    "        # === Learning setup ===\n",
    "        \"--lr\",                \"0.0003\",      # Explicit learning rate (0.0001 is too low → stagnation)\n",
    "        \"--scheduler_patience\",\"3\",          # Reduce LR if val loss doesn’t improve in 3 epochs\n",
    "        \"--clip_grad\",         \"30\",        # Avoid exploding gradients — essential when energy_weight is high\n",
    "        \"--weight_decay\",      \"1e-8\",       # Mild regularization to prevent overfitting\n",
    "\n",
    "        # === EMA helps smooth loss curve ===\n",
    "        \"--ema_decay\",         \"0.999\",     # Smooths validation loss and helps final convergence\n",
    "\n",
    "        # === Domain + training settings ===\n",
    "        \"--r_max\",             \"5.0\",\n",
    "        \"--max_num_epochs\",    \"30\",\n",
    "        \"--E0s\",               \"{3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\",    # Still allowed — could optionally be replaced by manual E0s\n",
    "        \"--seed\",              \"21\",\n",
    "        \"--patience\",     \"3\",\n",
    "\n",
    "        \"--restart_latest\",                   # Resumes from checkpoint if available\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "020bd1c8-95e3-45ee-b00e-bad4d73f9190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    mace_T1_finetune_h200_cn10 \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz \\\n",
      "    --valid_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz \\\n",
      "    --batch_size \\\n",
      "    2 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --valid_fraction \\\n",
      "    0.1 \\\n",
      "    --device \\\n",
      "    cuda \\\n",
      "    --forces_weight \\\n",
      "    100 \\\n",
      "    --energy_weight \\\n",
      "    5 \\\n",
      "    --lr \\\n",
      "    0.0003 \\\n",
      "    --scheduler_patience \\\n",
      "    3 \\\n",
      "    --clip_grad \\\n",
      "    30 \\\n",
      "    --weight_decay \\\n",
      "    1e-8 \\\n",
      "    --ema_decay \\\n",
      "    0.999 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --max_num_epochs \\\n",
      "    30 \\\n",
      "    --E0s \\\n",
      "    {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549} \\\n",
      "    --seed \\\n",
      "    21 \\\n",
      "    --patience \\\n",
      "    3 \\\n",
      "    --restart_latest\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 21:47:24.612 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-07-25 21:47:24.612 INFO: MACE version: 0.3.13\n",
      "2025-07-25 21:47:25.270 INFO: CUDA version: 12.6, CUDA device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:157: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 21:47:25.723 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-07-25 21:47:25.724 WARNING: Using multiheads finetuning with a foundation model that is not a Materials Project model, need to provied a path to a pretraining file with --pt_train_file.\n",
      "2025-07-25 21:47:25.725 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-07-25 21:47:25.725 INFO: Using heads: ['Default']\n",
      "2025-07-25 21:47:25.725 INFO: Using the key specifications to parse data:\n",
      "2025-07-25 21:47:25.725 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-07-25 21:47:25.725 INFO: =============    Processing head Default     ===========\n",
      "2025-07-25 21:47:47.330 INFO: Training set 1/1 [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 21:47:47.348 INFO: Total Training set [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 21:47:49.950 INFO: Validation set 1/1 [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 21:47:49.952 INFO: Total Validation set [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 21:47:49.952 INFO: Total number of configurations: train=6337, valid=705, tests=[],\n",
      "2025-07-25 21:47:50.248 INFO: Atomic Numbers used: [3, 8, 40, 57]\n",
      "2025-07-25 21:47:50.248 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-07-25 21:47:50.248 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\n",
      "2025-07-25 21:47:50.248 INFO: Processing datasets for head 'Default'\n",
      "2025-07-25 21:49:13.283 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-07-25 21:49:22.736 INFO: Combining 1 list datasets for head 'Default_valid'\n",
      "2025-07-25 21:49:22.736 INFO: Combined validation datasets for Default\n",
      "2025-07-25 21:49:22.736 INFO: Head 'Default' training dataset size: 6337\n",
      "2025-07-25 21:49:22.737 INFO: Computing average number of neighbors\n",
      "2025-07-25 21:49:30.275 INFO: Average number of neighbors: 68.51643679748439\n",
      "2025-07-25 21:49:30.276 INFO: During training the following quantities will be reported: energy, forces\n",
      "2025-07-25 21:49:30.276 INFO: ===========MODEL DETAILS===========\n",
      "2025-07-25 21:49:37.277 INFO: Loading FOUNDATION model\n",
      "2025-07-25 21:49:37.278 INFO: Using filtered elements: [3, 8, 40, 57]\n",
      "2025-07-25 21:49:37.278 INFO: Model configuration extracted from foundation model\n",
      "2025-07-25 21:49:37.279 INFO: Using universal loss function for fine-tuning\n",
      "2025-07-25 21:49:37.279 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-07-25 21:49:37.279 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-07-25 21:49:37.279 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-07-25 21:49:37.279 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 21:49:38.679 INFO: Total number of parameters: 894362\n",
      "2025-07-25 21:49:38.679 INFO: \n",
      "2025-07-25 21:49:38.679 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-07-25 21:49:38.679 INFO: Using ADAM as parameter optimizer\n",
      "2025-07-25 21:49:38.679 INFO: Batch size: 2\n",
      "2025-07-25 21:49:38.679 INFO: Number of gradient updates: 95055\n",
      "2025-07-25 21:49:38.679 INFO: Learning rate: 0.0003, weight decay: 1e-08\n",
      "2025-07-25 21:49:38.679 INFO: WeightedEnergyForcesLoss(energy_weight=5.000, forces_weight=100.000)\n",
      "2025-07-25 21:49:38.700 WARNING: No SWA checkpoint found, while SWA is enabled. Compare the swa_start parameter and the latest checkpoint.\n",
      "2025-07-25 21:49:38.701 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_h200_cn10_run-21_epoch-19.pt\n",
      "2025-07-25 21:49:38.739 INFO: Using gradient clipping with tolerance=30.000\n",
      "2025-07-25 21:49:38.739 INFO: \n",
      "2025-07-25 21:49:38.739 INFO: ===========TRAINING===========\n",
      "2025-07-25 21:49:38.739 INFO: Started training, reporting errors on validation set\n",
      "2025-07-25 21:49:38.739 INFO: Loss metrics on validation set\n",
      "2025-07-25 21:50:53.606 INFO: Initial: head: Default, loss=0.21875416, RMSE_E_per_atom=    5.23 meV, RMSE_F=   49.39 meV / A\n",
      "2025-07-25 22:22:55.482 INFO: Epoch 19: head: Default, loss=0.20574446, RMSE_E_per_atom=    3.55 meV, RMSE_F=   47.97 meV / A\n",
      "2025-07-25 22:54:55.033 INFO: Epoch 20: head: Default, loss=0.19977895, RMSE_E_per_atom=    3.58 meV, RMSE_F=   47.20 meV / A\n",
      "2025-07-25 23:26:55.902 INFO: Epoch 21: head: Default, loss=0.19583250, RMSE_E_per_atom=    4.40 meV, RMSE_F=   46.85 meV / A\n",
      "2025-07-25 23:58:55.504 INFO: Epoch 22: head: Default, loss=0.18581767, RMSE_E_per_atom=    3.96 meV, RMSE_F=   45.61 meV / A\n",
      "2025-07-26 00:30:55.966 INFO: Epoch 23: head: Default, loss=0.18342619, RMSE_E_per_atom=    2.76 meV, RMSE_F=   45.31 meV / A\n",
      "2025-07-26 01:02:56.264 INFO: Epoch 24: head: Default, loss=0.17398226, RMSE_E_per_atom=    2.93 meV, RMSE_F=   44.23 meV / A\n",
      "2025-07-26 01:34:57.155 INFO: Epoch 25: head: Default, loss=0.17182387, RMSE_E_per_atom=    3.08 meV, RMSE_F=   43.91 meV / A\n",
      "2025-07-26 02:06:58.828 INFO: Epoch 26: head: Default, loss=0.16775714, RMSE_E_per_atom=    5.75 meV, RMSE_F=   43.33 meV / A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/bin/mace_run_train\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m75\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mrun\u001b[0m\u001b[1;31m(args)\u001b[0m\n",
      "    \u001b[31m~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m778\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mtools.train\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<23 lines>...\n",
      "        \u001b[1;31mrank=rank,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m222\u001b[0m, in \u001b[35mtrain\u001b[0m\n",
      "    \u001b[31mtrain_one_epoch\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<11 lines>...\n",
      "        \u001b[1;31mrank=rank,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m370\u001b[0m, in \u001b[35mtrain_one_epoch\u001b[0m\n",
      "    _, opt_metrics = \u001b[31mtake_step\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                     \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model_to_train,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<6 lines>...\n",
      "        \u001b[1;31mdevice=device,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m416\u001b[0m, in \u001b[35mtake_step\u001b[0m\n",
      "    loss = closure()\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m410\u001b[0m, in \u001b[35mclosure\u001b[0m\n",
      "    \u001b[31mloss.backward\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/_tensor.py\"\u001b[0m, line \u001b[35m648\u001b[0m, in \u001b[35mbackward\u001b[0m\n",
      "    \u001b[31mtorch.autograd.backward\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mself, gradient, retain_graph, create_graph, inputs=inputs\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/autograd/__init__.py\"\u001b[0m, line \u001b[35m353\u001b[0m, in \u001b[35mbackward\u001b[0m\n",
      "    \u001b[31m_engine_run_backward\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mtensors,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "    ...<5 lines>...\n",
      "        \u001b[1;31maccumulate_grad=True,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/autograd/graph.py\"\u001b[0m, line \u001b[35m824\u001b[0m, in \u001b[35m_engine_run_backward\u001b[0m\n",
      "    return \u001b[31mVariable._execution_engine.run_backward\u001b[0m\u001b[1;31m(  # Calls into the C++ engine to run the backward pass\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        \u001b[1;31mt_outputs, *args, **kwargs\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m  # Calls into the C++ engine to run the backward pass\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 52\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_run_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--name\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_T1_finetune_h200_cn10\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--restart_latest\u001b[39m\u001b[38;5;124m\"\u001b[39m,                   \u001b[38;5;66;03m# Resumes from checkpoint if available\u001b[39;00m\n\u001b[1;32m     49\u001b[0m ]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd), file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m---> 52\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    os.environ[\"PYTHONPATH\"] = \"/home/phanim/harshitrawat/mace/mace\"\n",
    "\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        \"--name\",              \"mace_T1_finetune_h200_cn10\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "\n",
    "        \"--train_file\",        \"/home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz\",\n",
    "        \"--valid_file\",        \"/home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz\",\n",
    "\n",
    "        \"--batch_size\",        \"2\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "        \"--valid_fraction\",    \"0.1\",\n",
    "\n",
    "        \"--device\",            \"cuda\",\n",
    "\n",
    "        # === Loss function weights ===\n",
    "        \"--forces_weight\",     \"100\",         # Increased force weight to balance energy better\n",
    "        \"--energy_weight\",     \"5\",         # Reduced from 100 → avoid dominance + stabilize energy RMSE\n",
    "\n",
    "        # === Learning setup ===\n",
    "        \"--lr\",                \"0.0003\",      # Explicit learning rate (0.0001 is too low → stagnation)\n",
    "        \"--scheduler_patience\",\"3\",          # Reduce LR if val loss doesn’t improve in 3 epochs\n",
    "        \"--clip_grad\",         \"30\",        # Avoid exploding gradients — essential when energy_weight is high\n",
    "        \"--weight_decay\",      \"1e-8\",       # Mild regularization to prevent overfitting\n",
    "\n",
    "        # === EMA helps smooth loss curve ===\n",
    "        \"--ema_decay\",         \"0.999\",     # Smooths validation loss and helps final convergence\n",
    "\n",
    "        # === Domain + training settings ===\n",
    "        \"--r_max\",             \"5.0\",\n",
    "        \"--max_num_epochs\",    \"30\",\n",
    "        \"--E0s\",               \"{3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\",    # Still allowed — could optionally be replaced by manual E0s\n",
    "        \"--seed\",              \"21\",\n",
    "        \"--patience\",     \"3\",\n",
    "\n",
    "        \"--restart_latest\",                   # Resumes from checkpoint if available\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46fcd193-efc9-4d26-8a67-7e999d7ce165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    mace_T1_finetune_h200_cn10 \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz \\\n",
      "    --valid_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz \\\n",
      "    --batch_size \\\n",
      "    2 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --valid_fraction \\\n",
      "    0.1 \\\n",
      "    --device \\\n",
      "    cuda \\\n",
      "    --forces_weight \\\n",
      "    200 \\\n",
      "    --energy_weight \\\n",
      "    1 \\\n",
      "    --lr \\\n",
      "    0.0003 \\\n",
      "    --scheduler_patience \\\n",
      "    3 \\\n",
      "    --clip_grad \\\n",
      "    30 \\\n",
      "    --weight_decay \\\n",
      "    1e-8 \\\n",
      "    --ema_decay \\\n",
      "    0.999 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --max_num_epochs \\\n",
      "    30 \\\n",
      "    --E0s \\\n",
      "    {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549} \\\n",
      "    --seed \\\n",
      "    21 \\\n",
      "    --patience \\\n",
      "    3 \\\n",
      "    --restart_latest\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 02:08:51.155 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-07-26 02:08:51.155 INFO: MACE version: 0.3.13\n",
      "2025-07-26 02:08:51.765 INFO: CUDA version: 12.6, CUDA device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:157: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 02:08:52.343 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-07-26 02:08:52.344 WARNING: Using multiheads finetuning with a foundation model that is not a Materials Project model, need to provied a path to a pretraining file with --pt_train_file.\n",
      "2025-07-26 02:08:52.344 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-07-26 02:08:52.344 INFO: Using heads: ['Default']\n",
      "2025-07-26 02:08:52.344 INFO: Using the key specifications to parse data:\n",
      "2025-07-26 02:08:52.344 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-07-26 02:08:52.344 INFO: =============    Processing head Default     ===========\n",
      "2025-07-26 02:09:13.393 INFO: Training set 1/1 [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-26 02:09:13.410 INFO: Total Training set [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-26 02:09:16.081 INFO: Validation set 1/1 [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-26 02:09:16.083 INFO: Total Validation set [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-26 02:09:16.083 INFO: Total number of configurations: train=6337, valid=705, tests=[],\n",
      "2025-07-26 02:09:16.378 INFO: Atomic Numbers used: [3, 8, 40, 57]\n",
      "2025-07-26 02:09:16.378 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-07-26 02:09:16.378 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\n",
      "2025-07-26 02:09:16.378 INFO: Processing datasets for head 'Default'\n",
      "2025-07-26 02:10:39.883 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-07-26 02:10:49.402 INFO: Combining 1 list datasets for head 'Default_valid'\n",
      "2025-07-26 02:10:49.403 INFO: Combined validation datasets for Default\n",
      "2025-07-26 02:10:49.403 INFO: Head 'Default' training dataset size: 6337\n",
      "2025-07-26 02:10:49.403 INFO: Computing average number of neighbors\n",
      "2025-07-26 02:10:57.268 INFO: Average number of neighbors: 68.51643679748439\n",
      "2025-07-26 02:10:57.269 INFO: During training the following quantities will be reported: energy, forces\n",
      "2025-07-26 02:10:57.269 INFO: ===========MODEL DETAILS===========\n",
      "2025-07-26 02:11:04.496 INFO: Loading FOUNDATION model\n",
      "2025-07-26 02:11:04.498 INFO: Using filtered elements: [3, 8, 40, 57]\n",
      "2025-07-26 02:11:04.498 INFO: Model configuration extracted from foundation model\n",
      "2025-07-26 02:11:04.498 INFO: Using universal loss function for fine-tuning\n",
      "2025-07-26 02:11:04.498 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-07-26 02:11:04.498 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-07-26 02:11:04.498 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-07-26 02:11:04.498 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 02:11:05.911 INFO: Total number of parameters: 894362\n",
      "2025-07-26 02:11:05.911 INFO: \n",
      "2025-07-26 02:11:05.911 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-07-26 02:11:05.912 INFO: Using ADAM as parameter optimizer\n",
      "2025-07-26 02:11:05.912 INFO: Batch size: 2\n",
      "2025-07-26 02:11:05.912 INFO: Number of gradient updates: 95055\n",
      "2025-07-26 02:11:05.912 INFO: Learning rate: 0.0003, weight decay: 1e-08\n",
      "2025-07-26 02:11:05.912 INFO: WeightedEnergyForcesLoss(energy_weight=1.000, forces_weight=200.000)\n",
      "2025-07-26 02:11:05.914 WARNING: No SWA checkpoint found, while SWA is enabled. Compare the swa_start parameter and the latest checkpoint.\n",
      "2025-07-26 02:11:05.915 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_h200_cn10_run-21_epoch-26.pt\n",
      "2025-07-26 02:11:05.955 INFO: Using gradient clipping with tolerance=30.000\n",
      "2025-07-26 02:11:05.955 INFO: \n",
      "2025-07-26 02:11:05.955 INFO: ===========TRAINING===========\n",
      "2025-07-26 02:11:05.955 INFO: Started training, reporting errors on validation set\n",
      "2025-07-26 02:11:05.955 INFO: Loss metrics on validation set\n",
      "2025-07-26 02:12:21.099 INFO: Initial: head: Default, loss=0.33521649, RMSE_E_per_atom=    5.75 meV, RMSE_F=   43.33 meV / A\n",
      "2025-07-26 02:44:27.650 INFO: Epoch 26: head: Default, loss=0.32733785, RMSE_E_per_atom=    8.66 meV, RMSE_F=   42.90 meV / A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/bin/mace_run_train\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m75\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mrun\u001b[0m\u001b[1;31m(args)\u001b[0m\n",
      "    \u001b[31m~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m778\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mtools.train\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<23 lines>...\n",
      "        \u001b[1;31mrank=rank,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m222\u001b[0m, in \u001b[35mtrain\u001b[0m\n",
      "    \u001b[31mtrain_one_epoch\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<11 lines>...\n",
      "        \u001b[1;31mrank=rank,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m370\u001b[0m, in \u001b[35mtrain_one_epoch\u001b[0m\n",
      "    _, opt_metrics = \u001b[31mtake_step\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                     \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model_to_train,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<6 lines>...\n",
      "        \u001b[1;31mdevice=device,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m417\u001b[0m, in \u001b[35mtake_step\u001b[0m\n",
      "    \u001b[31moptimizer.step\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m485\u001b[0m, in \u001b[35mwrapper\u001b[0m\n",
      "    out = func(*args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m79\u001b[0m, in \u001b[35m_use_grad\u001b[0m\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/adam.py\"\u001b[0m, line \u001b[35m246\u001b[0m, in \u001b[35mstep\u001b[0m\n",
      "    \u001b[31madam\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mparams_with_grad,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<19 lines>...\n",
      "        \u001b[1;31mdecoupled_weight_decay=group[\"decoupled_weight_decay\"],\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m147\u001b[0m, in \u001b[35mmaybe_fallback\u001b[0m\n",
      "    return func(*args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/adam.py\"\u001b[0m, line \u001b[35m933\u001b[0m, in \u001b[35madam\u001b[0m\n",
      "    \u001b[31mfunc\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mparams,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^\u001b[0m\n",
      "    ...<17 lines>...\n",
      "        \u001b[1;31mdecoupled_weight_decay=decoupled_weight_decay,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/adam.py\"\u001b[0m, line \u001b[35m739\u001b[0m, in \u001b[35m_multi_tensor_adam\u001b[0m\n",
      "    1 - beta1 ** \u001b[31m_get_value\u001b[0m\u001b[1;31m(step)\u001b[0m for step in device_state_steps\n",
      "                 \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m94\u001b[0m, in \u001b[35m_get_value\u001b[0m\n",
      "    return \u001b[31mx.item\u001b[0m\u001b[1;31m()\u001b[0m if isinstance(x, torch.Tensor) else x\n",
      "           \u001b[31m~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 52\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_run_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--name\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_T1_finetune_h200_cn10\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--restart_latest\u001b[39m\u001b[38;5;124m\"\u001b[39m,                   \u001b[38;5;66;03m# Resumes from checkpoint if available\u001b[39;00m\n\u001b[1;32m     49\u001b[0m ]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd), file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m---> 52\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    os.environ[\"PYTHONPATH\"] = \"/home/phanim/harshitrawat/mace/mace\"\n",
    "\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        \"--name\",              \"mace_T1_finetune_h200_cn10\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "\n",
    "        \"--train_file\",        \"/home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz\",\n",
    "        \"--valid_file\",        \"/home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz\",\n",
    "\n",
    "        \"--batch_size\",        \"2\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "        \"--valid_fraction\",    \"0.1\",\n",
    "\n",
    "        \"--device\",            \"cuda\",\n",
    "\n",
    "        # === Loss function weights ===\n",
    "        \"--forces_weight\",     \"200\",         # Increased force weight to balance energy better\n",
    "        \"--energy_weight\",     \"1\",         # Reduced from 100 → avoid dominance + stabilize energy RMSE\n",
    "\n",
    "        # === Learning setup ===\n",
    "        \"--lr\",                \"0.0003\",      # Explicit learning rate (0.0001 is too low → stagnation)\n",
    "        \"--scheduler_patience\",\"3\",          # Reduce LR if val loss doesn’t improve in 3 epochs\n",
    "        \"--clip_grad\",         \"30\",        # Avoid exploding gradients — essential when energy_weight is high\n",
    "        \"--weight_decay\",      \"1e-8\",       # Mild regularization to prevent overfitting\n",
    "\n",
    "        # === EMA helps smooth loss curve ===\n",
    "        \"--ema_decay\",         \"0.999\",     # Smooths validation loss and helps final convergence\n",
    "\n",
    "        # === Domain + training settings ===\n",
    "        \"--r_max\",             \"5.0\",\n",
    "        \"--max_num_epochs\",    \"35\",\n",
    "        \"--E0s\",               \"{3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\",    # Still allowed — could optionally be replaced by manual E0s\n",
    "        \"--seed\",              \"21\",\n",
    "        \"--patience\",     \"3\",\n",
    "\n",
    "        \"--restart_latest\",                   # Resumes from checkpoint if available\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ddb27f-9ea0-4672-803d-1b778f376022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    mace_T1_finetune_h200_cn10 \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz \\\n",
      "    --valid_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz \\\n",
      "    --batch_size \\\n",
      "    2 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --valid_fraction \\\n",
      "    0.1 \\\n",
      "    --device \\\n",
      "    cuda \\\n",
      "    --forces_weight \\\n",
      "    200 \\\n",
      "    --energy_weight \\\n",
      "    1 \\\n",
      "    --lr \\\n",
      "    0.0006 \\\n",
      "    --scheduler_patience \\\n",
      "    4 \\\n",
      "    --clip_grad \\\n",
      "    10 \\\n",
      "    --weight_decay \\\n",
      "    1e-8 \\\n",
      "    --ema_decay \\\n",
      "    0.999 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --max_num_epochs \\\n",
      "    61 \\\n",
      "    --E0s \\\n",
      "    {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549} \\\n",
      "    --seed \\\n",
      "    21 \\\n",
      "    --patience \\\n",
      "    5 \\\n",
      "    --restart_latest\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-27 16:20:23.585 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-07-27 16:20:23.585 INFO: MACE version: 0.3.13\n",
      "2025-07-27 16:20:24.325 INFO: CUDA version: 12.6, CUDA device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:157: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-27 16:20:25.010 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-07-27 16:20:25.013 WARNING: Using multiheads finetuning with a foundation model that is not a Materials Project model, need to provied a path to a pretraining file with --pt_train_file.\n",
      "2025-07-27 16:20:25.013 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-07-27 16:20:25.013 INFO: Using heads: ['Default']\n",
      "2025-07-27 16:20:25.013 INFO: Using the key specifications to parse data:\n",
      "2025-07-27 16:20:25.014 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-07-27 16:20:25.014 INFO: =============    Processing head Default     ===========\n",
      "2025-07-27 16:20:46.065 INFO: Training set 1/1 [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-27 16:20:46.082 INFO: Total Training set [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-27 16:20:48.673 INFO: Validation set 1/1 [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-27 16:20:48.675 INFO: Total Validation set [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-27 16:20:48.675 INFO: Total number of configurations: train=6337, valid=705, tests=[],\n",
      "2025-07-27 16:20:48.979 INFO: Atomic Numbers used: [3, 8, 40, 57]\n",
      "2025-07-27 16:20:48.979 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-07-27 16:20:48.980 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\n",
      "2025-07-27 16:20:48.980 INFO: Processing datasets for head 'Default'\n",
      "2025-07-27 16:22:12.188 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-07-27 16:22:21.623 INFO: Combining 1 list datasets for head 'Default_valid'\n",
      "2025-07-27 16:22:21.623 INFO: Combined validation datasets for Default\n",
      "2025-07-27 16:22:21.623 INFO: Head 'Default' training dataset size: 6337\n",
      "2025-07-27 16:22:21.624 INFO: Computing average number of neighbors\n",
      "2025-07-27 16:22:29.360 INFO: Average number of neighbors: 68.51643679748439\n",
      "2025-07-27 16:22:29.361 INFO: During training the following quantities will be reported: energy, forces\n",
      "2025-07-27 16:22:29.361 INFO: ===========MODEL DETAILS===========\n",
      "2025-07-27 16:22:36.483 INFO: Loading FOUNDATION model\n",
      "2025-07-27 16:22:36.484 INFO: Using filtered elements: [3, 8, 40, 57]\n",
      "2025-07-27 16:22:36.485 INFO: Model configuration extracted from foundation model\n",
      "2025-07-27 16:22:36.485 INFO: Using universal loss function for fine-tuning\n",
      "2025-07-27 16:22:36.485 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-07-27 16:22:36.485 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-07-27 16:22:36.485 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-07-27 16:22:36.485 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-27 16:22:37.909 INFO: Total number of parameters: 894362\n",
      "2025-07-27 16:22:37.909 INFO: \n",
      "2025-07-27 16:22:37.909 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-07-27 16:22:37.909 INFO: Using ADAM as parameter optimizer\n",
      "2025-07-27 16:22:37.909 INFO: Batch size: 2\n",
      "2025-07-27 16:22:37.909 INFO: Number of gradient updates: 193278\n",
      "2025-07-27 16:22:37.909 INFO: Learning rate: 0.0006, weight decay: 1e-08\n",
      "2025-07-27 16:22:37.909 INFO: WeightedEnergyForcesLoss(energy_weight=1.000, forces_weight=200.000)\n",
      "2025-07-27 16:22:37.914 WARNING: No SWA checkpoint found, while SWA is enabled. Compare the swa_start parameter and the latest checkpoint.\n",
      "2025-07-27 16:22:37.914 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_h200_cn10_run-21_epoch-60.pt\n",
      "2025-07-27 16:22:37.962 INFO: Using gradient clipping with tolerance=10.000\n",
      "2025-07-27 16:22:37.962 INFO: \n",
      "2025-07-27 16:22:37.962 INFO: ===========TRAINING===========\n",
      "2025-07-27 16:22:37.962 INFO: Started training, reporting errors on validation set\n",
      "2025-07-27 16:22:37.962 INFO: Loss metrics on validation set\n",
      "2025-07-27 16:23:52.755 INFO: Initial: head: Default, loss=0.17985062, RMSE_E_per_atom=    9.05 meV, RMSE_F=   31.99 meV / A\n",
      "2025-07-27 16:55:54.305 INFO: Epoch 60: head: Default, loss=0.17877602, RMSE_E_per_atom=    9.06 meV, RMSE_F=   31.90 meV / A\n",
      "2025-07-27 16:55:54.411 INFO: Training complete\n",
      "2025-07-27 16:55:54.411 INFO: \n",
      "2025-07-27 16:55:54.411 INFO: ===========RESULTS===========\n",
      "2025-07-27 16:55:54.415 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_h200_cn10_run-21_epoch-60.pt\n",
      "2025-07-27 16:55:54.447 INFO: Loaded Stage one model from epoch 60 for evaluation\n",
      "2025-07-27 16:55:54.447 INFO: Saving model to checkpoints/mace_T1_finetune_h200_cn10_run-21.model\n",
      "2025-07-27 16:55:54.713 INFO: Compiling model, saving metadata to mace_T1_finetune_h200_cn10_compiled.model\n",
      "2025-07-27 16:55:55.329 INFO: Computing metrics for training, validation, and test sets\n",
      "2025-07-27 16:55:55.330 INFO: Skipping evaluation for heads: ['pt_head']\n",
      "2025-07-27 16:55:55.330 INFO: Evaluating train_Default ...\n",
      "2025-07-27 17:07:56.375 INFO: Evaluating valid_Default ...\n",
      "2025-07-27 17:09:09.347 INFO: Error-table on TRAIN and VALID:\n",
      "+---------------+---------------------+------------------+-------------------+\n",
      "|  config_type  | RMSE E / meV / atom | RMSE F / meV / A | relative F RMSE % |\n",
      "+---------------+---------------------+------------------+-------------------+\n",
      "| train_Default |            9.1      |         32.3     |          9.38     |\n",
      "| valid_Default |            9.1      |         31.9     |          9.28     |\n",
      "+---------------+---------------------+------------------+-------------------+\n",
      "2025-07-27 17:25:26.392 INFO: Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    os.environ[\"PYTHONPATH\"] = \"/home/phanim/harshitrawat/mace/mace\"\n",
    "\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        \"--name\",              \"mace_T1_finetune_h200_cn10\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "\n",
    "        \"--train_file\",        \"/home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz\",\n",
    "        \"--valid_file\",        \"/home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz\",\n",
    "\n",
    "        \"--batch_size\",        \"2\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "        \"--valid_fraction\",    \"0.1\",\n",
    "\n",
    "        \"--device\",            \"cuda\",\n",
    "\n",
    "        # === Loss function weights ===\n",
    "        \"--forces_weight\",     \"200\",         # Increased force weight to balance energy better\n",
    "        \"--energy_weight\",     \"1\",         # Reduced from 100 → avoid dominance + stabilize energy RMSE\n",
    "\n",
    "        # === Learning setup ===\n",
    "        \"--lr\",                \"0.0006\",      # Explicit learning rate (0.0001 is too low → stagnation)\n",
    "        \"--scheduler_patience\",\"4\",          # Reduce LR if val loss doesn’t improve in 3 epochs\n",
    "        \"--clip_grad\",         \"10\",        # Avoid exploding gradients — essential when energy_weight is high\n",
    "        \"--weight_decay\",      \"1e-8\",       # Mild regularization to prevent overfitting\n",
    "\n",
    "        # === EMA helps smooth loss curve ===\n",
    "        \"--ema_decay\",         \"0.999\",     # Smooths validation loss and helps final convergence\n",
    "\n",
    "        # === Domain + training settings ===\n",
    "        \"--r_max\",             \"5.0\",\n",
    "        \"--max_num_epochs\",    \"61\",\n",
    "        \"--E0s\",               \"{3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\",    # Still allowed — could optionally be replaced by manual E0s\n",
    "        \"--seed\",              \"21\",\n",
    "        \"--patience\",     \"5\",\n",
    "\n",
    "        \"--restart_latest\",                   # Resumes from checkpoint if available\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4483f6-8738-4e69-b6f2-969c5751929b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/e3nn/o3/_wigner.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n",
      "WARNING:root:'model_path' argument is deprecated, please use 'model_paths' in the future.\n",
      "/home/phanim/harshitrawat/mace/mace/calculators/mace.py:166: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using head Default out of ['Default']\n",
      "No dtype selected, switching to float64 to match model dtype.\n",
      "✅ Loaded MACE model on cuda:0\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0006_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0006_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0006_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0006_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0007_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0007_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0007_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0007_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0020_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0020_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0020_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0020_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0024_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0024_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0024_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0024_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0025_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0025_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0025_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0025_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0048_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0048_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0048_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0048_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0051_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0051_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0051_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0051_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0064_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0064_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0064_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0064_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0070_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0070_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0070_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0070_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0079_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0079_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0079_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0079_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0090_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0090_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0090_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0090_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0094_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0094_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0094_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0094_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0104_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0104_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0104_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0104_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0114_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0114_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0114_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0114_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0133_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0133_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0133_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0133_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0162_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0162_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0162_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0162_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0166_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0166_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0166_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0166_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0175_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0175_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0175_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0175_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0179_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0179_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0179_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0179_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0186_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0186_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0186_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0186_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0194_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0194_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0194_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0194_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0195_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0195_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0195_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0195_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0198_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0198_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0198_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T300_0198_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0005_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0005_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0005_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0005_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0019_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0019_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0019_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0019_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0034_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0034_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0034_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0034_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0042_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0042_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0042_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0042_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0077_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0077_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0077_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0077_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0092_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0092_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0092_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0092_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0093_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0093_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0093_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0093_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0096_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0096_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0096_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0096_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0105_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0105_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0105_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0105_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0106_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0106_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0106_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0106_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0107_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0107_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0107_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0107_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0110_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0110_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0110_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0110_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0114_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0114_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0114_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0114_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0132_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0132_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0132_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0132_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0134_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0134_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0134_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0134_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0139_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0139_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0139_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0139_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0145_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0145_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0145_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0145_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0151_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0151_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0151_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0151_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0182_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0182_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0182_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0182_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0189_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0189_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0189_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0189_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0193_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0193_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0193_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_100_slab_heavy_T450_0193_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0004_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0004_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0004_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0004_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0017_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0017_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0017_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0017_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0036_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0036_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0036_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0036_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0062_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0062_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0062_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0062_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0084_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0084_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0084_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0084_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0103_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0103_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0103_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0103_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0104_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0104_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0104_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0104_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0123_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0123_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0123_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0123_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0131_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0131_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0131_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0131_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0145_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0145_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0145_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0145_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0154_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0154_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0154_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0154_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0167_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0167_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0167_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0167_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0170_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0170_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0170_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0170_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0173_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0173_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0173_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0173_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0193_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0193_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0193_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T300_0193_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0015_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0015_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0015_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0015_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0018_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0018_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0018_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0018_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0032_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0032_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0032_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0032_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0036_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0036_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0036_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0036_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0057_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0057_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0057_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0057_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0062_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0062_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0062_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0062_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0065_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0065_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0065_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0065_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0078_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0078_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0078_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0078_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0094_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0094_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0094_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0094_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0097_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0097_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0097_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0097_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0120_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0120_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0120_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0120_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0154_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0154_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0154_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0154_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0160_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0160_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0160_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0160_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0194_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0194_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0194_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0194_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0197_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0197_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0197_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_110_slab_heavy_T450_0197_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0013_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0013_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0013_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0013_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0016_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0016_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0016_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0016_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0028_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0028_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0028_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0028_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0034_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0034_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0034_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0034_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0038_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0038_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0038_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0038_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0042_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0042_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0042_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0042_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0048_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0048_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0048_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0048_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0063_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0063_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0063_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0063_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0065_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0065_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0065_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0065_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0071_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0071_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0071_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0071_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0082_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0082_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0082_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0082_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0097_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0097_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0097_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0097_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0124_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0124_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0124_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0124_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0144_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0144_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0144_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0144_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0150_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0150_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0150_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0150_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0155_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0155_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0155_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0155_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0178_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0178_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0178_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T300_0178_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0010_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0010_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0010_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0010_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0066_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0066_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0066_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0066_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0106_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0106_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0106_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0106_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0119_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0119_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0119_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0119_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0129_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0129_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0129_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0129_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0144_strain+0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0144_strain+0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0144_strain-0.010_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0144_strain-0.015_perturbed.cif\n",
      "✅ cellrelaxed_LLZO_001_Zr_code93_sto__Li_111_slab_heavy_T450_0146_strain+0.010_perturbed.cif\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fname\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.cif\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     37\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, fname)\n\u001b[0;32m---> 38\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mextract_info_from_cif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m — \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36mextract_info_from_cif\u001b[0;34m(cif_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_info_from_cif\u001b[39m(cif_path):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m         atoms \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcif_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         atoms\u001b[38;5;241m.\u001b[39mcalc \u001b[38;5;241m=\u001b[39m calc\n\u001b[1;32m     20\u001b[0m         energy \u001b[38;5;241m=\u001b[39m atoms\u001b[38;5;241m.\u001b[39mget_potential_energy()\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/ase/io/formats.py:815\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, index, format, parallel, do_not_split_by_at_sign, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_iread(filename, index, \u001b[38;5;28mformat\u001b[39m, io, parallel\u001b[38;5;241m=\u001b[39mparallel,\n\u001b[1;32m    813\u001b[0m                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_iread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/ase/parallel.py:305\u001b[0m, in \u001b[0;36mparallel_generator.<locals>.new_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(generator)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_generator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (world\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    302\u001b[0m         args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparallel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;66;03m# Disable:\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m generator(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    306\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m result\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/ase/io/formats.py:881\u001b[0m, in \u001b[0;36m_iread\u001b[0;34m(filename, index, format, io, parallel, full_output, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# Make sure fd is closed in case loop doesn't finish:\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 881\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dct \u001b[38;5;129;01min\u001b[39;00m io\u001b[38;5;241m.\u001b[39mread(fd, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dct, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    883\u001b[0m             dct \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124matoms\u001b[39m\u001b[38;5;124m'\u001b[39m: dct}\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/ase/io/formats.py:639\u001b[0m, in \u001b[0;36mwrap_read_function\u001b[0;34m(read, filename, index, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m read(filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/ase/io/cif.py:661\u001b[0m, in \u001b[0;36mread_cif\u001b[0;34m(fileobj, index, store_tags, primitive_cell, subtrans_included, fractional_occupancies, reader)\u001b[0m\n\u001b[1;32m    650\u001b[0m g \u001b[38;5;241m=\u001b[39m iread_cif(\n\u001b[1;32m    651\u001b[0m     fileobj,\n\u001b[1;32m    652\u001b[0m     index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    657\u001b[0m     reader,\n\u001b[1;32m    658\u001b[0m )\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, (\u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# Return list of atoms\u001b[39;00m\n\u001b[0;32m--> 661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;66;03m# Return single atoms object\u001b[39;00m\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(g)\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/ase/io/cif.py:590\u001b[0m, in \u001b[0;36miread_cif\u001b[0;34m(fileobj, index, store_tags, primitive_cell, subtrans_included, fractional_occupancies, reader)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block\u001b[38;5;241m.\u001b[39mhas_structure():\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m     atoms \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_atoms\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstore_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimitive_cell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubtrans_included\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfractional_occupancies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfractional_occupancies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(atoms)\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m index \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/ase/io/cif.py:486\u001b[0m, in \u001b[0;36mCIFBlock.get_atoms\u001b[0;34m(self, store_tags, primitive_cell, subtrans_included, fractional_occupancies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cell\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    485\u001b[0m     spacegroup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_spacegroup(subtrans_included)\n\u001b[0;32m--> 486\u001b[0m     atoms \u001b[38;5;241m=\u001b[39m \u001b[43mcrystal\u001b[49m\u001b[43m(\u001b[49m\u001b[43munsymmetrized_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mspacegroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspacegroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msetting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspacegroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moccupancies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moccupancies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mprimitive_cell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprimitive_cell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     atoms \u001b[38;5;241m=\u001b[39m unsymmetrized_structure\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/ase/spacegroup/xtal.py:149\u001b[0m, in \u001b[0;36mcrystal\u001b[0;34m(symbols, basis, occupancies, spacegroup, setting, cell, cellpar, ab_normal, a_direction, size, onduplicates, symprec, pbc, primitive_cell, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 occ\u001b[38;5;241m.\u001b[39mupdate({symbols[index_dist]: occupancies[index_dist]})\n\u001b[1;32m    147\u001b[0m         occupancies_dict[\u001b[38;5;28mstr\u001b[39m(index)] \u001b[38;5;241m=\u001b[39m occ\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 149\u001b[0m sites, kinds \u001b[38;5;241m=\u001b[39m \u001b[43msg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequivalent_sites\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43monduplicates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monduplicates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43msymprec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymprec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# this is needed to handle deuterium masses\u001b[39;00m\n\u001b[1;32m    154\u001b[0m masses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/ase/spacegroup/spacegroup.py:475\u001b[0m, in \u001b[0;36mSpacegroup.equivalent_sites\u001b[0;34m(self, scaled_positions, onduplicates, symprec, occupancies)\u001b[0m\n\u001b[1;32m    473\u001b[0m diff \u001b[38;5;241m=\u001b[39m pos \u001b[38;5;241m-\u001b[39m positions0\n\u001b[1;32m    474\u001b[0m diff \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrint(diff)\n\u001b[0;32m--> 475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msymprec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m onduplicates \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeep\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2504\u001b[0m, in \u001b[0;36mall\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_all_dispatcher)\n\u001b[1;32m   2422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2423\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;124;03m    Test whether all array elements along a given axis evaluate to True.\u001b[39;00m\n\u001b[1;32m   2425\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2502\u001b[0m \n\u001b[1;32m   2503\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_and\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from ase.calculators.calculator import CalculatorError\n",
    "from mace.calculators import MACECalculator\n",
    "\n",
    "# === Config ===\n",
    "folder = \"/home/phanim/harshitrawat/summer/md/mdcifs_strained_perturbed_prime\"\n",
    "output_excel = \"/home/phanim/harshitrawat/summer/md/mdinfo_mace_predictions_T3prime.xlsx\"\n",
    "model_path = \"/home/phanim/harshitrawat/summer/checkpoints/mace_T1_finetune_h200_cn10_run-21.model\"\n",
    "\n",
    "# === Load custom MACE model on GPU 0 ===\n",
    "calc = MACECalculator(model_path=model_path, device=\"cuda:0\")\n",
    "print(\"✅ Loaded MACE model on cuda:0\")\n",
    "def extract_info_from_cif(cif_path):\n",
    "    try:\n",
    "        atoms = read(cif_path)\n",
    "        atoms.calc = calc\n",
    "        energy = atoms.get_potential_energy()\n",
    "        forces = atoms.get_forces()\n",
    "        fmax = np.max(np.linalg.norm(forces, axis=1))\n",
    "        stress = atoms.get_stress(voigt=False).tolist()\n",
    "\n",
    "        return {\n",
    "            \"file\": os.path.basename(cif_path),\n",
    "            \"energy_eV\": energy,\n",
    "            \"fmax_eV_per_A\": fmax,\n",
    "            \"stress_tensor\": stress,\n",
    "        }\n",
    "    except (CalculatorError, Exception) as e:\n",
    "        return {\"file\": os.path.basename(cif_path), \"error\": str(e)}\n",
    "\n",
    "results = []\n",
    "for fname in sorted(os.listdir(folder)):\n",
    "    if fname.endswith(\".cif\"):\n",
    "        path = os.path.join(folder, fname)\n",
    "        result = extract_info_from_cif(path)\n",
    "        results.append(result)\n",
    "        print(f\"✅ {fname}\" if \"error\" not in result else f\"❌ {fname} — {result['error']}\")\n",
    "\n",
    "pd.DataFrame(results).to_excel(output_excel, index=False)\n",
    "print(f\"\\n🧾 Saved predictions to: {output_excel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c31d1d9f-8003-47b1-9ad3-367866cc53e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA H200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fefffe-21a0-4953-9cf7-37559ee3a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc620a-0c43-498e-9781-33740a96e80f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU mace_0.3.8)",
   "language": "python",
   "name": "mace_0.3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
