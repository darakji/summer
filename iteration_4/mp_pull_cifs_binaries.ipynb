{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2afaa824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 142 structures from /home/phanim/harshitrawat/summer/replay_data/mp_finetuning-just_to_get_file_comb_142_run-84.xyz.cleaned.xyz\n",
      "\n",
      "Done. Wrote 142 CIFs to: /home/phanim/harshitrawat/summer/replay_data/split_cifs_meta\n",
      "Manifest: /home/phanim/harshitrawat/summer/replay_data/split_cifs_meta/split_manifest.xlsx\n",
      "Manifest JSON: /home/phanim/harshitrawat/summer/replay_data/split_cifs_meta/split_manifest.json\n"
     ]
    }
   ],
   "source": [
    "# pip install ase pandas openpyxl\n",
    "import os, re, json\n",
    "from pathlib import Path\n",
    "from ase.io import read, write\n",
    "import pandas as pd\n",
    "\n",
    "# --------- CONFIG ----------\n",
    "XYZ_PATH = \"/home/phanim/harshitrawat/summer/replay_data/mp_finetuning-just_to_get_file_comb_142_run-84.xyz\"\n",
    "OUT_DIR = None  # None => auto: <same_folder>/split_cifs_meta\n",
    "CLEAN_SUFFIX = \".cleaned.xyz\"  # cleaned copy will be written next to original\n",
    "# ---------------------------\n",
    "\n",
    "p = Path(XYZ_PATH)\n",
    "if OUT_DIR is None:\n",
    "    OUT_DIR = p.parent / \"split_cifs_meta\"\n",
    "OUT_DIR = Path(OUT_DIR)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CLEANED = p.with_suffix(p.suffix + CLEAN_SUFFIX)\n",
    "\n",
    "# ---- 1) CLEAN: convert Fortran 'd' floats to standard ----\n",
    "#   - Replace '1.23d-04' -> '1.23e-04'\n",
    "#   - Replace stray trailing '...0d' -> '...0' (rare but seen)\n",
    "# We apply only inside numeric contexts: digits followed by D/E markers.\n",
    "pat_exp = re.compile(r'(?<=\\d)[dD](?=[+\\-]?\\d)')   # 1.23d-04 -> e\n",
    "pat_trail = re.compile(r'(?<=\\d)[dD](?![+\\-]?\\d)') # 0.00000000d -> (drop)\n",
    "\n",
    "with p.open(\"r\", encoding=\"utf-8\") as fin, CLEANED.open(\"w\", encoding=\"utf-8\") as fout:\n",
    "    for line in fin:\n",
    "        # Convert in header attributes and data rows alike\n",
    "        line = pat_exp.sub(\"e\", line)\n",
    "        line = pat_trail.sub(\"\", line)\n",
    "        fout.write(line)\n",
    "\n",
    "# ---- 2) READ all structures with ASE ----\n",
    "atoms_list = read(str(CLEANED), index=\":\")  # extxyz inferred\n",
    "print(f\"Read {len(atoms_list)} structures from {CLEANED}\")\n",
    "\n",
    "# ---- helpers ----\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def to_builtin(obj):\n",
    "    \"\"\"Recursively convert numpy types to builtin types for JSON.\"\"\"\n",
    "    if obj is None:\n",
    "        return None\n",
    "    if isinstance(obj, (str, bytes)):\n",
    "        return obj.decode() if isinstance(obj, bytes) else obj\n",
    "    if isinstance(obj, (bool, int, float)):\n",
    "        return obj\n",
    "    if isinstance(obj, (np.bool_,)):\n",
    "        return bool(obj)\n",
    "    if isinstance(obj, (np.integer,)):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, (np.floating,)):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [to_builtin(x) for x in obj]\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): to_builtin(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    # last resort: stringify\n",
    "    return str(obj)\n",
    "\n",
    "def safe_formula(atoms):\n",
    "    \"\"\"Try reduced empirical; fallback to counted formula like Li2O.\"\"\"\n",
    "    try:\n",
    "        f = atoms.get_chemical_formula(mode=\"reduce\", empirical=True)\n",
    "        if f:\n",
    "            return f\n",
    "    except Exception:\n",
    "        pass\n",
    "    syms = atoms.get_chemical_symbols()\n",
    "    c = Counter(syms)\n",
    "    # order: simple Hill-ish for inorganic (C/H first not relevant) → alphabetical\n",
    "    parts = []\n",
    "    for el in sorted(c.keys()):\n",
    "        n = c[el]\n",
    "        parts.append(el if n == 1 else f\"{el}{n}\")\n",
    "    return \"\".join(parts) if parts else \"UNKNOWN\"\n",
    "\n",
    "# ---- 3) SPLIT to CIFs + MANIFEST ----\n",
    "rows = []\n",
    "for i, atoms in enumerate(atoms_list):\n",
    "    info = atoms.info or {}\n",
    "\n",
    "    mp_id = info.get(\"mp_id\")\n",
    "    if mp_id is None or str(mp_id).strip() == \"\":\n",
    "        mp_id = safe_formula(atoms) or f\"noid_{i}\"\n",
    "    else:\n",
    "        mp_id = str(mp_id)\n",
    "\n",
    "    # energy per atom may come as string/np types\n",
    "    epa = info.get(\"energy_per_atom\", None)\n",
    "    try:\n",
    "        epa = float(epa)\n",
    "    except Exception:\n",
    "        epa = None\n",
    "\n",
    "    # filename\n",
    "    if epa is not None:\n",
    "        fname = f\"{mp_id}__Epa{epa:.3f}eV.cif\"\n",
    "    else:\n",
    "        fname = f\"{mp_id}__struct_{i:03d}.cif\"\n",
    "    fname = fname.replace(\" \", \"_\")\n",
    "    cif_path = OUT_DIR / fname\n",
    "\n",
    "    # write CIF\n",
    "    write(str(cif_path), atoms)\n",
    "\n",
    "    # build manifest row (flatten + convert types)\n",
    "    flat = {\n",
    "        \"index\": int(i),\n",
    "        \"cif_path\": str(cif_path),\n",
    "        \"formula\": safe_formula(atoms),\n",
    "        \"natoms\": int(len(atoms)),\n",
    "    }\n",
    "    for k, v in (info.items()):\n",
    "        flat[str(k)] = to_builtin(v)\n",
    "\n",
    "    rows.append(flat)\n",
    "\n",
    "# ---- 4) Save manifest (JSON + Excel) ----\n",
    "df = pd.DataFrame(rows)\n",
    "df_path_xlsx = OUT_DIR / \"split_manifest.xlsx\"\n",
    "df_path_json = OUT_DIR / \"split_manifest.json\"\n",
    "\n",
    "# Excel: pandas will coerce lists to strings automatically via openpyxl\n",
    "df.to_excel(df_path_xlsx, index=False)\n",
    "\n",
    "# JSON: everything converted to builtin types\n",
    "with open(df_path_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump([to_builtin(r) for r in rows], f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nDone. Wrote {len(rows)} CIFs to: {OUT_DIR}\")\n",
    "print(f\"Manifest: {df_path_xlsx}\")\n",
    "print(f\"Manifest JSON: {df_path_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c00e329a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHGNet v0.3.0 initialized with 412,525 parameters\n",
      "CHGNet will run on cpu\n",
      "Found 142 CIFs in /home/phanim/harshitrawat/summer/replay_data/split_cifs_meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling with CHGNet:   5%|▍         | 7/142 [00:00<00:17,  7.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling with CHGNet: 100%|██████████| 142/142 [00:22<00:00,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DONE ===\n",
      "EXTXYZ : /home/phanim/harshitrawat/summer/replay_data/replay_labeled_by_chgnet.extxyz\n",
      "JSON   : /home/phanim/harshitrawat/summer/replay_data/replay_labeled_by_chgnet.json\n",
      "Frames : 142 / 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Label all CIFs in IN_DIR with CHGNet (single-point) and export:\n",
    "  1) Combined EXTXYZ with per-frame metadata (CHGNet labels)\n",
    "  2) JSON manifest with the same fields\n",
    "\n",
    "Fixes & robustness:\n",
    "- Uses at.get_volume() (avoids .volume() callables)\n",
    "- Keeps 'stress' as numpy (3x3) for EXTXYZ writer; converts to list only for JSON\n",
    "- Detaches calculator before writing to avoid key collisions\n",
    "- JSON-serializes numpy scalars/arrays recursively\n",
    "- Safe fallback formula if ASE can't compute reduced empirical\n",
    "- Skips failing frames but continues\n",
    "\n",
    "Customize IN_DIR/OUT paths below.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ase.io import read, write\n",
    "from ase import Atoms\n",
    "\n",
    "# === Your input directory with per-structure CIFs ===\n",
    "IN_DIR = Path(\"/home/phanim/harshitrawat/summer/replay_data/split_cifs_meta\")\n",
    "\n",
    "# === Outputs (written next to IN_DIR) ===\n",
    "OUT_EXTXYZ = IN_DIR.parent / \"replay_labeled_by_chgnet.extxyz\"\n",
    "OUT_JSON   = IN_DIR.parent / \"replay_labeled_by_chgnet.json\"\n",
    "\n",
    "# === CHGNet import (your env preference) ===\n",
    "# User preference from memory: import from chgnet.model.dynamics\n",
    "from chgnet.model.dynamics import CHGNetCalculator\n",
    "\n",
    "# ---- config ----\n",
    "DEVICE = \"cuda\"   # will auto-fallback to cpu if CUDA not available\n",
    "HEAD_NAME = \"chgnet_universal\"\n",
    "CONFIG_WEIGHT = 1.0\n",
    "PRETRAINED = True\n",
    "CALC_ID_START = 0\n",
    "IONIC_STEP = 0\n",
    "VERBOSE = True\n",
    "# ----------------\n",
    "\n",
    "\n",
    "def to_builtin(x):\n",
    "    \"\"\"Recursively cast numpy types to Python builtins (JSON-safe).\"\"\"\n",
    "    if x is None or isinstance(x, (bool, int, float, str)):\n",
    "        return x\n",
    "    if isinstance(x, bytes):\n",
    "        return x.decode(errors=\"ignore\")\n",
    "    if isinstance(x, (np.bool_,)):\n",
    "        return bool(x)\n",
    "    if isinstance(x, (np.integer,)):\n",
    "        return int(x)\n",
    "    if isinstance(x, (np.floating,)):\n",
    "        return float(x)\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return [to_builtin(v) for v in x]\n",
    "    if isinstance(x, dict):\n",
    "        return {str(k): to_builtin(v) for k, v in x.items()}\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.tolist()\n",
    "    return str(x)\n",
    "\n",
    "\n",
    "def safe_formula(atoms: Atoms) -> str:\n",
    "    \"\"\"Try reduced empirical; fallback to alphabetical counted formula.\"\"\"\n",
    "    try:\n",
    "        f = atoms.get_chemical_formula(mode=\"reduce\", empirical=True)\n",
    "        if f:\n",
    "            return f\n",
    "    except Exception:\n",
    "        pass\n",
    "    syms = atoms.get_chemical_symbols()\n",
    "    c = Counter(syms)\n",
    "    parts = []\n",
    "    for el in sorted(c.keys()):\n",
    "        n = c[el]\n",
    "        parts.append(el if n == 1 else f\"{el}{n}\")\n",
    "    return \"\".join(parts) if parts else \"UNKNOWN\"\n",
    "\n",
    "\n",
    "def atoms_to_labels(at: Atoms, calc_id: int):\n",
    "    \"\"\"\n",
    "    Run CHGNet single-point and return:\n",
    "      info  : dict with frame-level metadata (numpy stress kept as 3x3 array)\n",
    "      forces: (N,3) numpy\n",
    "      mag   : (N,) numpy (zeros if absent)\n",
    "      stress: (3,3) numpy\n",
    "    \"\"\"\n",
    "    # Potential energy (eV)\n",
    "    energy = float(at.get_potential_energy(apply_constraint=False))\n",
    "    natoms = len(at)\n",
    "    epa    = energy / natoms if natoms > 0 else float(\"nan\")\n",
    "\n",
    "    # Forces (eV/Å)\n",
    "    forces = at.get_forces(apply_constraint=False)  # (N,3) numpy\n",
    "\n",
    "    # Stress (eV/Å^3) as (3,3) numpy; guard for zero-volume / non-PBC\n",
    "    try:\n",
    "        vol = at.get_volume()\n",
    "        if vol and vol > 1e-12 and any(at.get_pbc()):\n",
    "            stress_3x3 = at.get_stress(voigt=False)  # (3,3)\n",
    "        else:\n",
    "            stress_3x3 = np.zeros((3, 3), float)\n",
    "    except Exception:\n",
    "        stress_3x3 = np.zeros((3, 3), float)\n",
    "\n",
    "    # Magmoms (per-atom)\n",
    "    if \"initial_magmoms\" in at.arrays:\n",
    "        mag = np.array(at.get_initial_magnetic_moments(), dtype=float)\n",
    "    elif \"magmoms\" in at.arrays:\n",
    "        mag = np.array(at.arrays[\"magmoms\"], dtype=float)\n",
    "    else:\n",
    "        mag = np.zeros((natoms,), dtype=float)\n",
    "\n",
    "    # Frame-level info (keep stress as numpy array for writer)\n",
    "    info: Dict[str, Any] = {\n",
    "        \"energy\": energy,\n",
    "        \"energy_per_atom\": epa,\n",
    "        \"ef_per_atom\": epa,\n",
    "        \"ef_per_atom_relaxed\": epa,\n",
    "        \"e_per_atom_relaxed\": epa,\n",
    "        \"bandgap\": None,  # CHGNet doesn't output this; kept for schema compat\n",
    "        \"pretrained\": PRETRAINED,\n",
    "        \"config_weight\": CONFIG_WEIGHT,\n",
    "        \"head\": HEAD_NAME,\n",
    "        \"calc_id\": int(calc_id),\n",
    "        \"ionic_step\": int(IONIC_STEP),\n",
    "        \"stress\": np.array(stress_3x3, dtype=float),  # IMPORTANT: numpy for extxyz\n",
    "        \"pbc\": \" \".join(\"T\" if b else \"F\" for b in at.get_pbc()),\n",
    "        \"REF_energy\": energy,\n",
    "        \"formula\": safe_formula(at),\n",
    "        \"natoms\": natoms,\n",
    "    }\n",
    "    return info, forces, mag, stress_3x3\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Calculator\n",
    "    try:\n",
    "        calc = CHGNetCalculator(device=DEVICE)\n",
    "    except Exception:\n",
    "        calc = CHGNetCalculator(device=\"cpu\")\n",
    "        if VERBOSE:\n",
    "            print(\"CHGNet will run on cpu\")\n",
    "\n",
    "    # Collect CIFs\n",
    "    cif_paths: List[Path] = sorted([p for p in IN_DIR.glob(\"*.cif\") if p.is_file()])\n",
    "    print(f\"Found {len(cif_paths)} CIFs in {IN_DIR}\")\n",
    "\n",
    "    frames: List[Atoms] = []\n",
    "    manifest: List[Dict[str, Any]] = []\n",
    "    calc_id = CALC_ID_START\n",
    "\n",
    "    for path in tqdm(cif_paths, desc=\"Labeling with CHGNet\"):\n",
    "        try:\n",
    "            at: Atoms = read(path)\n",
    "\n",
    "            # Ensure periodic for solids if the cell has volume\n",
    "            try:\n",
    "                vol = at.get_volume()\n",
    "                if vol and vol > 1e-12:\n",
    "                    at.set_pbc([True, True, True])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Run single-point\n",
    "            at.calc = calc\n",
    "            info, forces, mag, stress = atoms_to_labels(at, calc_id=calc_id)\n",
    "\n",
    "            # Embed arrays/info for EXTXYZ\n",
    "            at.info.update(info)                                   # stress kept as numpy (3,3)\n",
    "            at.arrays[\"forces\"] = np.array(forces, dtype=float)\n",
    "            at.arrays[\"magmoms\"] = np.array(mag, dtype=float)\n",
    "\n",
    "            # Detach calculator to avoid writer key collisions\n",
    "            at.calc = None\n",
    "            frames.append(at)\n",
    "\n",
    "            # Manifest row (JSON builtins; convert stress to list here)\n",
    "            row = {k: v for k, v in info.items() if k != \"stress\"}\n",
    "            row[\"stress\"] = np.asarray(info[\"stress\"]).tolist()\n",
    "            row[\"filename\"] = path.name\n",
    "            row[\"elements\"] = \"-\".join(sorted(set(at.get_chemical_symbols())))\n",
    "            manifest.append(to_builtin(row))\n",
    "\n",
    "            calc_id += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed on {path.name}: {e}\")\n",
    "\n",
    "    # Write outputs\n",
    "    if frames:\n",
    "        write(str(OUT_EXTXYZ), frames, format=\"extxyz\")\n",
    "    with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump([to_builtin(r) for r in manifest], f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"\\n=== DONE ===\")\n",
    "    print(f\"EXTXYZ : {OUT_EXTXYZ}\")\n",
    "    print(f\"JSON   : {OUT_JSON}\")\n",
    "    print(f\"Frames : {len(frames)} / {len(cif_paths)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf7230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replay frames: 142\n",
      "T3 frames    : 1612\n",
      "Done. Wrote 1754 frames to /home/phanim/harshitrawat/summer/T1_T2_T3_data/T3withreplay_chgnet_labeled.extxyz\n"
     ]
    }
   ],
   "source": [
    "from ase.io import read, write\n",
    "\n",
    "# Input files\n",
    "replay_path = \"/home/phanim/harshitrawat/summer/replay_data/replay_labeled_by_chgnet.extxyz\"\n",
    "t3_path     = \"/home/phanim/harshitrawat/summer/T1_T2_T3_data/T3_chgnet_labeled.extxyz\"\n",
    "\n",
    "# Output file\n",
    "out_path    = \"/home/phanim/harshitrawat/summer/T1_T2_T3_data/T3withreplay_chgnet_labeled.extxyz\"\n",
    "\n",
    "# Read all frames from both extxyz files\n",
    "replay_frames = read(replay_path, index=\":\")\n",
    "t3_frames     = read(t3_path, index=\":\")\n",
    "\n",
    "print(f\"Replay frames: {len(replay_frames)}\")\n",
    "print(f\"T3 frames    : {len(t3_frames)}\")\n",
    "\n",
    "# Concatenate\n",
    "all_frames = t3_frames + replay_frames\n",
    "\n",
    "# Write combined file\n",
    "write(out_path, all_frames, format=\"extxyz\")\n",
    "\n",
    "print(f\"Done. Wrote {len(all_frames)} frames to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad129e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replay frames: 142\n",
      "T3 frames    : 705\n",
      "Done. Wrote 847 frames to /home/phanim/harshitrawat/summer/T1_T2_T3_data/T2withreplay_chgnet_labeled.extxyz\n"
     ]
    }
   ],
   "source": [
    "from ase.io import read, write\n",
    "\n",
    "# Input files\n",
    "replay_path = \"/home/phanim/harshitrawat/summer/replay_data/replay_labeled_by_chgnet.extxyz\"\n",
    "t3_path     = \"/home/phanim/harshitrawat/summer/T1_T2_T3_data/T2_chgnet_labeled.extxyz\"\n",
    "\n",
    "# Output file\n",
    "out_path    = \"/home/phanim/harshitrawat/summer/T1_T2_T3_data/T2withreplay_chgnet_labeled.extxyz\"\n",
    "\n",
    "# Read all frames from both extxyz files\n",
    "replay_frames = read(replay_path, index=\":\")\n",
    "t3_frames     = read(t3_path, index=\":\")\n",
    "\n",
    "print(f\"Replay frames: {len(replay_frames)}\")\n",
    "print(f\"T3 frames    : {len(t3_frames)}\")\n",
    "\n",
    "# Concatenate\n",
    "all_frames = t3_frames + replay_frames\n",
    "\n",
    "# Write combined file\n",
    "write(out_path, all_frames, format=\"extxyz\")\n",
    "\n",
    "print(f\"Done. Wrote {len(all_frames)} frames to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94e1715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mace_0.3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
