{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29be04a-668b-4434-9efb-691c88850842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You loaded a model directly. Try:\n",
      "model = ckpt; print(dir(model))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3607249/1526315102.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"/home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model\", map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ckpt = torch.load(\"/home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model\", map_location=\"cpu\")\n",
    "if isinstance(ckpt, dict):\n",
    "    print(\"Checkpoint keys:\")\n",
    "    print(ckpt.keys())\n",
    "else:\n",
    "    print(\"You loaded a model directly. Try:\")\n",
    "    print(\"model = ckpt; print(dir(model))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ce27f46-0d98-4bd5-b72d-8d5c90565720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__e3nn_compile_mode__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'atomic_energies_fn', 'atomic_numbers', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'interactions', 'ipu', 'load_state_dict', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'node_embedding', 'num_interactions', 'parameters', 'products', 'r_max', 'radial_embedding', 'readouts', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'scale_shift', 'set_extra_state', 'set_submodule', 'share_memory', 'spherical_harmonics', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "model = ckpt; print(dir(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3010753-e5d0-4a50-b085-c70e9f441586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atomic_energies_fn.atomic_energies tensor([-3.6672e+00, -1.3321e+00, -3.4821e+00, -4.7367e+00, -7.7249e+00,\n",
      "        -8.4056e+00, -7.3601e+00, -7.2846e+00, -4.8965e+00,  1.3918e-12,\n",
      "        -2.7594e+00, -2.8140e+00, -4.8469e+00, -7.6948e+00, -6.9633e+00,\n",
      "        -4.6726e+00, -2.8117e+00, -6.2595e-02, -2.6176e+00, -5.3905e+00,\n",
      "        -7.8858e+00, -1.0268e+01, -8.6651e+00, -9.2331e+00, -8.3050e+00,\n",
      "        -7.0490e+00, -5.5774e+00, -5.1727e+00, -3.2521e+00, -1.2902e+00,\n",
      "        -3.5271e+00, -4.7085e+00, -3.9765e+00, -3.8862e+00, -2.5185e+00,\n",
      "         6.7669e+00, -2.5635e+00, -4.9380e+00, -1.0150e+01, -1.1847e+01,\n",
      "        -1.2139e+01, -8.7917e+00, -8.7869e+00, -7.7809e+00, -6.8500e+00,\n",
      "        -4.8910e+00, -2.0634e+00, -6.3957e-01, -2.7887e+00, -3.8186e+00,\n",
      "        -3.5871e+00, -2.8804e+00, -1.6356e+00,  9.8467e+00, -2.7653e+00,\n",
      "        -4.9910e+00, -8.9337e+00, -8.7356e+00, -8.0190e+00, -8.2515e+00,\n",
      "        -7.5917e+00, -8.1697e+00, -1.3593e+01, -1.8518e+01, -7.6474e+00,\n",
      "        -8.1230e+00, -7.6078e+00, -6.8503e+00, -7.8269e+00, -3.5848e+00,\n",
      "        -7.4554e+00, -1.2796e+01, -1.4108e+01, -9.3549e+00, -1.1388e+01,\n",
      "        -9.6219e+00, -7.3244e+00, -5.3047e+00, -2.3801e+00,  2.4949e-01,\n",
      "        -2.3240e+00, -3.7300e+00, -3.4388e+00, -5.0629e+00, -1.1025e+01,\n",
      "        -1.2266e+01, -1.3856e+01, -1.4933e+01, -1.5283e+01],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "\n",
    "for k in state_dict.keys():\n",
    "    if \"atomic_energies\" in k.lower() or \"e0\" in k.lower():\n",
    "        print(k, state_dict[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f1c454a-73fe-4996-a6d8-b5118837b45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
      "        73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 91, 92, 93, 94])\n"
     ]
    }
   ],
   "source": [
    "print(model.atomic_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "480b9d87-8fb0-43a8-a546-2cb9d5df5a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    mace_T1_finetune_scripted \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --multiheads_finetuning \\\n",
      "    True \\\n",
      "    --atomic_numbers \\\n",
      "    [3,8,40,57] \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz \\\n",
      "    --valid_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz \\\n",
      "    --batch_size \\\n",
      "    2 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --valid_fraction \\\n",
      "    0.1 \\\n",
      "    --ema_decay \\\n",
      "    0.99999 \\\n",
      "    --lr \\\n",
      "    0.0001 \\\n",
      "    --num_samples_pt \\\n",
      "    100000 \\\n",
      "    --forces_weight \\\n",
      "    10 \\\n",
      "    --energy_weight \\\n",
      "    1 \\\n",
      "    --loss \\\n",
      "    universal \\\n",
      "    --device \\\n",
      "    cuda \\\n",
      "    --max_num_epochs \\\n",
      "    20 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --restart_latest \\\n",
      "    --E0s \\\n",
      "    average \\\n",
      "    --seed \\\n",
      "    42\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 09:02:47.075 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-07-25 09:02:47.075 INFO: MACE version: 0.3.13\n",
      "2025-07-25 09:02:47.620 INFO: CUDA version: 12.6, CUDA device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:157: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 09:02:48.107 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-07-25 09:02:48.108 WARNING: Using multiheads finetuning with a foundation model that is not a Materials Project model, need to provied a path to a pretraining file with --pt_train_file.\n",
      "2025-07-25 09:02:48.108 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-07-25 09:02:48.108 INFO: Using heads: ['Default']\n",
      "2025-07-25 09:02:48.108 INFO: Using the key specifications to parse data:\n",
      "2025-07-25 09:02:48.108 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-07-25 09:02:48.108 INFO: =============    Processing head Default     ===========\n",
      "2025-07-25 09:03:09.263 INFO: Training set 1/1 [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 09:03:09.280 INFO: Total Training set [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 09:03:11.914 INFO: Validation set 1/1 [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 09:03:11.916 INFO: Total Validation set [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 09:03:11.916 INFO: Total number of configurations: train=6337, valid=705, tests=[],\n",
      "2025-07-25 09:03:11.916 INFO: Using atomic numbers from command line argument\n",
      "2025-07-25 09:03:11.916 INFO: Atomic Numbers used: [3, 8, 40, 57]\n",
      "2025-07-25 09:03:11.917 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-07-25 09:03:11.917 INFO: Computing average Atomic Energies using least squares regression\n",
      "2025-07-25 09:03:11.968 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\n",
      "2025-07-25 09:03:11.968 INFO: Processing datasets for head 'Default'\n",
      "2025-07-25 09:04:34.906 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-07-25 09:04:44.320 INFO: Combining 1 list datasets for head 'Default_valid'\n",
      "2025-07-25 09:04:44.320 INFO: Combined validation datasets for Default\n",
      "2025-07-25 09:04:44.320 INFO: Head 'Default' training dataset size: 6337\n",
      "2025-07-25 09:04:44.320 INFO: Computing average number of neighbors\n",
      "2025-07-25 09:04:51.976 INFO: Average number of neighbors: 68.51557639403025\n",
      "2025-07-25 09:04:51.977 INFO: During training the following quantities will be reported: energy, forces, stress\n",
      "2025-07-25 09:04:51.977 INFO: ===========MODEL DETAILS===========\n",
      "2025-07-25 09:04:58.860 INFO: Loading FOUNDATION model\n",
      "2025-07-25 09:04:58.862 INFO: Using filtered elements: [3, 8, 40, 57]\n",
      "2025-07-25 09:04:58.862 INFO: Model configuration extracted from foundation model\n",
      "2025-07-25 09:04:58.862 INFO: Using universal loss function for fine-tuning\n",
      "2025-07-25 09:04:58.862 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-07-25 09:04:58.862 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-07-25 09:04:58.862 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-07-25 09:04:58.862 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 09:05:00.267 INFO: Total number of parameters: 894362\n",
      "2025-07-25 09:05:00.267 INFO: \n",
      "2025-07-25 09:05:00.267 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-07-25 09:05:00.267 INFO: Using ADAM as parameter optimizer\n",
      "2025-07-25 09:05:00.267 INFO: Batch size: 2\n",
      "2025-07-25 09:05:00.267 INFO: Number of gradient updates: 63370\n",
      "2025-07-25 09:05:00.267 INFO: Learning rate: 0.0001, weight decay: 5e-07\n",
      "2025-07-25 09:05:00.267 INFO: UniversalLoss(energy_weight=1.000, forces_weight=10.000, stress_weight=1.000)\n",
      "2025-07-25 09:05:00.269 WARNING: No SWA checkpoint found, while SWA is enabled. Compare the swa_start parameter and the latest checkpoint.\n",
      "2025-07-25 09:05:00.270 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_scripted_run-42_epoch-13.pt\n",
      "2025-07-25 09:05:00.556 INFO: Using gradient clipping with tolerance=10.000\n",
      "2025-07-25 09:05:00.556 INFO: \n",
      "2025-07-25 09:05:00.556 INFO: ===========TRAINING===========\n",
      "2025-07-25 09:05:00.556 INFO: Started training, reporting errors on validation set\n",
      "2025-07-25 09:05:00.556 INFO: Loss metrics on validation set\n",
      "2025-07-25 09:06:30.807 INFO: Initial: head: Default, loss=0.00794118, RMSE_E_per_atom=  487.84 meV, RMSE_F=   84.18 meV / A, RMSE_stress=    4.87 meV / A^3\n",
      "2025-07-25 09:40:29.235 INFO: Epoch 13: head: Default, loss=0.00793038, RMSE_E_per_atom=  499.21 meV, RMSE_F=   83.93 meV / A, RMSE_stress=    4.85 meV / A^3\n",
      "2025-07-25 10:14:24.086 INFO: Epoch 14: head: Default, loss=0.00788934, RMSE_E_per_atom=  479.05 meV, RMSE_F=   83.68 meV / A, RMSE_stress=    4.83 meV / A^3\n",
      "2025-07-25 10:48:18.978 INFO: Epoch 15: head: Default, loss=0.00787378, RMSE_E_per_atom=  494.62 meV, RMSE_F=   83.45 meV / A, RMSE_stress=    4.81 meV / A^3\n",
      "2025-07-25 11:22:14.557 INFO: Epoch 16: head: Default, loss=0.00785254, RMSE_E_per_atom=  495.51 meV, RMSE_F=   83.23 meV / A, RMSE_stress=    4.80 meV / A^3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 49\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_run_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--name\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_T1_finetune_scripted\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--seed\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m42\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     46\u001b[0m ]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd), file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m---> 49\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    os.environ[\"PYTHONPATH\"] = \"/home/phanim/harshitrawat/mace/mace\"\n",
    "\n",
    "    # ——— Training command ———\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        \"--name\",              \"mace_T1_finetune_scripted\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "        \"--multiheads_finetuning\", \"True\",\n",
    "        \"--atomic_numbers\",    \"[3,8,40,57]\",\n",
    "\n",
    "        \"--train_file\",        \"/home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz\",\n",
    "        \"--valid_file\",        \"/home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz\",\n",
    "\n",
    "        \"--batch_size\",        \"2\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "        \"--valid_fraction\",    \"0.1\",\n",
    "\n",
    "        \"--ema_decay\",         \"0.99999\",\n",
    "        \"--lr\",                \"0.0001\",\n",
    "        \"--num_samples_pt\",    \"100000\",\n",
    "\n",
    "        \"--forces_weight\",     \"10\",\n",
    "        \"--energy_weight\",     \"1\",\n",
    "        \"--loss\",              \"universal\",\n",
    "\n",
    "        \"--device\",            \"cuda\",\n",
    "        \"--max_num_epochs\",    \"20\",\n",
    "        \"--r_max\",             \"5.0\",\n",
    "\n",
    "        \"--restart_latest\",\n",
    "        \"--E0s\",               \"average\",\n",
    "\n",
    "        \"--seed\",              \"42\",\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35de9ee8-06a4-44ff-a4ce-a6deaa90a997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    mace_T1_finetune_scripted \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --multiheads_finetuning \\\n",
      "    True \\\n",
      "    --atomic_numbers \\\n",
      "    [3,8,40,57] \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz \\\n",
      "    --valid_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz \\\n",
      "    --batch_size \\\n",
      "    2 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --valid_fraction \\\n",
      "    0.1 \\\n",
      "    --ema_decay \\\n",
      "    0.9999 \\\n",
      "    --lr \\\n",
      "    0.001 \\\n",
      "    --num_samples_pt \\\n",
      "    100000 \\\n",
      "    --clip_grad \\\n",
      "    100 \\\n",
      "    --weight_decay \\\n",
      "    1e-8 \\\n",
      "    --scheduler_patience \\\n",
      "    3 \\\n",
      "    --forces_weight \\\n",
      "    30 \\\n",
      "    --energy_weight \\\n",
      "    100 \\\n",
      "    --loss \\\n",
      "    universal \\\n",
      "    --device \\\n",
      "    cuda \\\n",
      "    --max_num_epochs \\\n",
      "    20 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --restart_latest \\\n",
      "    --E0s \\\n",
      "    average \\\n",
      "    --seed \\\n",
      "    42\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 11:36:05.631 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-07-25 11:36:05.632 INFO: MACE version: 0.3.13\n",
      "2025-07-25 11:36:06.278 INFO: CUDA version: 12.6, CUDA device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:157: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 11:36:07.138 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-07-25 11:36:07.139 WARNING: Using multiheads finetuning with a foundation model that is not a Materials Project model, need to provied a path to a pretraining file with --pt_train_file.\n",
      "2025-07-25 11:36:07.139 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-07-25 11:36:07.140 INFO: Using heads: ['Default']\n",
      "2025-07-25 11:36:07.140 INFO: Using the key specifications to parse data:\n",
      "2025-07-25 11:36:07.140 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-07-25 11:36:07.140 INFO: =============    Processing head Default     ===========\n",
      "2025-07-25 11:36:28.495 INFO: Training set 1/1 [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 11:36:28.513 INFO: Total Training set [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 11:36:31.170 INFO: Validation set 1/1 [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 11:36:31.172 INFO: Total Validation set [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 11:36:31.172 INFO: Total number of configurations: train=6337, valid=705, tests=[],\n",
      "2025-07-25 11:36:31.172 INFO: Using atomic numbers from command line argument\n",
      "2025-07-25 11:36:31.173 INFO: Atomic Numbers used: [3, 8, 40, 57]\n",
      "2025-07-25 11:36:31.173 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-07-25 11:36:31.173 INFO: Computing average Atomic Energies using least squares regression\n",
      "2025-07-25 11:36:31.226 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\n",
      "2025-07-25 11:36:31.226 INFO: Processing datasets for head 'Default'\n",
      "2025-07-25 11:37:54.804 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-07-25 11:38:04.327 INFO: Combining 1 list datasets for head 'Default_valid'\n",
      "2025-07-25 11:38:04.327 INFO: Combined validation datasets for Default\n",
      "2025-07-25 11:38:04.327 INFO: Head 'Default' training dataset size: 6337\n",
      "2025-07-25 11:38:04.328 INFO: Computing average number of neighbors\n",
      "2025-07-25 11:38:12.174 INFO: Average number of neighbors: 68.51557639403025\n",
      "2025-07-25 11:38:12.176 INFO: During training the following quantities will be reported: energy, forces, stress\n",
      "2025-07-25 11:38:12.176 INFO: ===========MODEL DETAILS===========\n",
      "2025-07-25 11:38:19.146 INFO: Loading FOUNDATION model\n",
      "2025-07-25 11:38:19.148 INFO: Using filtered elements: [3, 8, 40, 57]\n",
      "2025-07-25 11:38:19.148 INFO: Model configuration extracted from foundation model\n",
      "2025-07-25 11:38:19.148 INFO: Using universal loss function for fine-tuning\n",
      "2025-07-25 11:38:19.148 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-07-25 11:38:19.148 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-07-25 11:38:19.148 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-07-25 11:38:19.148 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 11:38:20.504 INFO: Total number of parameters: 894362\n",
      "2025-07-25 11:38:20.505 INFO: \n",
      "2025-07-25 11:38:20.505 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-07-25 11:38:20.505 INFO: Using ADAM as parameter optimizer\n",
      "2025-07-25 11:38:20.505 INFO: Batch size: 2\n",
      "2025-07-25 11:38:20.505 INFO: Number of gradient updates: 63370\n",
      "2025-07-25 11:38:20.505 INFO: Learning rate: 0.001, weight decay: 1e-08\n",
      "2025-07-25 11:38:20.505 INFO: UniversalLoss(energy_weight=100.000, forces_weight=30.000, stress_weight=1.000)\n",
      "2025-07-25 11:38:20.524 WARNING: No SWA checkpoint found, while SWA is enabled. Compare the swa_start parameter and the latest checkpoint.\n",
      "2025-07-25 11:38:20.525 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_scripted_run-42_epoch-16.pt\n",
      "2025-07-25 11:38:20.562 INFO: Using gradient clipping with tolerance=100.000\n",
      "2025-07-25 11:38:20.562 INFO: \n",
      "2025-07-25 11:38:20.562 INFO: ===========TRAINING===========\n",
      "2025-07-25 11:38:20.562 INFO: Started training, reporting errors on validation set\n",
      "2025-07-25 11:38:20.562 INFO: Loss metrics on validation set\n",
      "2025-07-25 11:39:50.297 INFO: Initial: head: Default, loss=0.35828787, RMSE_E_per_atom=  495.51 meV, RMSE_F=   83.23 meV / A, RMSE_stress=    4.80 meV / A^3\n",
      "2025-07-25 12:13:48.864 INFO: Epoch 16: head: Default, loss=0.31850428, RMSE_E_per_atom=  439.86 meV, RMSE_F=   84.37 meV / A, RMSE_stress=    6.12 meV / A^3\n",
      "2025-07-25 12:47:44.686 INFO: Epoch 17: head: Default, loss=0.26792789, RMSE_E_per_atom=  367.54 meV, RMSE_F=   84.06 meV / A, RMSE_stress=    5.26 meV / A^3\n",
      "2025-07-25 13:21:39.622 INFO: Epoch 18: head: Default, loss=0.56962896, RMSE_E_per_atom=  617.63 meV, RMSE_F=   85.06 meV / A, RMSE_stress=    5.35 meV / A^3\n",
      "2025-07-25 13:55:38.946 INFO: Epoch 19: head: Default, loss=0.20694374, RMSE_E_per_atom=  231.34 meV, RMSE_F=   83.79 meV / A, RMSE_stress=    5.33 meV / A^3\n",
      "2025-07-25 13:55:39.079 INFO: Training complete\n",
      "2025-07-25 13:55:39.079 INFO: \n",
      "2025-07-25 13:55:39.079 INFO: ===========RESULTS===========\n",
      "2025-07-25 13:55:39.082 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_scripted_run-42_epoch-19.pt\n",
      "2025-07-25 13:55:39.116 INFO: Loaded Stage one model from epoch 19 for evaluation\n",
      "2025-07-25 13:55:39.116 INFO: Saving model to checkpoints/mace_T1_finetune_scripted_run-42.model\n",
      "2025-07-25 13:55:39.366 INFO: Compiling model, saving metadata to mace_T1_finetune_scripted_compiled.model\n",
      "2025-07-25 13:55:39.956 INFO: Computing metrics for training, validation, and test sets\n",
      "2025-07-25 13:55:39.957 INFO: Skipping evaluation for heads: ['pt_head']\n",
      "2025-07-25 13:55:39.957 INFO: Evaluating train_Default ...\n",
      "2025-07-25 14:10:28.513 INFO: Evaluating valid_Default ...\n",
      "2025-07-25 14:11:56.393 INFO: Error-table on TRAIN and VALID:\n",
      "+---------------+---------------------+------------------+-------------------+---------------------------------------+\n",
      "|  config_type  | RMSE E / meV / atom | RMSE F / meV / A | relative F RMSE % | RMSE Stress (Virials) / meV / A (A^3) |\n",
      "+---------------+---------------------+------------------+-------------------+---------------------------------------+\n",
      "| train_Default |          230.0      |         85.4     |         24.79     |                     5.7               |\n",
      "| valid_Default |          231.3      |         83.8     |         24.38     |                     5.3               |\n",
      "+---------------+---------------------+------------------+-------------------+---------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/bin/mace_run_train\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m75\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mrun\u001b[0m\u001b[1;31m(args)\u001b[0m\n",
      "    \u001b[31m~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m994\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mplotter.plot\u001b[0m\u001b[1;31m(epoch, model_to_evaluate, rank)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/visualise_train.py\"\u001b[0m, line \u001b[35m124\u001b[0m, in \u001b[35mplot\u001b[0m\n",
      "    train_valid_dict = model_inference(\n",
      "        self.train_valid_data,\n",
      "    ...<3 lines>...\n",
      "        self.distributed,\n",
      "    )\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/visualise_train.py\"\u001b[0m, line \u001b[35m462\u001b[0m, in \u001b[35mmodel_inference\u001b[0m\n",
      "    results = scatter_metric(batch, output)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m1751\u001b[0m, in \u001b[35m_wrapped_call_impl\u001b[0m\n",
      "    return \u001b[31mself._call_impl\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m1762\u001b[0m, in \u001b[35m_call_impl\u001b[0m\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torchmetrics/metric.py\"\u001b[0m, line \u001b[35m313\u001b[0m, in \u001b[35mforward\u001b[0m\n",
      "    self._forward_cache = \u001b[31mself._forward_full_state_update\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "                          \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torchmetrics/metric.py\"\u001b[0m, line \u001b[35m339\u001b[0m, in \u001b[35m_forward_full_state_update\u001b[0m\n",
      "    cache = self._copy_state_dict()\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torchmetrics/metric.py\"\u001b[0m, line \u001b[35m968\u001b[0m, in \u001b[35m_copy_state_dict\u001b[0m\n",
      "    \u001b[31m_.detach().clone\u001b[0m\u001b[1;31m()\u001b[0m.to(_.device) if isinstance(_, Tensor) else deepcopy(_) for _ in current_value\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 52\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_run_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--name\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_T1_finetune_scripted\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--seed\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m42\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     49\u001b[0m ]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd), file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m---> 52\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    os.environ[\"PYTHONPATH\"] = \"/home/phanim/harshitrawat/mace/mace\"\n",
    "\n",
    "    # ——— Training command ———\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        \"--name\",              \"mace_T1_finetune_scripted\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "        \"--multiheads_finetuning\", \"True\",\n",
    "        \"--atomic_numbers\",    \"[3,8,40,57]\",\n",
    "\n",
    "        \"--train_file\",        \"/home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz\",\n",
    "        \"--valid_file\",        \"/home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz\",\n",
    "\n",
    "        \"--batch_size\",        \"2\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "        \"--valid_fraction\",    \"0.1\",\n",
    "\n",
    "        \"--ema_decay\",         \"0.9999\",\n",
    "        \"--lr\",                \"0.001\", #changed\n",
    "        \"--num_samples_pt\",    \"100000\",\n",
    "        \"--clip_grad\",         \"100\", #added\n",
    "        \"--weight_decay\",      \"1e-8\", #added \n",
    "        \"--scheduler_patience\", \"3\", #added\n",
    "\n",
    "        \"--forces_weight\",     \"30\",\n",
    "        \"--energy_weight\",     \"100\",\n",
    "        \"--loss\",              \"universal\",\n",
    "\n",
    "        \"--device\",            \"cuda\",\n",
    "        \"--max_num_epochs\",    \"20\",\n",
    "        \"--r_max\",             \"5.0\",\n",
    "\n",
    "        \"--restart_latest\",\n",
    "        \"--E0s\", \"{3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\",\n",
    "\n",
    "        \"--seed\",              \"42\",\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674d97a8-657f-4ff9-801a-16cd366d854e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    mace_T1_finetune_scripted \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --multiheads_finetuning \\\n",
      "    True \\\n",
      "    --atomic_numbers \\\n",
      "    [3,8,40,57] \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz \\\n",
      "    --valid_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz \\\n",
      "    --batch_size \\\n",
      "    2 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --valid_fraction \\\n",
      "    0.1 \\\n",
      "    --ema_decay \\\n",
      "    0.999 \\\n",
      "    --lr \\\n",
      "    0.0003 \\\n",
      "    --num_samples_pt \\\n",
      "    100000 \\\n",
      "    --clip_grad \\\n",
      "    30 \\\n",
      "    --weight_decay \\\n",
      "    1e-8 \\\n",
      "    --scheduler_patience \\\n",
      "    3 \\\n",
      "    --forces_weight \\\n",
      "    50 \\\n",
      "    --energy_weight \\\n",
      "    100 \\\n",
      "    --loss \\\n",
      "    universal \\\n",
      "    --device \\\n",
      "    cuda \\\n",
      "    --max_num_epochs \\\n",
      "    40 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --restart_latest \\\n",
      "    --E0s \\\n",
      "    {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549} \\\n",
      "    --seed \\\n",
      "    42\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 14:25:50.372 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-07-25 14:25:50.373 INFO: MACE version: 0.3.13\n",
      "2025-07-25 14:25:51.092 INFO: CUDA version: 12.6, CUDA device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:157: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 14:25:51.632 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-07-25 14:25:51.633 WARNING: Using multiheads finetuning with a foundation model that is not a Materials Project model, need to provied a path to a pretraining file with --pt_train_file.\n",
      "2025-07-25 14:25:51.634 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-07-25 14:25:51.634 INFO: Using heads: ['Default']\n",
      "2025-07-25 14:25:51.634 INFO: Using the key specifications to parse data:\n",
      "2025-07-25 14:25:51.634 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-07-25 14:25:51.634 INFO: =============    Processing head Default     ===========\n",
      "2025-07-25 14:26:12.797 INFO: Training set 1/1 [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 14:26:12.815 INFO: Total Training set [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 14:26:15.442 INFO: Validation set 1/1 [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 14:26:15.444 INFO: Total Validation set [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 14:26:15.444 INFO: Total number of configurations: train=6337, valid=705, tests=[],\n",
      "2025-07-25 14:26:15.444 INFO: Using atomic numbers from command line argument\n",
      "2025-07-25 14:26:15.444 INFO: Atomic Numbers used: [3, 8, 40, 57]\n",
      "2025-07-25 14:26:15.444 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-07-25 14:26:15.444 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\n",
      "2025-07-25 14:26:15.444 INFO: Processing datasets for head 'Default'\n",
      "2025-07-25 14:27:38.838 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-07-25 14:27:48.343 INFO: Combining 1 list datasets for head 'Default_valid'\n",
      "2025-07-25 14:27:48.344 INFO: Combined validation datasets for Default\n",
      "2025-07-25 14:27:48.344 INFO: Head 'Default' training dataset size: 6337\n",
      "2025-07-25 14:27:48.344 INFO: Computing average number of neighbors\n",
      "2025-07-25 14:27:55.960 INFO: Average number of neighbors: 68.51557639403025\n",
      "2025-07-25 14:27:55.962 INFO: During training the following quantities will be reported: energy, forces, stress\n",
      "2025-07-25 14:27:55.962 INFO: ===========MODEL DETAILS===========\n",
      "2025-07-25 14:28:02.959 INFO: Loading FOUNDATION model\n",
      "2025-07-25 14:28:02.961 INFO: Using filtered elements: [3, 8, 40, 57]\n",
      "2025-07-25 14:28:02.962 INFO: Model configuration extracted from foundation model\n",
      "2025-07-25 14:28:02.962 INFO: Using universal loss function for fine-tuning\n",
      "2025-07-25 14:28:02.962 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-07-25 14:28:02.962 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-07-25 14:28:02.962 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-07-25 14:28:02.962 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 14:28:04.349 INFO: Total number of parameters: 894362\n",
      "2025-07-25 14:28:04.349 INFO: \n",
      "2025-07-25 14:28:04.349 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-07-25 14:28:04.349 INFO: Using ADAM as parameter optimizer\n",
      "2025-07-25 14:28:04.349 INFO: Batch size: 2\n",
      "2025-07-25 14:28:04.349 INFO: Number of gradient updates: 126740\n",
      "2025-07-25 14:28:04.349 INFO: Learning rate: 0.0003, weight decay: 1e-08\n",
      "2025-07-25 14:28:04.349 INFO: UniversalLoss(energy_weight=100.000, forces_weight=50.000, stress_weight=1.000)\n",
      "2025-07-25 14:28:04.352 WARNING: No SWA checkpoint found, while SWA is enabled. Compare the swa_start parameter and the latest checkpoint.\n",
      "2025-07-25 14:28:04.352 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_scripted_run-42_epoch-19.pt\n",
      "2025-07-25 14:28:04.396 INFO: Using gradient clipping with tolerance=30.000\n",
      "2025-07-25 14:28:04.396 INFO: \n",
      "2025-07-25 14:28:04.396 INFO: ===========TRAINING===========\n",
      "2025-07-25 14:28:04.396 INFO: Started training, reporting errors on validation set\n",
      "2025-07-25 14:28:04.396 INFO: Loss metrics on validation set\n",
      "2025-07-25 14:29:34.018 INFO: Initial: head: Default, loss=0.21565373, RMSE_E_per_atom=  231.34 meV, RMSE_F=   83.79 meV / A, RMSE_stress=    5.33 meV / A^3\n",
      "2025-07-25 15:03:32.156 INFO: Epoch 19: head: Default, loss=0.18629218, RMSE_E_per_atom=  236.60 meV, RMSE_F=   84.61 meV / A, RMSE_stress=    6.15 meV / A^3\n",
      "2025-07-25 15:37:27.787 INFO: Epoch 20: head: Default, loss=0.19035592, RMSE_E_per_atom=  198.57 meV, RMSE_F=   84.40 meV / A, RMSE_stress=    6.51 meV / A^3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/bin/mace_run_train\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m75\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mrun\u001b[0m\u001b[1;31m(args)\u001b[0m\n",
      "    \u001b[31m~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m778\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mtools.train\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<23 lines>...\n",
      "        \u001b[1;31mrank=rank,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m222\u001b[0m, in \u001b[35mtrain\u001b[0m\n",
      "    \u001b[31mtrain_one_epoch\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<11 lines>...\n",
      "        \u001b[1;31mrank=rank,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m370\u001b[0m, in \u001b[35mtrain_one_epoch\u001b[0m\n",
      "    _, opt_metrics = \u001b[31mtake_step\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                     \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mmodel=model_to_train,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<6 lines>...\n",
      "        \u001b[1;31mdevice=device,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/train.py\"\u001b[0m, line \u001b[35m417\u001b[0m, in \u001b[35mtake_step\u001b[0m\n",
      "    \u001b[31moptimizer.step\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m485\u001b[0m, in \u001b[35mwrapper\u001b[0m\n",
      "    out = func(*args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m79\u001b[0m, in \u001b[35m_use_grad\u001b[0m\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/adam.py\"\u001b[0m, line \u001b[35m246\u001b[0m, in \u001b[35mstep\u001b[0m\n",
      "    \u001b[31madam\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mparams_with_grad,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<19 lines>...\n",
      "        \u001b[1;31mdecoupled_weight_decay=group[\"decoupled_weight_decay\"],\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m147\u001b[0m, in \u001b[35mmaybe_fallback\u001b[0m\n",
      "    return func(*args, **kwargs)\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/adam.py\"\u001b[0m, line \u001b[35m933\u001b[0m, in \u001b[35madam\u001b[0m\n",
      "    \u001b[31mfunc\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mparams,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^\u001b[0m\n",
      "    ...<17 lines>...\n",
      "        \u001b[1;31mdecoupled_weight_decay=decoupled_weight_decay,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/adam.py\"\u001b[0m, line \u001b[35m739\u001b[0m, in \u001b[35m_multi_tensor_adam\u001b[0m\n",
      "    1 - beta1 ** \u001b[31m_get_value\u001b[0m\u001b[1;31m(step)\u001b[0m for step in device_state_steps\n",
      "                 \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\"\u001b[0m, line \u001b[35m94\u001b[0m, in \u001b[35m_get_value\u001b[0m\n",
      "    return \u001b[31mx.item\u001b[0m\u001b[1;31m()\u001b[0m if isinstance(x, torch.Tensor) else x\n",
      "           \u001b[31m~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_run_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--name\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_T1_finetune_scripted\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--seed\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m42\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     49\u001b[0m ]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd), file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m---> 52\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    os.environ[\"PYTHONPATH\"] = \"/home/phanim/harshitrawat/mace/mace\"\n",
    "\n",
    "    # ——— Training command ———\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        \"--name\",              \"mace_T1_finetune_scripted\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "        \"--multiheads_finetuning\", \"True\",\n",
    "        \"--atomic_numbers\",    \"[3,8,40,57]\",\n",
    "\n",
    "        \"--train_file\",        \"/home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz\",\n",
    "        \"--valid_file\",        \"/home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz\",\n",
    "\n",
    "        \"--batch_size\",        \"2\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "        \"--valid_fraction\",    \"0.1\",\n",
    "\n",
    "        \"--ema_decay\",         \"0.999\",\n",
    "        \"--lr\",                \"0.0003\", #changed\n",
    "        \"--num_samples_pt\",    \"100000\",\n",
    "        \"--clip_grad\",         \"30\", # Clip harder to avoid another spike\n",
    "        \"--weight_decay\",      \"1e-8\", #added \n",
    "        \"--scheduler_patience\", \"3\", #added\n",
    "\n",
    "        \"--forces_weight\",     \"50\",\n",
    "        \"--energy_weight\",     \"100\",\n",
    "        \"--loss\",              \"universal\",\n",
    "\n",
    "        \"--device\",            \"cuda\",\n",
    "        \"--max_num_epochs\",    \"40\",\n",
    "        \"--r_max\",             \"5.0\",\n",
    "\n",
    "        \"--restart_latest\",\n",
    "        \"--E0s\", \"{3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\",\n",
    "\n",
    "        \"--seed\",              \"42\",\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5e6f4aa-65c2-44de-8bc1-eaff043c1d7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    mace_T1_finetune_scripted \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --multiheads_finetuning \\\n",
      "    True \\\n",
      "    --atomic_numbers \\\n",
      "    [3,8,40,57] \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz \\\n",
      "    --valid_file \\\n",
      "    /home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz \\\n",
      "    --batch_size \\\n",
      "    2 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --valid_fraction \\\n",
      "    0.1 \\\n",
      "    --ema_decay \\\n",
      "    0.999 \\\n",
      "    --lr \\\n",
      "    0.0003 \\\n",
      "    --num_samples_pt \\\n",
      "    100000 \\\n",
      "    --clip_grad \\\n",
      "    30 \\\n",
      "    --weight_decay \\\n",
      "    1e-8 \\\n",
      "    --scheduler_patience \\\n",
      "    3 \\\n",
      "    --forces_weight \\\n",
      "    100 \\\n",
      "    --energy_weight \\\n",
      "    5 \\\n",
      "    --device \\\n",
      "    cuda \\\n",
      "    --max_num_epochs \\\n",
      "    40 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --restart_latest \\\n",
      "    --E0s \\\n",
      "    {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549} \\\n",
      "    --seed \\\n",
      "    42\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 21:25:41.353 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-07-25 21:25:41.354 INFO: MACE version: 0.3.13\n",
      "2025-07-25 21:25:42.057 INFO: CUDA version: 12.6, CUDA device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:157: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 21:25:42.574 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-07-25 21:25:42.575 WARNING: Using multiheads finetuning with a foundation model that is not a Materials Project model, need to provied a path to a pretraining file with --pt_train_file.\n",
      "2025-07-25 21:25:42.575 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-07-25 21:25:42.575 INFO: Using heads: ['Default']\n",
      "2025-07-25 21:25:42.575 INFO: Using the key specifications to parse data:\n",
      "2025-07-25 21:25:42.575 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-07-25 21:25:42.575 INFO: =============    Processing head Default     ===========\n",
      "2025-07-25 21:26:03.716 INFO: Training set 1/1 [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 21:26:03.734 INFO: Total Training set [energy: 6337, stress: 0, virials: 0, dipole components: 0, head: 6337, forces: 6337, charges: 0]\n",
      "2025-07-25 21:26:06.357 INFO: Validation set 1/1 [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 21:26:06.359 INFO: Total Validation set [energy: 705, stress: 0, virials: 0, dipole components: 0, head: 705, forces: 705, charges: 0]\n",
      "2025-07-25 21:26:06.359 INFO: Total number of configurations: train=6337, valid=705, tests=[],\n",
      "2025-07-25 21:26:06.359 INFO: Using atomic numbers from command line argument\n",
      "2025-07-25 21:26:06.360 INFO: Atomic Numbers used: [3, 8, 40, 57]\n",
      "2025-07-25 21:26:06.360 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-07-25 21:26:06.360 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\n",
      "2025-07-25 21:26:06.360 INFO: Processing datasets for head 'Default'\n",
      "2025-07-25 21:27:29.815 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-07-25 21:27:39.309 INFO: Combining 1 list datasets for head 'Default_valid'\n",
      "2025-07-25 21:27:39.309 INFO: Combined validation datasets for Default\n",
      "2025-07-25 21:27:39.309 INFO: Head 'Default' training dataset size: 6337\n",
      "2025-07-25 21:27:39.310 INFO: Computing average number of neighbors\n",
      "2025-07-25 21:27:47.491 INFO: Average number of neighbors: 68.51557639403025\n",
      "2025-07-25 21:27:47.492 INFO: During training the following quantities will be reported: energy, forces\n",
      "2025-07-25 21:27:47.492 INFO: ===========MODEL DETAILS===========\n",
      "2025-07-25 21:27:54.433 INFO: Loading FOUNDATION model\n",
      "2025-07-25 21:27:54.435 INFO: Using filtered elements: [3, 8, 40, 57]\n",
      "2025-07-25 21:27:54.435 INFO: Model configuration extracted from foundation model\n",
      "2025-07-25 21:27:54.435 INFO: Using universal loss function for fine-tuning\n",
      "2025-07-25 21:27:54.435 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-07-25 21:27:54.435 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-07-25 21:27:54.435 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-07-25 21:27:54.435 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 21:27:55.855 INFO: Total number of parameters: 894362\n",
      "2025-07-25 21:27:55.855 INFO: \n",
      "2025-07-25 21:27:55.855 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-07-25 21:27:55.855 INFO: Using ADAM as parameter optimizer\n",
      "2025-07-25 21:27:55.855 INFO: Batch size: 2\n",
      "2025-07-25 21:27:55.855 INFO: Number of gradient updates: 126740\n",
      "2025-07-25 21:27:55.855 INFO: Learning rate: 0.0003, weight decay: 1e-08\n",
      "2025-07-25 21:27:55.855 INFO: WeightedEnergyForcesLoss(energy_weight=5.000, forces_weight=100.000)\n",
      "2025-07-25 21:27:55.860 WARNING: No SWA checkpoint found, while SWA is enabled. Compare the swa_start parameter and the latest checkpoint.\n",
      "2025-07-25 21:27:55.860 INFO: Loading checkpoint: ./checkpoints/mace_T1_finetune_scripted_run-42_epoch-26.pt\n",
      "2025-07-25 21:27:55.906 INFO: Using gradient clipping with tolerance=30.000\n",
      "2025-07-25 21:27:55.906 INFO: \n",
      "2025-07-25 21:27:55.906 INFO: ===========TRAINING===========\n",
      "2025-07-25 21:27:55.906 INFO: Started training, reporting errors on validation set\n",
      "2025-07-25 21:27:55.906 INFO: Loss metrics on validation set\n",
      "2025-07-25 21:29:10.714 INFO: Initial: head: Default, loss=0.48885111, RMSE_E_per_atom=   24.32 meV, RMSE_F=   72.93 meV / A\n",
      "2025-07-25 22:01:13.528 INFO: Epoch 26: head: Default, loss=0.35001886, RMSE_E_per_atom=   28.68 meV, RMSE_F=   62.00 meV / A\n",
      "2025-07-25 22:33:12.861 INFO: Epoch 27: head: Default, loss=0.30569820, RMSE_E_per_atom=   15.26 meV, RMSE_F=   58.27 meV / A\n",
      "2025-07-25 23:05:12.998 INFO: Epoch 28: head: Default, loss=0.28681651, RMSE_E_per_atom=   15.91 meV, RMSE_F=   56.54 meV / A\n",
      "2025-07-25 23:37:13.170 INFO: Epoch 29: head: Default, loss=0.26539503, RMSE_E_per_atom=   11.62 meV, RMSE_F=   54.47 meV / A\n",
      "2025-07-26 00:09:12.959 INFO: Epoch 30: head: Default, loss=0.24962891, RMSE_E_per_atom=    8.25 meV, RMSE_F=   52.78 meV / A\n",
      "2025-07-26 00:41:14.056 INFO: Epoch 31: head: Default, loss=0.23721244, RMSE_E_per_atom=   12.99 meV, RMSE_F=   51.41 meV / A\n",
      "2025-07-26 01:14:37.543 INFO: Epoch 32: head: Default, loss=0.22752978, RMSE_E_per_atom=   11.02 meV, RMSE_F=   50.46 meV / A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 51\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_run_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--name\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_T1_finetune_scripted\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--seed\u001b[39m\u001b[38;5;124m\"\u001b[39m,              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m42\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m ]\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd), file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m---> 51\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    os.environ[\"PYTHONPATH\"] = \"/home/phanim/harshitrawat/mace/mace\"\n",
    "\n",
    "    # ——— Training command ———\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        \"--name\",              \"mace_T1_finetune_scripted\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal_new/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "        \"--multiheads_finetuning\", \"True\",\n",
    "        \"--atomic_numbers\",    \"[3,8,40,57]\",\n",
    "\n",
    "        \"--train_file\",        \"/home/phanim/harshitrawat/summer/final_work/T1_chgnet_labeled.extxyz\",\n",
    "        \"--valid_file\",        \"/home/phanim/harshitrawat/summer/final_work/T2_chgnet_labeled.extxyz\",\n",
    "\n",
    "        \"--batch_size\",        \"2\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "        \"--valid_fraction\",    \"0.1\",\n",
    "\n",
    "        \"--ema_decay\",         \"0.999\",\n",
    "        \"--lr\",                \"0.0003\", #changed\n",
    "        \"--num_samples_pt\",    \"100000\",\n",
    "        \"--clip_grad\",         \"30\", # Clip harder to avoid another spike\n",
    "        \"--weight_decay\",      \"1e-8\", #added \n",
    "        \"--scheduler_patience\", \"3\", #added\n",
    "\n",
    "        \"--forces_weight\",     \"100\",\n",
    "        \"--energy_weight\",     \"5\",\n",
    "# universal loss removed... might have been the root cause of the stagnation\n",
    "        \"--device\",            \"cuda\",\n",
    "        \"--max_num_epochs\",    \"40\",\n",
    "        \"--r_max\",             \"5.0\",\n",
    "\n",
    "        \"--restart_latest\",\n",
    "        \"--E0s\", \"{3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\",\n",
    "\n",
    "        \"--seed\",              \"42\",\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d473afc-c671-4b94-9607-10e96a908282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU mace_0.3.8)",
   "language": "python",
   "name": "mace_0.3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
