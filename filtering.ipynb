{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8bf6f66-9b9a-4ff8-ade1-0009146e976e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IncompleteJSONError",
     "evalue": "lexical error: invalid char in json text.\n                                                            (right here) ------^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteJSONError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m         \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         sys\u001b[38;5;241m.\u001b[39mexit(\u001b[38;5;241m130\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m seen_valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(INPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# stream top-level dict: material_id → dict of entries\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mid, entries \u001b[38;5;129;01min\u001b[39;00m ijson\u001b[38;5;241m.\u001b[39mkvitems(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, multiple_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m eid, entry \u001b[38;5;129;01min\u001b[39;00m entries\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     47\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_entry(entry):\n",
      "\u001b[0;31mIncompleteJSONError\u001b[0m: lexical error: invalid char in json text.\n                                                            (right here) ------^\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import ijson, random, sys\n",
    "from ase import Atoms\n",
    "from ase.io import write\n",
    "\n",
    "# --- config ---\n",
    "INPATH   = \"/home/phanim/harshitrawat/MPtrj_2022.9_full.json\"\n",
    "OUTPATH  = \"/home/phanim/harshitrawat/summer/replay_LiLaZrO_5k_le200.extxyz\"\n",
    "WANTED   = {\"Li\", \"La\", \"Zr\", \"O\"}\n",
    "MAX_AT   = 200\n",
    "TARGET_N = 5000\n",
    "SEED     = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "def valid_entry(entry):\n",
    "    try:\n",
    "        syms = entry[\"symbols\"]\n",
    "        uniq = set(syms)\n",
    "        if not uniq.issubset(WANTED): return False\n",
    "        if not (1 <= len(uniq) <= 4): return False\n",
    "        if len(syms) > MAX_AT: return False\n",
    "        if \"positions\" not in entry or \"cell\" not in entry or \"energy\" not in entry: return False\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def make_atoms(entry):\n",
    "    ats = Atoms(\n",
    "        symbols=entry[\"symbols\"],\n",
    "        positions=entry[\"positions\"],\n",
    "        cell=entry[\"cell\"],\n",
    "        pbc=True\n",
    "    )\n",
    "    ats.info[\"energy\"] = float(entry[\"energy\"])\n",
    "    return ats\n",
    "\n",
    "def main():\n",
    "    reservoir = []\n",
    "    kept = 0\n",
    "    seen_valid = 0\n",
    "\n",
    "    with open(INPATH, \"rb\") as f:\n",
    "        # stream top-level dict: material_id → dict of entries\n",
    "        for mid, entries in ijson.kvitems(f, \"\", multiple_values=True):\n",
    "            for eid, entry in entries.items():\n",
    "                if not valid_entry(entry):\n",
    "                    continue\n",
    "\n",
    "                seen_valid += 1\n",
    "                if kept < TARGET_N:\n",
    "                    try:\n",
    "                        reservoir.append(make_atoms(entry))\n",
    "                        kept += 1\n",
    "                    except Exception:\n",
    "                        seen_valid -= 1\n",
    "                        continue\n",
    "                else:\n",
    "                    # reservoir sampling replacement\n",
    "                    j = random.randrange(seen_valid)\n",
    "                    if j < TARGET_N:\n",
    "                        try:\n",
    "                            reservoir[j] = make_atoms(entry)\n",
    "                        except Exception:\n",
    "                            seen_valid -= 1\n",
    "                            continue\n",
    "\n",
    "    write(OUTPATH, reservoir)\n",
    "    print(f\"[done] wrote {len(reservoir)} structures to {OUTPATH}\")\n",
    "    print(f\"[stats] seen_valid={seen_valid}, kept={kept}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        sys.exit(130)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32706fb9-311a-4bb2-8f60-365822506f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mp-1005792 ['mp-1012897-0-0', 'mp-1005792-0-1', 'mp-1005792-0-0', 'mp-1005792-1-1', 'mp-1005792-1-0']\n",
      "1 mp-1006278 ['mp-1006287-0-0', 'mp-1006278-0-4', 'mp-1006278-0-3', 'mp-1006278-0-2', 'mp-1006278-0-1']\n",
      "2 mp-10068 ['mp-910115-0-0', 'mp-10068-0-2', 'mp-10068-1-4', 'mp-10068-1-2', 'mp-10068-1-0']\n",
      "3 mp-1007758 ['mp-1007758-0-0', 'mp-1007758-1-10', 'mp-1007758-1-9', 'mp-1007758-1-8', 'mp-1007758-1-6']\n"
     ]
    }
   ],
   "source": [
    "import ijson\n",
    "\n",
    "f = \"/home/phanim/harshitrawat/MPtrj_2022.9_full.json\"\n",
    "with open(f, \"rb\") as fd:\n",
    "    for i, (k,v) in enumerate(ijson.kvitems(fd, \"\", multiple_values=True)):\n",
    "        print(i, k, list(v.keys())[:5])\n",
    "        if i==3: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f56de526-7f42-497f-ba76-2813d97d0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# --- robust extractor for CHGNet MPtrj ---\n",
    "def elements_from_structure(record):\n",
    "    s = record.get(\"structure\")\n",
    "    if not isinstance(s, dict):\n",
    "        return set()\n",
    "\n",
    "    # 1) composition dict (common in pymatgen as_dict)\n",
    "    comp = s.get(\"composition\")\n",
    "    if isinstance(comp, dict):\n",
    "        # comp might be {\"Li\":7, \"La\":3, \"Zr\":2, \"O\":12} or {\"@class\":\"Composition\", ...}\n",
    "        # Try dict of element->count first:\n",
    "        keys = [k for k in comp.keys() if isinstance(k, str) and len(k) <= 3]\n",
    "        if keys:\n",
    "            return set(keys)\n",
    "        # Sometimes nested like {\"reduced_cell_composition\": {\"Li\":7,...}}; try to find a flat dict of elements\n",
    "        for v in comp.values():\n",
    "            if isinstance(v, dict):\n",
    "                el_keys = [k for k in v.keys() if isinstance(k, str) and len(k) <= 3]\n",
    "                if el_keys:\n",
    "                    return set(el_keys)\n",
    "\n",
    "    # 2) sites[*].species[*].element (CHGNet docs)\n",
    "    sites = s.get(\"sites\")\n",
    "    if isinstance(sites, list):\n",
    "        out = set()\n",
    "        for site in sites:\n",
    "            species = site.get(\"species\", [])\n",
    "            # species can be [{\"element\":\"Li\",\"occu\":1}] or [{\"element\":{\"element\":\"Li\"},...}]\n",
    "            for sp in species:\n",
    "                el = sp.get(\"element\")\n",
    "                if isinstance(el, dict) and \"element\" in el:\n",
    "                    el = el[\"element\"]\n",
    "                if isinstance(el, str) and el:\n",
    "                    out.add(el)\n",
    "            # fallback: label field sometimes present (\"Li\", \"O\", ...)\n",
    "            lab = site.get(\"label\")\n",
    "            if isinstance(lab, str) and len(lab) <= 3:\n",
    "                out.add(lab)\n",
    "        if out:\n",
    "            return out\n",
    "\n",
    "    # 3) last resort: try top-level shortcut if present\n",
    "    els = record.get(\"elements\")\n",
    "    if isinstance(els, list) and els:\n",
    "        return set(map(str, els))\n",
    "\n",
    "    return set()\n",
    "\n",
    "TARGET = {\"Li\",\"La\",\"Zr\",\"O\"}\n",
    "ALLOWED = {2,3,4}\n",
    "\n",
    "def filter_chunk(in_path, out_path):\n",
    "    kept = seen = 0\n",
    "    with open(in_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as fi, \\\n",
    "         open(out_path, \"w\", encoding=\"utf-8\") as fo:\n",
    "        for line in fi:\n",
    "            s = line.strip()\n",
    "            if not s:\n",
    "                continue\n",
    "            try:\n",
    "                d = json.loads(s)\n",
    "            except Exception:\n",
    "                continue\n",
    "            seen += 1\n",
    "            elems = elements_from_structure(d)\n",
    "            if elems and (len(elems) in ALLOWED) and elems.issubset(TARGET):\n",
    "                if not d.get(\"elements\"):\n",
    "                    d = dict(d); d[\"elements\"] = sorted(elems)\n",
    "                fo.write(json.dumps(d, separators=(\",\",\":\")) + \"\\n\")\n",
    "                kept += 1\n",
    "    return in_path, seen, kept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14950464-13e1-449b-b005-6c82b50363b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected NDJSON. Copying -> normalized NDJSON ...\n",
      "Done: copied 1 lines to /home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/MPtrj_base.ndjson in 48.2s\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "SRC = \"/home/phanim/harshitrawat/MPtrj_2022.9_full.json\"   # or .json.gz\n",
    "WORKDIR = \"/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb\"\n",
    "NDJSON = f\"{WORKDIR}/MPtrj_base.ndjson\"\n",
    "\n",
    "import os, gzip, io, ijson, json, time\n",
    "os.makedirs(WORKDIR, exist_ok=True)\n",
    "\n",
    "def open_bin(path):\n",
    "    return gzip.open(path, \"rb\") if path.endswith(\".gz\") else open(path, \"rb\")\n",
    "\n",
    "def first_non_ws_byte(f):\n",
    "    pos = f.tell()\n",
    "    while True:\n",
    "        chunk = f.read(65536)\n",
    "        if not chunk:\n",
    "            f.seek(pos); return None\n",
    "        for b in chunk:\n",
    "            if chr(b) not in \" \\t\\r\\n\":\n",
    "                f.seek(pos); return b\n",
    "\n",
    "t0 = time.time()\n",
    "with open_bin(SRC) as fb:\n",
    "    b = first_non_ws_byte(fb)\n",
    "    if b is None:\n",
    "        raise RuntimeError(\"Source file is empty.\")\n",
    "    if chr(b) == '[':\n",
    "        # Big JSON array -> stream to NDJSON\n",
    "        print(\"Detected big JSON array. Streaming -> NDJSON ...\")\n",
    "        it = ijson.items(fb, \"item\")\n",
    "        count = 0\n",
    "        with open(NDJSON, \"w\", encoding=\"utf-8\") as out:\n",
    "            for obj in it:\n",
    "                out.write(json.dumps(obj, separators=(\",\", \":\")) + \"\\n\")\n",
    "                count += 1\n",
    "                if count % 100000 == 0:\n",
    "                    print(f\"  wrote {count:,} objects...\", flush=True)\n",
    "        print(f\"Done: wrote {count:,} objects to {NDJSON} in {time.time()-t0:.1f}s\")\n",
    "    else:\n",
    "        # NDJSON already -> just copy as-is (strip blanks)\n",
    "        print(\"Detected NDJSON. Copying -> normalized NDJSON ...\")\n",
    "        count = 0\n",
    "        with io.TextIOWrapper(fb, encoding=\"utf-8\", errors=\"ignore\") as fi, \\\n",
    "             open(NDJSON, \"w\", encoding=\"utf-8\") as out:\n",
    "            for line in fi:\n",
    "                s = line.strip()\n",
    "                if not s: continue\n",
    "                out.write(s + \"\\n\")\n",
    "                count += 1\n",
    "        print(f\"Done: copied {count:,} lines to {NDJSON} in {time.time()-t0:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4781a1f2-b881-4963-9655-3ea816ca1ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 lines into 30 chunks in 52.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_00.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_01.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_02.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_03.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_04.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_05.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_06.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_07.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_08.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_09.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_10.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_11.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_12.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_13.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_14.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_15.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_16.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_17.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_18.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_19.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_20.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_21.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_22.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_23.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_24.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_25.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_26.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_27.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_28.ndjson',\n",
       " '/home/phanim/harshitrawat/summer/mptrj_li_lazr_o_nb/chunk_29.ndjson']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CHUNKS = 30  # set to number of CPU cores you want\n",
    "\n",
    "chunk_paths = [f\"{WORKDIR}/chunk_{i:02d}.ndjson\" for i in range(NUM_CHUNKS)]\n",
    "files = [open(p, \"w\", encoding=\"utf-8\") for p in chunk_paths]\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "line_count = 0\n",
    "with open(NDJSON, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if not line.strip(): continue\n",
    "        files[i % NUM_CHUNKS].write(line)\n",
    "        line_count += 1\n",
    "\n",
    "for fh in files: fh.close()\n",
    "print(f\"Split {line_count:,} lines into {NUM_CHUNKS} chunks in {time.time()-t0:.1f}s\")\n",
    "chunk_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d325b87-5a71-434b-8a05-992c9a89ca0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IncompleteJSONError",
     "evalue": "lexical error: invalid char in json text.\n                                                            (right here) ------^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteJSONError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(SRC, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f, \u001b[38;5;28mopen\u001b[39m(NDJSON, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m ijson\u001b[38;5;241m.\u001b[39mitems(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     10\u001b[0m         out\u001b[38;5;241m.\u001b[39mwrite(json\u001b[38;5;241m.\u001b[39mdumps(obj, separators\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIncompleteJSONError\u001b[0m: lexical error: invalid char in json text.\n                                                            (right here) ------^\n"
     ]
    }
   ],
   "source": [
    "import ijson, gzip, json, time\n",
    "\n",
    "SRC = \"/home/phanim/harshitrawat/MPtrj_2022.9_full.json\"   # or .gz\n",
    "NDJSON = f\"{WORKDIR}/MPtrj_base.ndjson\"\n",
    "\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "with open(SRC, \"rb\") as f, open(NDJSON, \"w\", encoding=\"utf-8\") as out:\n",
    "    for obj in ijson.items(f, \"item\"):\n",
    "        out.write(json.dumps(obj, separators=(\",\",\":\")) + \"\\n\")\n",
    "        count += 1\n",
    "        if count % 100000 == 0:\n",
    "            print(f\"wrote {count:,} objects...\", flush=True)\n",
    "\n",
    "print(f\"Done: wrote {count:,} objects to {NDJSON} in {time.time()-t0:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865640cd-1c93-4d56-862d-70109124d6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vac_axis=2 (0=a, 1=b, 2=c); wrote /home/phanim/harshitrawat/summer/md/mdcifs_strained_perturbed_prime/cellrelaxed_LLZO_011_La_code71_sto__Li_100_slab_heavy_T300_0138_strain+0.015_perturbed_centered.cif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/pymatgen/core/structure.py:3107: UserWarning: Issues encountered while parsing CIF: 1 fractional coordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  struct = parser.parse_structures(primitive=primitive)[0]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from pymatgen.core import Structure\n",
    "import numpy as np, os, json\n",
    "\n",
    "SRC = \"/home/phanim/harshitrawat/summer/md/mdcifs_strained_perturbed_prime/cellrelaxed_LLZO_011_La_code71_sto__Li_100_slab_heavy_T300_0138_strain+0.015_perturbed.cif\"\n",
    "s = Structure.from_file(SRC)\n",
    "lengths = np.array([s.lattice.a, s.lattice.b, s.lattice.c])\n",
    "frac = s.frac_coords.copy()\n",
    "\n",
    "occupied, vac = [], []\n",
    "for ax in range(3):\n",
    "    c = frac[:, ax]\n",
    "    span_frac = max(1e-9, c.max() - c.min())\n",
    "    span_cart = span_frac * lengths[ax]\n",
    "    occupied.append(span_cart)\n",
    "    vac.append(max(0.0, lengths[ax] - span_cart))\n",
    "vac_axis = int(np.argmax(vac))\n",
    "\n",
    "# center along vacuum axis\n",
    "minf, maxf = frac[:, vac_axis].min(), frac[:, vac_axis].max()\n",
    "shift = 0.5 - 0.5*(minf + maxf)\n",
    "frac[:, vac_axis] = (frac[:, vac_axis] + shift) % 1.0\n",
    "\n",
    "s_centered = s.copy()\n",
    "s_centered.remove_sites(range(len(s_centered)))\n",
    "for i, sp in enumerate(s.species):\n",
    "    s_centered.append(sp, frac[i], coords_are_cartesian=False)\n",
    "\n",
    "OUT = os.path.splitext(SRC)[0] + \"_centered.cif\"\n",
    "s_centered.to(filename=OUT)\n",
    "print(f\"vac_axis={vac_axis} (0=a, 1=b, 2=c); wrote {OUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ba3f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust centering for slabs split across periodic boundaries\n",
    "# - Finds the largest fractional gap along each axis (vacuum)\n",
    "# - Rotates fractional coords so slab is contiguous and centered at 0.5\n",
    "# - Optional: add vacuum padding and disable PBC along vacuum axis\n",
    "# Requires: pip install ase\n",
    "\n",
    "from ase.io import read, write\n",
    "import numpy as np, os\n",
    "from typing import Tuple\n",
    "\n",
    "AXMAP = {\"a\":0,\"b\":1,\"c\":2}\n",
    "\n",
    "def largest_gap_shift(fracs_1d: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Given fractional coords in [0,1), find the circular largest gap.\n",
    "    Returns (gap_center, gap_size), where shifting all fracs by\n",
    "    (-gap_center + 0.5) moves the gap center to 0.5, i.e., centers the slab.\n",
    "    \"\"\"\n",
    "    f = np.sort(fracs_1d % 1.0)\n",
    "    if len(f) == 0:\n",
    "        return 0.5, 1.0\n",
    "    # Gaps between consecutive points on the circle:\n",
    "    diffs = np.diff(f, append=f[0] + 1.0)\n",
    "    i = int(np.argmax(diffs))\n",
    "    gap_size = float(diffs[i])\n",
    "    # Gap runs from f[i] -> f[i]+gap_size. Its center:\n",
    "    gap_center = (f[i] + gap_size/2.0) % 1.0\n",
    "    return gap_center, gap_size\n",
    "\n",
    "def detect_vac_axis_by_gap(atoms) -> Tuple[int, list]:\n",
    "    \"\"\"\n",
    "    Vacuum thickness (Å) = largest fractional gap * axis length.\n",
    "    Returns (vac_axis, [vacA_a, vacA_b, vacA_c]).\n",
    "    \"\"\"\n",
    "    cell = atoms.get_cell()\n",
    "    lengths = cell.lengths()\n",
    "    frac = atoms.get_scaled_positions() % 1.0\n",
    "    vacA = []\n",
    "    for ax in range(3):\n",
    "        _, gap = largest_gap_shift(frac[:, ax])\n",
    "        vacA.append(float(gap * lengths[ax]))\n",
    "    return int(np.argmax(vacA)), vacA\n",
    "\n",
    "def rotate_and_center(atoms, ax: int):\n",
    "    \"\"\"\n",
    "    Rotate fractional coords so the largest gap is centered at 0.5,\n",
    "    making the slab contiguous and centered along axis ax.\n",
    "    \"\"\"\n",
    "    frac = atoms.get_scaled_positions() % 1.0\n",
    "    gap_center, _ = largest_gap_shift(frac[:, ax])\n",
    "    # We want the gap center at 0.5 -> slab center at 0.0 and symmetric.\n",
    "    # Shift = 0.5 - gap_center\n",
    "    shift = (0.5 - gap_center) % 1.0\n",
    "    frac[:, ax] = (frac[:, ax] + shift) % 1.0\n",
    "\n",
    "    # Now center the slab block exactly at 0.5 (continuous segment midpoint)\n",
    "    # Compute occupied segment [min,max] after rotation (no wrap now)\n",
    "    lo, hi = float(frac[:, ax].min()), float(frac[:, ax].max())\n",
    "    mid = 0.5 * (lo + hi)\n",
    "    frac[:, ax] = (frac[:, ax] + (0.5 - mid)) % 1.0\n",
    "\n",
    "    atoms.set_scaled_positions(frac)\n",
    "\n",
    "def add_vacuum_padding(atoms, ax: int, pad_A: float):\n",
    "    \"\"\"Increase lattice length along axis ax by pad_A while preserving tilt.\"\"\"\n",
    "    if pad_A <= 0: \n",
    "        return\n",
    "    cell = atoms.get_cell().array.copy()\n",
    "    vec = cell[ax]\n",
    "    L = np.linalg.norm(vec)\n",
    "    if L > 1e-12:\n",
    "        cell[ax] = vec * ((L + pad_A) / L)\n",
    "        atoms.set_cell(cell, scale_atoms=False)\n",
    "\n",
    "def center_slab_gap_method(\n",
    "    infile: str,\n",
    "    axis: str = \"auto\",      # \"auto\" or \"a\"/\"b\"/\"c\"\n",
    "    pad_A: float = 0.0,      # extra vacuum to add (Å)\n",
    "    nonperiodic: bool = True,\n",
    "    basename: str | None = None,\n",
    "    write_xyz: bool = True,\n",
    "    write_lammps: bool = True,\n",
    "):\n",
    "    atoms = read(infile)\n",
    "    stem = os.path.splitext(os.path.basename(infile))[0]\n",
    "    base = basename or f\"{stem}_centered\"\n",
    "\n",
    "    if axis == \"auto\":\n",
    "        vac_ax, vacA = detect_vac_axis_by_gap(atoms)\n",
    "    else:\n",
    "        vac_ax = AXMAP[axis.lower()]\n",
    "        _, vacA = detect_vac_axis_by_gap(atoms)  # still report\n",
    "\n",
    "    # First rotate+center into a contiguous block, then optionally add padding.\n",
    "    # (Order doesn’t matter for fractional rotation, but this keeps intuition clean.)\n",
    "    rotate_and_center(atoms, vac_ax)\n",
    "    add_vacuum_padding(atoms, vac_ax, pad_A)\n",
    "    # Re-center again after padding to be super safe numerically:\n",
    "    rotate_and_center(atoms, vac_ax)\n",
    "\n",
    "    if nonperiodic:\n",
    "        pbc = list(atoms.get_pbc())\n",
    "        pbc[vac_ax] = False\n",
    "        atoms.set_pbc(pbc)\n",
    "\n",
    "    out_cif = f\"{base}.cif\"\n",
    "    write(out_cif, atoms)\n",
    "    out_xyz = out_lmp = None\n",
    "\n",
    "    if write_xyz:\n",
    "        out_xyz = f\"{base}.xyz\"\n",
    "        write(out_xyz, atoms)   # XYZ has no PBC → Avogadro shows a single slab\n",
    "\n",
    "    if write_lammps:\n",
    "        out_lmp = f\"{base}.data\"\n",
    "        write(out_lmp, atoms, format=\"lammps-data\")  # respects PBC → gives p p f if nonperiodic\n",
    "\n",
    "    return {\n",
    "        \"vacuum_axis_index\": vac_ax,                 # 0=a,1=b,2=c\n",
    "        \"vacuum_estimates_A\": {\"a\":vacA[0], \"b\":vacA[1], \"c\":vacA[2]},\n",
    "        \"outputs\": {\"cif\": out_cif, \"xyz\": out_xyz, \"lammps_data\": out_lmp},\n",
    "        \"nonperiodic_applied\": bool(nonperiodic),\n",
    "        \"extra_padding_A\": float(pad_A),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838e0e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vacuum_axis_index': 2,\n",
       " 'vacuum_estimates_A': {'a': 0.028919990786413052,\n",
       "  'b': 0.03174803773705648,\n",
       "  'c': 0.12013604529882116},\n",
       " 'outputs': {'cif': 'cellrelaxed_LLZO_011_La_code71_sto__Li_100_slab_heavy_T300_0138_strain+0.015_perturbed_centered.cif',\n",
       "  'xyz': 'cellrelaxed_LLZO_011_La_code71_sto__Li_100_slab_heavy_T300_0138_strain+0.015_perturbed_centered.xyz',\n",
       "  'lammps_data': 'cellrelaxed_LLZO_011_La_code71_sto__Li_100_slab_heavy_T300_0138_strain+0.015_perturbed_centered.data'},\n",
       " 'nonperiodic_applied': True,\n",
       " 'extra_padding_A': 10.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === EDIT THIS ===\n",
    "infile = \"/home/phanim/harshitrawat/summer/md/mdcifs_strained_perturbed_prime/cellrelaxed_LLZO_011_La_code71_sto__Li_100_slab_heavy_T300_0138_strain+0.015_perturbed.cif\"\n",
    "\n",
    "rep = center_slab(\n",
    "    infile,\n",
    "    axis=\"auto\",        # or \"c\" if you know vacuum is along c\n",
    "    pad_A=10.0,         # add 10 Å more vacuum (set 0.0 to skip)\n",
    "    nonperiodic=True,   # off-PBC along vacuum (XYZ, LAMMPS respect it)\n",
    "    basename=None,      # custom base name if you want\n",
    ")\n",
    "rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5455585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU mace_0.3.8)",
   "language": "python",
   "name": "mace_0.3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
