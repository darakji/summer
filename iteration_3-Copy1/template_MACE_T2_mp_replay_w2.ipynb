{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74803bd4-0874-4a95-bcd2-702000a67339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    mace_T2_including_replay_w2 \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/iteration_3-Copy1/one.xyz \\\n",
      "    --valid_fraction \\\n",
      "    0.5 \\\n",
      "    --batch_size \\\n",
      "    1 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --device \\\n",
      "    cpu \\\n",
      "    --forces_weight \\\n",
      "    0 \\\n",
      "    --energy_weight \\\n",
      "    0 \\\n",
      "    --stress_weight \\\n",
      "    0 \\\n",
      "    --lr \\\n",
      "    0.006 \\\n",
      "    --scheduler_patience \\\n",
      "    4 \\\n",
      "    --clip_grad \\\n",
      "    1 \\\n",
      "    --weight_decay \\\n",
      "    1e-8 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --max_num_epochs \\\n",
      "    1 \\\n",
      "    --E0s \\\n",
      "    {3: -1.2302615750354944} \\\n",
      "    --seed \\\n",
      "    84 \\\n",
      "    --patience \\\n",
      "    8 \\\n",
      "    --restart_latest\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-21 20:19:52.743 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-08-21 20:19:52.743 INFO: MACE version: 0.3.14\n",
      "2025-08-21 20:19:52.743 INFO: Using CPU\n",
      "2025-08-21 20:19:52.864 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-08-21 20:19:52.864 WARNING: Using multiheads finetuning with a foundation model that is not a Materials Project model, need to provied a path to a pretraining file with --pt_train_file.\n",
      "2025-08-21 20:19:52.864 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-08-21 20:19:52.864 INFO: Using heads: ['Default']\n",
      "2025-08-21 20:19:52.864 INFO: Using the key specifications to parse data:\n",
      "2025-08-21 20:19:52.864 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head', 'elec_temp': 'elec_temp', 'total_charge': 'total_charge', 'polarizability': 'polarizability', 'total_spin': 'total_spin'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-08-21 20:19:52.864 INFO: =============    Processing head Default     ===========\n",
      "2025-08-21 20:19:52.869 WARNING: No forces found with key 'REF_forces' in '/home/phanim/harshitrawat/summer/iteration_3-Copy1/one.xyz'. If this is unexpected, Please change the key name in the command line arguments or ensure that the file contains the required data.\n",
      "2025-08-21 20:19:52.869 INFO: Training set 1/1 [energy: 2, stress: 0, virials: 0, dipole components: 0, head: 2, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 0, charges: 0]\n",
      "2025-08-21 20:19:52.869 INFO: Total Training set [energy: 2, stress: 0, virials: 0, dipole components: 0, head: 2, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 0, charges: 0]\n",
      "2025-08-21 20:19:52.869 INFO: No validation set provided, splitting training data instead.\n",
      "2025-08-21 20:19:52.869 INFO: Using random 50% of training set for validation with following indices: [0]\n",
      "2025-08-21 20:19:52.869 INFO: Random Split Training set [energy: 1, stress: 0, virials: 0, dipole components: 0, head: 1, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 0, charges: 0]\n",
      "2025-08-21 20:19:52.869 INFO: Random Split Validation set [energy: 1, stress: 0, virials: 0, dipole components: 0, head: 1, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 0, charges: 0]\n",
      "2025-08-21 20:19:52.869 INFO: Total number of configurations: train=1, valid=1, tests=[],\n",
      "2025-08-21 20:19:52.869 INFO: Atomic Numbers used: [3]\n",
      "2025-08-21 20:19:52.869 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-08-21 20:19:52.870 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944}\n",
      "2025-08-21 20:19:52.870 INFO: Processing datasets for head 'Default'\n",
      "2025-08-21 20:19:52.870 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-08-21 20:19:52.871 INFO: Head 'Default' training dataset size: 1\n",
      "2025-08-21 20:19:52.871 INFO: Computing average number of neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:152: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-21 20:19:53.175 INFO: Average number of neighbors: nan\n",
      "2025-08-21 20:19:53.175 INFO: During training the following quantities will be reported: energy, forces\n",
      "2025-08-21 20:19:53.175 INFO: ===========MODEL DETAILS===========\n",
      "2025-08-21 20:19:53.177 WARNING: Standard deviation of the scaling is zero, Changing to no scaling\n",
      "2025-08-21 20:19:53.177 INFO: Loading FOUNDATION model\n",
      "2025-08-21 20:19:53.177 INFO: Using filtered elements: [3]\n",
      "2025-08-21 20:19:53.177 INFO: Model configuration extracted from foundation model\n",
      "2025-08-21 20:19:53.177 INFO: Using weighted loss function for fine-tuning\n",
      "2025-08-21 20:19:53.177 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-08-21 20:19:53.177 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-08-21 20:19:53.177 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-08-21 20:19:53.177 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-21 20:20:04.057 INFO: Total number of parameters: 723866\n",
      "2025-08-21 20:20:04.057 INFO: \n",
      "2025-08-21 20:20:04.057 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-08-21 20:20:04.057 INFO: Using ADAM as parameter optimizer\n",
      "2025-08-21 20:20:04.057 INFO: Batch size: 1\n",
      "2025-08-21 20:20:04.057 INFO: Number of gradient updates: 1\n",
      "2025-08-21 20:20:04.057 INFO: Learning rate: 0.006, weight decay: 1e-08\n",
      "2025-08-21 20:20:04.057 INFO: WeightedEnergyForcesLoss(energy_weight=0.000, forces_weight=0.000)\n",
      "2025-08-21 20:20:04.059 WARNING: No SWA checkpoint found, while SWA is enabled. Compare the swa_start parameter and the latest checkpoint.\n",
      "2025-08-21 20:20:04.059 INFO: Loading checkpoint: ./checkpoints/mace_T2_including_replay_w2_run-84_epoch-77.pt\n",
      "2025-08-21 20:20:04.213 INFO: Using gradient clipping with tolerance=1.000\n",
      "2025-08-21 20:20:04.213 INFO: \n",
      "2025-08-21 20:20:04.213 INFO: ===========TRAINING===========\n",
      "2025-08-21 20:20:04.213 INFO: Started training, reporting errors on validation set\n",
      "2025-08-21 20:20:04.213 INFO: Loss metrics on validation set\n",
      "2025-08-21 20:20:04.829 INFO: Initial: head: Default, loss=0.00000000, RMSE_E_per_atom= 1384.88 meV, RMSE_F=None meV / A\n",
      "2025-08-21 20:20:07.407 INFO: Epoch 0: head: Default, loss=0.00000000, RMSE_E_per_atom= 1384.88 meV, RMSE_F=None meV / A\n",
      "2025-08-21 20:20:07.491 INFO: Training complete\n",
      "2025-08-21 20:20:07.491 INFO: \n",
      "2025-08-21 20:20:07.491 INFO: ===========RESULTS===========\n",
      "2025-08-21 20:20:07.491 INFO: Loading checkpoint: ./checkpoints/mace_T2_including_replay_w2_run-84_epoch-77.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/bin/mace_run_train\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m77\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mrun\u001b[0m\u001b[1;31m(args)\u001b[0m\n",
      "    \u001b[31m~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py\"\u001b[0m, line \u001b[35m940\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    epoch = checkpoint_handler.load_latest(\n",
      "        state=tools.CheckpointState(model, optimizer, lr_scheduler),\n",
      "        swa=swa_eval,\n",
      "        device=device,\n",
      "    )\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py\"\u001b[0m, line \u001b[35m215\u001b[0m, in \u001b[35mload_latest\u001b[0m\n",
      "    \u001b[31mself.builder.load_checkpoint\u001b[0m\u001b[1;31m(state=state, checkpoint=checkpoint, strict=strict)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py\"\u001b[0m, line \u001b[35m40\u001b[0m, in \u001b[35mload_checkpoint\u001b[0m\n",
      "    \u001b[31mstate.model.load_state_dict\u001b[0m\u001b[1;31m(checkpoint[\"model\"], strict=strict)\u001b[0m  # type: ignore\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m2593\u001b[0m, in \u001b[35mload_state_dict\u001b[0m\n",
      "    raise RuntimeError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "\u001b[1;35mRuntimeError\u001b[0m: \u001b[35mError(s) in loading state_dict for ScaleShiftMACE:\n",
      "\tsize mismatch for atomic_numbers: copying a param with shape torch.Size([86]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "\tsize mismatch for node_embedding.linear.weight: copying a param with shape torch.Size([11008]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for atomic_energies_fn.atomic_energies: copying a param with shape torch.Size([2, 86]) from checkpoint, the shape in current model is torch.Size([1, 1]).\n",
      "\tsize mismatch for interactions.0.skip_tp.weight: copying a param with shape torch.Size([1409024]) from checkpoint, the shape in current model is torch.Size([16384]).\n",
      "\tsize mismatch for interactions.1.skip_tp.weight: copying a param with shape torch.Size([1409024]) from checkpoint, the shape in current model is torch.Size([16384]).\n",
      "\tsize mismatch for products.0.symmetric_contractions.contractions.0.weights_max: copying a param with shape torch.Size([86, 23, 128]) from checkpoint, the shape in current model is torch.Size([1, 23, 128]).\n",
      "\tsize mismatch for products.0.symmetric_contractions.contractions.0.weights.0: copying a param with shape torch.Size([86, 4, 128]) from checkpoint, the shape in current model is torch.Size([1, 4, 128]).\n",
      "\tsize mismatch for products.0.symmetric_contractions.contractions.0.weights.1: copying a param with shape torch.Size([86, 1, 128]) from checkpoint, the shape in current model is torch.Size([1, 1, 128]).\n",
      "\tsize mismatch for products.0.symmetric_contractions.contractions.1.weights_max: copying a param with shape torch.Size([86, 51, 128]) from checkpoint, the shape in current model is torch.Size([1, 51, 128]).\n",
      "\tsize mismatch for products.0.symmetric_contractions.contractions.1.weights.0: copying a param with shape torch.Size([86, 6, 128]) from checkpoint, the shape in current model is torch.Size([1, 6, 128]).\n",
      "\tsize mismatch for products.0.symmetric_contractions.contractions.1.weights.1: copying a param with shape torch.Size([86, 1, 128]) from checkpoint, the shape in current model is torch.Size([1, 1, 128]).\n",
      "\tsize mismatch for products.0.symmetric_contractions.contractions.2.weights_max: copying a param with shape torch.Size([86, 65, 128]) from checkpoint, the shape in current model is torch.Size([1, 65, 128]).\n",
      "\tsize mismatch for products.0.symmetric_contractions.contractions.2.weights.0: copying a param with shape torch.Size([86, 7, 128]) from checkpoint, the shape in current model is torch.Size([1, 7, 128]).\n",
      "\tsize mismatch for products.0.symmetric_contractions.contractions.2.weights.1: copying a param with shape torch.Size([86, 1, 128]) from checkpoint, the shape in current model is torch.Size([1, 1, 128]).\n",
      "\tsize mismatch for products.1.symmetric_contractions.contractions.0.weights_max: copying a param with shape torch.Size([86, 23, 128]) from checkpoint, the shape in current model is torch.Size([1, 23, 128]).\n",
      "\tsize mismatch for products.1.symmetric_contractions.contractions.0.weights.0: copying a param with shape torch.Size([86, 4, 128]) from checkpoint, the shape in current model is torch.Size([1, 4, 128]).\n",
      "\tsize mismatch for products.1.symmetric_contractions.contractions.0.weights.1: copying a param with shape torch.Size([86, 1, 128]) from checkpoint, the shape in current model is torch.Size([1, 1, 128]).\n",
      "\tsize mismatch for readouts.0.linear.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for readouts.0.linear.output_mask: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "\tsize mismatch for readouts.1.linear_1.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for readouts.1.linear_1.output_mask: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for readouts.1.linear_2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for readouts.1.linear_2.output_mask: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "\tsize mismatch for scale_shift.scale: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "\tsize mismatch for scale_shift.shift: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\u001b[0m\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['mace_run_train', '--name', 'mace_T2_including_replay_w2', '--model', 'MACE', '--num_interactions', '2', '--foundation_model', '/home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model', '--foundation_model_readout', '--train_file', '/home/phanim/harshitrawat/summer/iteration_3-Copy1/one.xyz', '--valid_fraction', '0.5', '--batch_size', '1', '--valid_batch_size', '1', '--device', 'cpu', '--forces_weight', '0', '--energy_weight', '0', '--stress_weight', '0', '--lr', '0.006', '--scheduler_patience', '4', '--clip_grad', '1', '--weight_decay', '1e-8', '--r_max', '5.0', '--max_num_epochs', '1', '--E0s', '{3: -1.2302615750354944}', '--seed', '84', '--patience', '8', '--restart_latest']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 56\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmace_run_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# === General settings ===\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--restart_latest\u001b[39m\u001b[38;5;124m\"\u001b[39m,                   \u001b[38;5;66;03m# Resumes from checkpoint if available\u001b[39;00m\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd), file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m---> 56\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    527\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['mace_run_train', '--name', 'mace_T2_including_replay_w2', '--model', 'MACE', '--num_interactions', '2', '--foundation_model', '/home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model', '--foundation_model_readout', '--train_file', '/home/phanim/harshitrawat/summer/iteration_3-Copy1/one.xyz', '--valid_fraction', '0.5', '--batch_size', '1', '--valid_batch_size', '1', '--device', 'cpu', '--forces_weight', '0', '--energy_weight', '0', '--stress_weight', '0', '--lr', '0.006', '--scheduler_patience', '4', '--clip_grad', '1', '--weight_decay', '1e-8', '--r_max', '5.0', '--max_num_epochs', '1', '--E0s', '{3: -1.2302615750354944}', '--seed', '84', '--patience', '8', '--restart_latest']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# Now universal MACE finetuning on T2\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        # === General settings ===\n",
    "        \"--name\",              \"mace_T2_including_replay_w2\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "    # --- MP replay (pretraining head) ---\n",
    "        \"--pt_train_file\",\"/home/phanim/harshitrawat/summer/replay_data/mp_finetuning-mace_T2_mp_replay_run-42.xyz\",              # <- MP replay shortcut\n",
    "        \"--atomic_numbers\",\"[3,8,40,57]\",    # Li, O, Zr, La\n",
    "        \"--multiheads_finetuning\",\"True\",\n",
    "\n",
    "        \"--train_file\",\"/home/phanim/harshitrawat/summer/iteration_3-Copy1/one.xyz\",\n",
    "        \"--valid_fraction\", \"0.5\",\n",
    "        \"--batch_size\",        \"1\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "\n",
    "        \"--device\",            \"cpu\",\n",
    "\n",
    "        # === Loss function weights ===\n",
    "        \"--forces_weight\",     \"0\",         # Increased force weight to balance energy better\n",
    "        \"--energy_weight\",     \"0\",   \n",
    "        \"--stress_weight\", \"0\",             # Reduced from 100 → avoid dominance + stabilize energy RMSE\n",
    "\n",
    "        # === Learning setup ===\n",
    "        \"--lr\",                \"0.006\",      # Explicit learning rate (0.0001 is too low → stagnation)\n",
    "        \"--scheduler_patience\",\"4\",          # Reduce LR if val loss doesn’t improve in 3 epochs\n",
    "        \"--clip_grad\",         \"1\",        # Avoid exploding gradients — essential when energy_weight is high\n",
    "        \"--weight_decay\",      \"1e-8\",       # Mild regularization to prevent overfitting\n",
    "\n",
    "        # === EMA helps smooth loss curve ===\n",
    "        #\"--ema_decay\",         \"0.999\",     # Smooths validation loss and helps final convergence\n",
    "\n",
    "        # === Domain + training settings ===\n",
    "        \"--r_max\",             \"5.0\",\n",
    "        \"--max_num_epochs\",    \"1\",\n",
    "        \"--E0s\",               \"average\",    # Still allowed — could optionally be replaced by manual E0s\n",
    "        \"--seed\",              \"84\",\n",
    "        \"--patience\",     \"8\",\n",
    "\n",
    "        \"--restart_latest\",                   # Resumes from checkpoint if available\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda62619-66cf-4057-a0bd-f54f8d36312d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Keys renamed to REF_* and saved to:\n",
      "/home/phanim/harshitrawat/summer/replay_data/mp_finetuning-mace_T2_mp_replay_run-42_REFkeys.xyz\n"
     ]
    }
   ],
   "source": [
    "# Now universal MACE finetuning on T2\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        # === General settings ===\n",
    "        \"--name\",              \"template_mace_T2_including_replay_w2\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "    # --- MP replay (pretraining head) ---\n",
    "        # \"--pt_train_file\",\"/home/phanim/harshitrawat/summer/replay_data/mp_finetuning-mace_T2_mp_replay_run-42.xyz\",              # <- MP replay shortcut\n",
    "        # \"--atomic_numbers\",\"[3,8,40,57]\",    # Li, O, Zr, La\n",
    "        # \"--multiheads_finetuning\",\"True\",\n",
    "\n",
    "        \"--train_file\",\"/home/phanim/harshitrawat/summer/iteration_3-Copy1/one.xyz\",\n",
    "        \"--valid_fraction\", \"0.5\",\n",
    "        \"--batch_size\",        \"1\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "\n",
    "        \"--device\",            \"cpu\",\n",
    "\n",
    "        # === Loss function weights ===\n",
    "        \"--forces_weight\",     \"0\",         # Increased force weight to balance energy better\n",
    "        \"--energy_weight\",     \"10\",   \n",
    "        \"--stress_weight\", \"0\",             # Reduced from 100 → avoid dominance + stabilize energy RMSE\n",
    "\n",
    "        # === Learning setup ===\n",
    "        \"--lr\",                \"0.006\",      # Explicit learning rate (0.0001 is too low → stagnation)\n",
    "        \"--scheduler_patience\",\"4\",          # Reduce LR if val loss doesn’t improve in 3 epochs\n",
    "        \"--clip_grad\",         \"1\",        # Avoid exploding gradients — essential when energy_weight is high\n",
    "        \"--weight_decay\",      \"1e-8\",       # Mild regularization to prevent overfitting\n",
    "\n",
    "        # === EMA helps smooth loss curve ===\n",
    "        #\"--ema_decay\",         \"0.999\",     # Smooths validation loss and helps final convergence\n",
    "\n",
    "        # === Domain + training settings ===\n",
    "        \"--r_max\",             \"5.0\",\n",
    "        \"--max_num_epochs\",    \"1\",\n",
    "        \"--E0s\",               \"average\",    # Still allowed — could optionally be replaced by manual E0s\n",
    "        \"--seed\",              \"84\",\n",
    "        \"--patience\",     \"8\",\n",
    "\n",
    "        \"--restart_latest\",                   # Resumes from checkpoint if available\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd803b6-71b5-4fab-974f-2ea3ba19f232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: mace_run_train \\\n",
      "    --name \\\n",
      "    dummy_mace_T2_including_replay_w2 \\\n",
      "    --model \\\n",
      "    MACE \\\n",
      "    --num_interactions \\\n",
      "    2 \\\n",
      "    --foundation_model \\\n",
      "    /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model \\\n",
      "    --foundation_model_readout \\\n",
      "    --pt_train_file \\\n",
      "    /home/phanim/harshitrawat/summer/replay_data/mp_finetuning-mace_T2_mp_replay_run-42.xyz \\\n",
      "    --atomic_numbers \\\n",
      "    [3,8,40,57] \\\n",
      "    --multiheads_finetuning \\\n",
      "    True \\\n",
      "    --train_file \\\n",
      "    /home/phanim/harshitrawat/summer/dummy.extxyz \\\n",
      "    --valid_file \\\n",
      "    /home/phanim/harshitrawat/summer/dummy.extxyz \\\n",
      "    --batch_size \\\n",
      "    2 \\\n",
      "    --valid_batch_size \\\n",
      "    1 \\\n",
      "    --device \\\n",
      "    cuda \\\n",
      "    --forces_weight \\\n",
      "    0 \\\n",
      "    --energy_weight \\\n",
      "    10 \\\n",
      "    --stress_weight \\\n",
      "    0 \\\n",
      "    --lr \\\n",
      "    0.006 \\\n",
      "    --scheduler_patience \\\n",
      "    4 \\\n",
      "    --clip_grad \\\n",
      "    1 \\\n",
      "    --weight_decay \\\n",
      "    1e-8 \\\n",
      "    --r_max \\\n",
      "    5.0 \\\n",
      "    --max_num_epochs \\\n",
      "    1 \\\n",
      "    --E0s \\\n",
      "    {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549} \\\n",
      "    --seed \\\n",
      "    84 \\\n",
      "    --patience \\\n",
      "    8 \\\n",
      "    --restart_latest\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-22 03:17:46.609 INFO: ===========VERIFYING SETTINGS===========\n",
      "2025-08-22 03:17:46.609 INFO: MACE version: 0.3.14\n",
      "2025-08-22 03:17:46.655 INFO: CUDA version: 12.6, CUDA device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/cli/run_train.py:152: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  model_foundation = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-22 03:17:47.240 INFO: Using foundation model /home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model as initial checkpoint.\n",
      "2025-08-22 03:17:47.241 INFO: Multihead finetuning mode, setting learning rate to 0.0001 and EMA to True. To use a different learning rate, set --force_mh_ft_lr=True.\n",
      "2025-08-22 03:17:47.241 INFO: Using multiheads finetuning mode, setting learning rate to 0.0001 and EMA to True\n",
      "2025-08-22 03:17:47.241 INFO: ===========LOADING INPUT DATA===========\n",
      "2025-08-22 03:17:47.241 INFO: Using heads: ['Default', 'pt_head']\n",
      "2025-08-22 03:17:47.241 INFO: Using the key specifications to parse data:\n",
      "2025-08-22 03:17:47.241 INFO: Default: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head', 'elec_temp': 'elec_temp', 'total_charge': 'total_charge', 'polarizability': 'polarizability', 'total_spin': 'total_spin'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-08-22 03:17:47.241 INFO: pt_head: KeySpecification(info_keys={'energy': 'REF_energy', 'stress': 'REF_stress', 'virials': 'REF_virials', 'dipole': 'dipole', 'head': 'head', 'elec_temp': 'elec_temp', 'total_charge': 'total_charge', 'polarizability': 'polarizability', 'total_spin': 'total_spin'}, arrays_keys={'forces': 'REF_forces', 'charges': 'REF_charges'})\n",
      "2025-08-22 03:17:47.241 INFO: =============    Processing head Default     ===========\n",
      "2025-08-22 03:17:47.251 WARNING: No forces found with key 'REF_forces' in '/home/phanim/harshitrawat/summer/dummy.extxyz'. If this is unexpected, Please change the key name in the command line arguments or ensure that the file contains the required data.\n",
      "2025-08-22 03:17:47.252 INFO: Training set 1/1 [energy: 2, stress: 0, virials: 0, dipole components: 0, head: 2, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 0, charges: 0]\n",
      "2025-08-22 03:17:47.252 INFO: Total Training set [energy: 2, stress: 0, virials: 0, dipole components: 0, head: 2, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 0, charges: 0]\n",
      "2025-08-22 03:17:47.253 WARNING: No forces found with key 'REF_forces' in '/home/phanim/harshitrawat/summer/dummy.extxyz'. If this is unexpected, Please change the key name in the command line arguments or ensure that the file contains the required data.\n",
      "2025-08-22 03:17:47.253 INFO: Validation set 1/1 [energy: 2, stress: 0, virials: 0, dipole components: 0, head: 2, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 0, charges: 0]\n",
      "2025-08-22 03:17:47.253 INFO: Total Validation set [energy: 2, stress: 0, virials: 0, dipole components: 0, head: 2, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 0, charges: 0]\n",
      "2025-08-22 03:17:47.253 INFO: Total number of configurations: train=2, valid=2, tests=[],\n",
      "2025-08-22 03:17:47.253 INFO: =============    Processing head pt_head     ===========\n",
      "2025-08-22 03:17:50.089 INFO: Training set 1/1 [energy: 10000, stress: 10000, virials: 0, dipole components: 0, head: 10000, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 10000, charges: 0]\n",
      "2025-08-22 03:17:50.115 INFO: Total Training set [energy: 10000, stress: 10000, virials: 0, dipole components: 0, head: 10000, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 10000, charges: 0]\n",
      "2025-08-22 03:17:50.115 INFO: No validation set provided, splitting training data instead.\n",
      "2025-08-22 03:17:50.117 INFO: Using random 10% of training set for validation with indices saved in: ./valid_indices_84.txt\n",
      "2025-08-22 03:17:50.143 INFO: Random Split Training set [energy: 9000, stress: 9000, virials: 0, dipole components: 0, head: 9000, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 9000, charges: 0]\n",
      "2025-08-22 03:17:50.145 INFO: Random Split Validation set [energy: 1000, stress: 1000, virials: 0, dipole components: 0, head: 1000, elec_temp: 0, total_charge: 0, polarizability: 0, total_spin: 0, forces: 1000, charges: 0]\n",
      "2025-08-22 03:17:50.145 INFO: Total number of configurations: train=9000, valid=1000, tests=[],\n",
      "2025-08-22 03:17:50.146 INFO: ==================Using multiheads finetuning mode==================\n",
      "2025-08-22 03:17:50.146 WARNING: Ratio of the number of configurations in the training set and the in the pt_train_file is 0.00022222222222222223, increasing the number of configurations in the fine-tuning heads by 450\n",
      "2025-08-22 03:17:50.146 INFO: Total number of configurations in pretraining: train=9000, valid=1000\n",
      "2025-08-22 03:17:50.146 INFO: Using atomic numbers from command line argument\n",
      "2025-08-22 03:17:50.167 INFO: Atomic Numbers used: [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 91, 92, 93, 94]\n",
      "2025-08-22 03:17:50.167 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument\n",
      "2025-08-22 03:17:50.171 INFO: Atomic Energies used (z: eV) for head Default: {3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\n",
      "2025-08-22 03:17:50.171 INFO: Atomic Energies used (z: eV) for head pt_head: {1: -3.667168021358939, 3: -3.482100566595956, 4: -4.736697230897597, 5: -7.724935420523256, 6: -8.405573550273285, 7: -7.360100452662763, 8: -7.28459863421322, 9: -4.896490881731322, 11: -2.7593613569762425, 12: -2.814047612069227, 13: -4.846881245288104, 14: -7.694793133351899, 15: -6.9632957911820235, 16: -4.672630400190884, 17: -2.8116892814008096, 19: -2.6176454856894793, 20: -5.390461060484104, 21: -7.8857952163517675, 22: -10.268392986214433, 23: -8.665147785496703, 24: -9.233050763772013, 25: -8.304951520770791, 26: -7.0489865771593765, 27: -5.577439766222147, 28: -5.172747618813715, 29: -3.2520726958619472, 30: -1.2901611618726314, 31: -3.527082192997912, 32: -4.70845955030298, 33: -3.9765109025623238, 34: -3.886231055836541, 35: -2.5184940099633986, 36: 6.766947645687137, 37: -2.5634958965928316, 38: -4.938005211501922, 39: -10.149818838085771, 40: -11.846857579882572, 41: -12.138896361658485, 42: -8.791678800595722, 43: -8.78694939675911, 44: -7.78093221529871, 45: -6.850021409115055, 46: -4.891019073240479, 47: -2.0634296773864045, 48: -0.6395695518943755, 49: -2.7887442084286693, 50: -3.818604275441892, 51: -3.587068329278862, 52: -2.8804045971118897, 53: -1.6355986842433357, 54: 9.846723842807721, 55: -2.765284507132287, 56: -4.990956432167774, 57: -8.933684809576345, 58: -8.735591176647514, 59: -8.018966025544966, 60: -8.251491970213372, 61: -7.591719594359237, 62: -8.169659881166858, 63: -13.592664636171698, 64: -18.517523458456985, 65: -7.647396572993602, 66: -8.122981037851925, 67: -7.607787319678067, 68: -6.85029094445494, 69: -7.8268821327130365, 70: -3.584786591677161, 71: -7.455406192077973, 72: -12.796283502572146, 73: -14.108127281277586, 74: -9.354916969477486, 75: -11.387537567890853, 76: -9.621909492152557, 77: -7.324393429417677, 78: -5.3046964808341945, 79: -2.380092582080244, 80: 0.24948924158195362, 81: -2.3239789120665026, 82: -3.730042357127322, 83: -3.438792347649683, 89: -5.062878214511315, 90: -11.02462566385297, 91: -12.265613551943261, 92: -13.855648206100362, 93: -14.933092020258243, 94: -15.282826131998245}\n",
      "2025-08-22 03:17:50.171 INFO: Processing datasets for head 'Default'\n",
      "2025-08-22 03:17:50.307 INFO: Combining 1 list datasets for head 'Default'\n",
      "2025-08-22 03:17:50.307 INFO: Combining 1 list datasets for head 'Default_valid'\n",
      "2025-08-22 03:17:50.307 INFO: Combined validation datasets for Default\n",
      "2025-08-22 03:17:50.307 INFO: Head 'Default' training dataset size: 902\n",
      "2025-08-22 03:17:50.308 INFO: Processing datasets for head 'pt_head'\n",
      "2025-08-22 03:17:58.117 INFO: Combining 1 list datasets for head 'pt_head'\n",
      "2025-08-22 03:17:58.965 INFO: Head 'pt_head' training dataset size: 9000\n",
      "2025-08-22 03:17:58.966 INFO: Average number of neighbors: 61.964672446250916\n",
      "2025-08-22 03:17:58.966 INFO: During training the following quantities will be reported: energy, forces, stress\n",
      "2025-08-22 03:17:58.966 INFO: ===========MODEL DETAILS===========\n",
      "2025-08-22 03:18:03.704 WARNING: Standard deviation of the scaling is zero, Changing to no scaling\n",
      "2025-08-22 03:18:03.712 INFO: Loading FOUNDATION model\n",
      "2025-08-22 03:18:03.713 INFO: Using filtered elements: [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 91, 92, 93, 94]\n",
      "2025-08-22 03:18:03.713 INFO: Model configuration extracted from foundation model\n",
      "2025-08-22 03:18:03.713 INFO: Using universal loss function for fine-tuning\n",
      "2025-08-22 03:18:03.714 INFO: Message passing with hidden irreps 128x0e+128x1o+128x2e)\n",
      "2025-08-22 03:18:03.714 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
      "2025-08-22 03:18:03.714 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)\n",
      "2025-08-22 03:18:03.714 INFO: Distance transform for radial basis functions: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-22 03:18:13.041 INFO: Total number of parameters: 5556810\n",
      "2025-08-22 03:18:13.042 INFO: \n",
      "2025-08-22 03:18:13.042 INFO: ===========OPTIMIZER INFORMATION===========\n",
      "2025-08-22 03:18:13.042 INFO: Using ADAM as parameter optimizer\n",
      "2025-08-22 03:18:13.042 INFO: Batch size: 2\n",
      "2025-08-22 03:18:13.042 INFO: Using Exponential Moving Average with decay: 0.99999\n",
      "2025-08-22 03:18:13.042 INFO: Number of gradient updates: 4951\n",
      "2025-08-22 03:18:13.042 INFO: Learning rate: 0.0001, weight decay: 1e-08\n",
      "2025-08-22 03:18:13.042 INFO: UniversalLoss(energy_weight=10.000, forces_weight=0.000, stress_weight=0.000)\n",
      "2025-08-22 03:18:13.046 WARNING: Cannot find checkpoint with tag 'dummy_mace_T2_including_replay_w2_run-84' in './checkpoints'\n",
      "2025-08-22 03:18:13.047 INFO: Using gradient clipping with tolerance=1.000\n",
      "2025-08-22 03:18:13.047 INFO: \n",
      "2025-08-22 03:18:13.047 INFO: ===========TRAINING===========\n",
      "2025-08-22 03:18:13.047 INFO: Started training, reporting errors on validation set\n",
      "2025-08-22 03:18:13.047 INFO: Loss metrics on validation set\n",
      "2025-08-22 03:20:46.748 INFO: Initial: head: pt_head, loss=0.03504716, RMSE_E_per_atom=  468.57 meV, RMSE_F=   99.92 meV / A, RMSE_stress=    6.45 meV / A^3\n",
      "2025-08-22 03:20:46.979 INFO: Initial: head: Default, loss=0.99056127, RMSE_E_per_atom= 9910.61 meV, RMSE_F=None meV / A, RMSE_stress=None meV / A^3\n",
      "2025-08-22 03:39:39.815 INFO: Epoch 0: head: pt_head, loss=0.00287404, RMSE_E_per_atom=   60.53 meV, RMSE_F=  277.05 meV / A, RMSE_stress=   15.03 meV / A^3\n",
      "2025-08-22 03:39:40.013 INFO: Epoch 0: head: Default, loss=0.00011023, RMSE_E_per_atom=    4.70 meV, RMSE_F=None meV / A, RMSE_stress=None meV / A^3\n",
      "2025-08-22 03:39:40.328 INFO: Training complete\n",
      "2025-08-22 03:39:40.328 INFO: \n",
      "2025-08-22 03:39:40.329 INFO: ===========RESULTS===========\n",
      "2025-08-22 03:39:40.331 INFO: Loading checkpoint: ./checkpoints/dummy_mace_T2_including_replay_w2_run-84_epoch-0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages/mace/tools/checkpoint.py:187: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=checkpoint_info.path, map_location=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-22 03:39:40.823 INFO: Loaded Stage one model from epoch 0 for evaluation\n",
      "2025-08-22 03:39:40.823 INFO: Saving model to checkpoints/dummy_mace_T2_including_replay_w2_run-84.model\n",
      "2025-08-22 03:39:41.158 INFO: Compiling model, saving metadata to dummy_mace_T2_including_replay_w2_compiled.model\n",
      "2025-08-22 03:39:41.776 INFO: Computing metrics for training, validation, and test sets\n",
      "2025-08-22 03:39:41.777 INFO: Skipping evaluation for heads: ['pt_head']\n",
      "2025-08-22 03:39:41.777 INFO: Evaluating train_Default ...\n",
      "2025-08-22 03:40:31.165 INFO: Skipping evaluation of train_pt_head (in skip_heads list)\n",
      "2025-08-22 03:40:31.165 INFO: Evaluating valid_Default ...\n",
      "2025-08-22 03:40:31.366 INFO: Skipping evaluation of valid_pt_head (in skip_heads list)\n",
      "2025-08-22 03:40:31.374 INFO: Error-table on TRAIN and VALID:\n",
      "+---------------+---------------------+------------------+-------------------+---------------------------------------+\n",
      "|  config_type  | RMSE E / meV / atom | RMSE F / meV / A | relative F RMSE % | RMSE Stress (Virials) / meV / A (A^3) |\n",
      "+---------------+---------------------+------------------+-------------------+---------------------------------------+\n",
      "| train_Default |            4.7      |       None       |        None       |                  None                 |\n",
      "| valid_Default |            4.7      |       None       |        None       |                  None                 |\n",
      "+---------------+---------------------+------------------+-------------------+---------------------------------------+\n",
      "2025-08-22 03:40:31.452 INFO: Done\n"
     ]
    }
   ],
   "source": [
    "# Now universal MACE finetuning on T2\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # ——— Environment setup ———\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "    cmd = [\n",
    "        \"mace_run_train\",\n",
    "        # === General settings ===\n",
    "        \"--name\",              \"dummy_mace_T2_including_replay_w2\",\n",
    "        \"--model\",             \"MACE\",\n",
    "        \"--num_interactions\",  \"2\",\n",
    "        \"--foundation_model\",  \"/home/phanim/harshitrawat/summer/mace_models/universal/2024-01-07-mace-128-L2_epoch-199.model\",\n",
    "        \"--foundation_model_readout\",\n",
    "    # --- MP replay (pretraining head) ---\n",
    "        \"--pt_train_file\",\"/home/phanim/harshitrawat/summer/replay_data/mp_finetuning-mace_T2_mp_replay_run-42.xyz\",              # <- MP replay shortcut\n",
    "        \"--atomic_numbers\",\"[3,8,40,57]\",    # Li, O, Zr, La\n",
    "        \"--multiheads_finetuning\",\"True\",\n",
    "\n",
    "        \"--train_file\", \"/home/phanim/harshitrawat/summer/dummy.extxyz\",\n",
    "        \"--valid_file\", \"/home/phanim/harshitrawat/summer/dummy.extxyz\",\n",
    "\n",
    "        \"--batch_size\",        \"2\",\n",
    "        \"--valid_batch_size\",  \"1\",\n",
    "\n",
    "        \"--device\",            \"cuda\",\n",
    "\n",
    "        # === Loss function weights ===\n",
    "        \"--forces_weight\",     \"0\",         # Increased force weight to balance energy better\n",
    "        \"--energy_weight\",     \"10\",   \n",
    "        \"--stress_weight\", \"0\",             # Reduced from 100 → avoid dominance + stabilize energy RMSE\n",
    "\n",
    "        # === Learning setup ===\n",
    "        \"--lr\",                \"0.006\",      # Explicit learning rate (0.0001 is too low → stagnation)\n",
    "        \"--scheduler_patience\",\"4\",          # Reduce LR if val loss doesn’t improve in 3 epochs\n",
    "        \"--clip_grad\",         \"1\",        # Avoid exploding gradients — essential when energy_weight is high\n",
    "        \"--weight_decay\",      \"1e-8\",       # Mild regularization to prevent overfitting\n",
    "\n",
    "        # === EMA helps smooth loss curve ===\n",
    "        #\"--ema_decay\",         \"0.999\",     # Smooths validation loss and helps final convergence\n",
    "\n",
    "        # === Domain + training settings ===\n",
    "        \"--r_max\",             \"5.0\",\n",
    "        \"--max_num_epochs\",    \"1\",\n",
    "        \"--E0s\",               \"{3: -1.2302615750354944, 8: -23.049110738413006, 40: 23.367646191010394, 57: 15.192898072498549}\",    # Still allowed — could optionally be replaced by manual E0s\n",
    "        \"--seed\",              \"84\",\n",
    "        \"--patience\",     \"8\",\n",
    "\n",
    "        \"--restart_latest\",                   # Resumes from checkpoint if available\n",
    "    ]\n",
    "\n",
    "    print(\"Running:\", \" \\\\\\n    \".join(cmd), file=sys.stderr)\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eaa615d-2325-4419-80a0-3d680335b9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing keys: []\n",
      "unexpected keys: []\n",
      "✅ Wrote: /home/phanim/harshitrawat/summer/formation_energy/mace_T2_frozen_220825.model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = \"/home/phanim/harshitrawat/summer/iteration_3/checkpoints/mace_T2_including_replay_w2_run-84_epoch-77.pt\"\n",
    "template_model_path = \"/home/phanim/harshitrawat/summer/iteration_3-Copy1/checkpoints/dummy_mace_T2_including_replay_w2_run-84.model\"\n",
    "out_model_path = \"/home/phanim/harshitrawat/summer/formation_energy/mace_T2_frozen_220825.model\"\n",
    "\n",
    "# Load both with full objects (not weights_only)\n",
    "ckpt  = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "model = torch.load(template_model_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "# Inject weights from checkpoint\n",
    "missing, unexpected = model.load_state_dict(ckpt[\"model\"], strict=False)\n",
    "print(\"missing keys:\", missing)\n",
    "print(\"unexpected keys:\", unexpected)\n",
    "\n",
    "# Save the usable .model\n",
    "torch.save(model, out_model_path)\n",
    "print(\"✅ Wrote:\", out_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a6c825-de67-4ba0-ae3d-c2de2887d744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/mace/mace/calculators/mace.py:166: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using head Default out of ['pt_head', 'Default']\n",
      "No dtype selected, switching to float64 to match model dtype.\n",
      "Li: μ_model = -1.738880 eV/atom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/pymatgen/core/structure.py:3107: UserWarning: Issues encountered while parsing CIF: 4 fractional coordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  struct = parser.parse_structures(primitive=primitive)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La: μ_model = 18.890417 eV/atom\n",
      "Zr: μ_model = 26.440122 eV/atom\n",
      "O: μ_model = -20.875662 eV/atom\n"
     ]
    }
   ],
   "source": [
    "from mace.calculators import MACECalculator\n",
    "mace_calc = MACECalculator(model_paths=[\"/home/phanim/harshitrawat/summer/formation_energy/mace_T2_frozen_220825.model\"], device=\"cuda\")  # or \"cpu\"\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.core import Structure\n",
    "adaptor = AseAtomsAdaptor()\n",
    "\n",
    "pmg_structure = Structure.from_file(\"/home/phanim/harshitrawat/summer/formation_energy/cifs/Li.cif\")  # e.g. for Li\n",
    "ase_atoms = adaptor.get_atoms(pmg_structure)\n",
    "ase_atoms.calc = mace_calc\n",
    "total_energy = ase_atoms.get_potential_energy()\n",
    "mu_model_Li = total_energy / len(ase_atoms)\n",
    "print(f\"Li: μ_model = {mu_model_Li:.6f} eV/atom\")\n",
    "# Let us do this for La, Zr, and O as well\n",
    "pmg_structure = Structure.from_file(\"/home/phanim/harshitrawat/summer/formation_energy/cifs/La.cif\")\n",
    "ase_atoms = adaptor.get_atoms(pmg_structure)\n",
    "ase_atoms.calc = mace_calc\n",
    "total_energy = ase_atoms.get_potential_energy()\n",
    "mu_model_La = total_energy / len(ase_atoms)\n",
    "print(f\"La: μ_model = {mu_model_La:.6f} eV/atom\")\n",
    "pmg_structure = Structure.from_file(\"/home/phanim/harshitrawat/summer/formation_energy/cifs/Zr.cif\")\n",
    "ase_atoms = adaptor.get_atoms(pmg_structure)\n",
    "ase_atoms.calc = mace_calc\n",
    "total_energy = ase_atoms.get_potential_energy()\n",
    "mu_model_Zr = total_energy / len(ase_atoms)\n",
    "print(f\"Zr: μ_model = {mu_model_Zr:.6f} eV/atom\")\n",
    "pmg_structure = Structure.from_file(\"/home/phanim/harshitrawat/summer/formation_energy/cifs/O2.cif\")  # Needs to be a periodic solid O2 structure\n",
    "ase_atoms = adaptor.get_atoms(pmg_structure)\n",
    "ase_atoms.calc = mace_calc\n",
    "total_energy = ase_atoms.get_potential_energy()\n",
    "mu_model_O = total_energy / len(ase_atoms)\n",
    "print(f\"O: μ_model = {mu_model_O:.6f} eV/atom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb73e79-1774-43ff-ab2d-b99db10fafb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/mace/mace/calculators/mace.py:166: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using head Default out of ['pt_head', 'Default']\n",
      "No dtype selected, switching to float64 to match model dtype.\n",
      "Li2O2          :  E_form (MACE_T2_w2_it3) = -0.311494 eV/atom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/pymatgen/core/structure.py:3107: UserWarning: Issues encountered while parsing CIF: 12 fractional coordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  struct = parser.parse_structures(primitive=primitive)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li2O           :  E_form (MACE_T2_w2_it3) = -0.354533 eV/atom\n",
      "Li7La3Zr2O12   :  E_form (MACE_T2_w2_it3) = -1.119615 eV/atom\n",
      "ZrO2           :  E_form (MACE_T2_w2_it3) = -3.445901 eV/atom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/pymatgen/core/structure.py:3107: UserWarning: Issues encountered while parsing CIF: 8 fractional coordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  struct = parser.parse_structures(primitive=primitive)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La2O3          :  E_form (MACE_T2_w2_it3) = -3.348167 eV/atom\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# ---- 1. Load the MACE model -------------------------------------------\n",
    "calculator = MACECalculator(model_paths=[\"/home/phanim/harshitrawat/summer/formation_energy/mace_T2_frozen_220825.model\"], device=\"cuda\")  # or \"cpu\"\n",
    "\n",
    "# ---- 2. Reference μ_model from MACE -----------------------------------\n",
    "\n",
    "mu_mace = {\n",
    "    \"Li\": -1.738880,\n",
    "    \"La\": 18.890417,\n",
    "    \"Zr\": 26.440122,\n",
    "    \"O\":  -20.875662,\n",
    "}\n",
    "\n",
    "# ---- 3. CIF files ------------------------------------------------------\n",
    "cif_dir = \"/home/phanim/harshitrawat/summer/formation_energy/cifs\"\n",
    "compounds = {\n",
    "    \"mp-841.cif\": \"Li2O2\",\n",
    "    \"mp-1960.cif\": \"Li2O\",\n",
    "    \"mp-942733.cif\": \"Li7La3Zr2O12\",\n",
    "    \"mp-2858.cif\": \"ZrO2\",\n",
    "    \"mp-1968.cif\": \"La2O3\",\n",
    "}\n",
    "\n",
    "# ---- 4. Predict formation energy per atom -----------------------------\n",
    "for fname, label in compounds.items():\n",
    "    struct = Structure.from_file(os.path.join(cif_dir, fname))\n",
    "    comp = struct.composition\n",
    "    n_atoms = comp.num_atoms\n",
    "\n",
    "    # Convert to ASE\n",
    "    ase_atoms = AseAtomsAdaptor.get_atoms(struct)\n",
    "\n",
    "    # Assign calculator and predict energy\n",
    "    ase_atoms.calc = calculator\n",
    "    energy_total = ase_atoms.get_potential_energy()  # eV (total)\n",
    "\n",
    "    # Reference energy from MACE chemical potentials\n",
    "    ref_total = sum(comp[el] * mu_mace[el.symbol] for el in comp.elements)\n",
    "\n",
    "    # Formation energy per atom\n",
    "    e_form = (energy_total - ref_total) / n_atoms\n",
    "\n",
    "    print(f\"{label:15s}:  E_form (MACE_T2_w2_it3) = {e_form: .6f} eV/atom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e647a58-c76d-4255-a2ca-4b4b88da0a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phanim/harshitrawat/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_2750347/3549858856.py:22: DeprecationWarning: Accessing summary data through MPRester.summary is deprecated. Please use MPRester.materials.summary instead.\n",
      "  docs = mpr.summary.search(\n"
     ]
    },
    {
     "ename": "MPRestError",
     "evalue": "invalid fields requested: ['energy']. Available fields: ['builder_meta', 'nsites', 'elements', 'nelements', 'composition', 'composition_reduced', 'formula_pretty', 'formula_anonymous', 'chemsys', 'volume', 'density', 'density_atomic', 'symmetry', 'property_name', 'material_id', 'deprecated', 'deprecation_reasons', 'last_updated', 'origins', 'warnings', 'structure', 'task_ids', 'uncorrected_energy_per_atom', 'energy_per_atom', 'formation_energy_per_atom', 'energy_above_hull', 'is_stable', 'equilibrium_reaction_energy_per_atom', 'decomposes_to', 'xas', 'grain_boundaries', 'band_gap', 'cbm', 'vbm', 'efermi', 'is_gap_direct', 'is_metal', 'es_source_calc_id', 'bandstructure', 'dos', 'dos_energy_up', 'dos_energy_down', 'is_magnetic', 'ordering', 'total_magnetization', 'total_magnetization_normalized_vol', 'total_magnetization_normalized_formula_units', 'num_magnetic_sites', 'num_unique_magnetic_sites', 'types_of_magnetic_species', 'bulk_modulus', 'shear_modulus', 'universal_anisotropy', 'homogeneous_poisson', 'e_total', 'e_ionic', 'e_electronic', 'n', 'e_ij_max', 'weighted_surface_energy_EV_PER_ANG2', 'weighted_surface_energy', 'weighted_work_function', 'surface_anisotropy', 'shape_factor', 'has_reconstructed', 'possible_species', 'has_props', 'theoretical', 'database_Ids']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMPRestError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m combo \u001b[38;5;129;01min\u001b[39;00m combinations(wanted_elements, r):\n\u001b[1;32m     21\u001b[0m     chemsys \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(combo)\n\u001b[0;32m---> 22\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[43mmpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchemsys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchemsys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaterial_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformula_pretty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstructure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menergy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchemsys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m entries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/mp_api/client/routes/materials/summary.py:367\u001b[0m, in \u001b[0;36mSummaryRester.search\u001b[0;34m(self, band_gap, chemsys, crystal_system, density, deprecated, e_electronic, e_ionic, e_total, efermi, elastic_anisotropy, elements, energy_above_hull, equilibrium_reaction_energy, exclude_elements, formation_energy, formula, g_reuss, g_voigt, g_vrh, has_props, has_reconstructed, is_gap_direct, is_metal, is_stable, k_reuss, k_voigt, k_vrh, magnetic_ordering, material_ids, n, num_elements, num_sites, num_magnetic_sites, num_unique_magnetic_sites, piezoelectric_modulus, poisson_ratio, possible_species, shape_factor, spacegroup_number, spacegroup_symbol, surface_energy_anisotropy, theoretical, total_energy, total_magnetization, total_magnetization_normalized_formula_units, total_magnetization_normalized_vol, uncorrected_energy, volume, weighted_surface_energy, weighted_work_function, include_gnome, num_chunks, chunk_size, all_fields, fields, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m     query_params\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_id_not_eq\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgnome_r2scan_statics\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m    361\u001b[0m query_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    362\u001b[0m     entry: query_params[entry]\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m query_params\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_params[entry] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    365\u001b[0m }\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/mp_api/client/core/client.py:1191\u001b[0m, in \u001b[0;36mBaseRester._search\u001b[0;34m(self, num_chunks, chunk_size, all_fields, fields, **kwargs)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A generic search method to retrieve documents matching specific parameters.\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;124;03m    A list of documents.\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# This method should be customized for each end point to give more user friendly,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# documented kwargs.\u001b[39;00m\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_all_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/mp_api/client/core/client.py:1264\u001b[0m, in \u001b[0;36mBaseRester._get_all_documents\u001b[0;34m(self, query_params, all_fields, fields, chunk_size, num_chunks)\u001b[0m\n\u001b[1;32m   1250\u001b[0m list_entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m   1251\u001b[0m     (\n\u001b[1;32m   1252\u001b[0m         (key, \u001b[38;5;28mlen\u001b[39m(entry\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1260\u001b[0m )\n\u001b[1;32m   1262\u001b[0m chosen_param \u001b[38;5;241m=\u001b[39m list_entries[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(list_entries) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_resource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchosen_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/mace_0.3.8/lib/python3.10/site-packages/mp_api/client/core/client.py:464\u001b[0m, in \u001b[0;36mBaseRester._query_resource\u001b[0;34m(self, criteria, fields, suburl, use_document_model, parallel_param, num_chunks, chunk_size, timeout)\u001b[0m\n\u001b[1;32m    460\u001b[0m         invalid_fields \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    461\u001b[0m             f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavailable_fields\n\u001b[1;32m    462\u001b[0m         ]\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m invalid_fields:\n\u001b[0;32m--> 464\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m MPRestError(\n\u001b[1;32m    465\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid fields requested: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minvalid_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Available fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavailable_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m             )\n\u001b[1;32m    468\u001b[0m     criteria[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(fields)\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mMPRestError\u001b[0m: invalid fields requested: ['energy']. Available fields: ['builder_meta', 'nsites', 'elements', 'nelements', 'composition', 'composition_reduced', 'formula_pretty', 'formula_anonymous', 'chemsys', 'volume', 'density', 'density_atomic', 'symmetry', 'property_name', 'material_id', 'deprecated', 'deprecation_reasons', 'last_updated', 'origins', 'warnings', 'structure', 'task_ids', 'uncorrected_energy_per_atom', 'energy_per_atom', 'formation_energy_per_atom', 'energy_above_hull', 'is_stable', 'equilibrium_reaction_energy_per_atom', 'decomposes_to', 'xas', 'grain_boundaries', 'band_gap', 'cbm', 'vbm', 'efermi', 'is_gap_direct', 'is_metal', 'es_source_calc_id', 'bandstructure', 'dos', 'dos_energy_up', 'dos_energy_down', 'is_magnetic', 'ordering', 'total_magnetization', 'total_magnetization_normalized_vol', 'total_magnetization_normalized_formula_units', 'num_magnetic_sites', 'num_unique_magnetic_sites', 'types_of_magnetic_species', 'bulk_modulus', 'shear_modulus', 'universal_anisotropy', 'homogeneous_poisson', 'e_total', 'e_ionic', 'e_electronic', 'n', 'e_ij_max', 'weighted_surface_energy_EV_PER_ANG2', 'weighted_surface_energy', 'weighted_work_function', 'surface_anisotropy', 'shape_factor', 'has_reconstructed', 'possible_species', 'has_props', 'theoretical', 'database_Ids']"
     ]
    }
   ],
   "source": [
    "from mp_api.client import MPRester\n",
    "from pymatgen.core import Structure\n",
    "from ase.io import write\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "import os\n",
    "\n",
    "API_KEY = \"j3J85pX4nLw6asHG9E2lbbCHEKDKgrjc\"   # <-- put your Materials Project API key here\n",
    "adaptor = AseAtomsAdaptor()\n",
    "\n",
    "# Output directory\n",
    "os.makedirs(\"mp_li_la_zr_o_cifs\", exist_ok=True)\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "wanted_elements = [\"Li\", \"La\", \"Zr\", \"O\"]\n",
    "all_structures = []\n",
    "\n",
    "with MPRester(API_KEY) as mpr:\n",
    "    for r in [2, 3, 4]:  # binaries, ternaries, quaternaries\n",
    "        for combo in combinations(wanted_elements, r):\n",
    "            chemsys = \"-\".join(combo)\n",
    "            docs = mpr.summary.search(\n",
    "                chemsys=chemsys,\n",
    "                fields=[\"material_id\", \"formula_pretty\", \"structure\", \"energy\"]\n",
    "            )\n",
    "            print(f\"{chemsys}: {len(docs)} entries\")\n",
    "\n",
    "            for doc in docs:\n",
    "                struct = doc.structure\n",
    "                ase_atoms = adaptor.get_atoms(struct)\n",
    "                ase_atoms.info[\"energy\"] = doc.energy\n",
    "                all_structures.append(ase_atoms)\n",
    "\n",
    "                # Save CIF\n",
    "                cif_name = f\"mp_li_la_zr_o_cifs/{doc.material_id}_{doc.formula_pretty}.cif\"\n",
    "                struct.to(fmt=\"cif\", filename=cif_name)\n",
    "\n",
    "# Write replay dataset\n",
    "write(\"replay_li_la_zr_o.xyz\", all_structures)\n",
    "print(f\"Saved {len(all_structures)} structures into replay_li_la_zr_o.xyz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991c88bf-938d-4a38-868e-3cf3c6bb669d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2750347/4090857286.py:19: DeprecationWarning: Accessing summary data through MPRester.summary is deprecated. Please use MPRester.materials.summary instead.\n",
      "  docs = mpr.summary.search(\n",
      "Retrieving SummaryDoc documents: 100%|████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 61082.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li-La: 3 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5526.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li-Zr: 1 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|█████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 202241.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li-O: 23 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 19152.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La-Zr: 2 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|█████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 113359.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La-O: 12 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|█████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 200963.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zr-O: 31 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li-La-Zr: 0 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 66126.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li-La-O: 7 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|█████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 145572.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li-Zr-O: 16 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 61230.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La-Zr-O: 6 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 14768.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li-La-Zr-O: 3 entries\n",
      "Saved 104 structures into replay_li_la_zr_o.xyz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mp_api.client import MPRester\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from ase.io import write\n",
    "from itertools import combinations\n",
    "import os\n",
    "\n",
    "API_KEY = \"j3J85pX4nLw6asHG9E2lbbCHEKDKgrjc\"\n",
    "adaptor = AseAtomsAdaptor()\n",
    "\n",
    "os.makedirs(\"mp_li_la_zr_o_cifs\", exist_ok=True)\n",
    "wanted_elements = [\"Li\", \"La\", \"Zr\", \"O\"]\n",
    "\n",
    "structures = []\n",
    "\n",
    "with MPRester(API_KEY) as mpr:\n",
    "    for r in [2, 3, 4]:  # binaries, ternaries, quaternaries\n",
    "        for combo in combinations(wanted_elements, r):\n",
    "            chemsys = \"-\".join(combo)\n",
    "            docs = mpr.summary.search(\n",
    "                chemsys=chemsys,\n",
    "                fields=[\"material_id\", \"formula_pretty\", \"structure\",\n",
    "                        \"nsites\", \"energy_per_atom\"]\n",
    "            )\n",
    "            print(f\"{chemsys}: {len(docs)} entries\")\n",
    "\n",
    "            for doc in docs:\n",
    "                struct = doc.structure\n",
    "                ase_atoms = adaptor.get_atoms(struct)\n",
    "\n",
    "                # Convert per-atom energy to total energy\n",
    "                total_energy = doc.energy_per_atom * doc.nsites\n",
    "                ase_atoms.info[\"energy\"] = total_energy\n",
    "\n",
    "                structures.append(ase_atoms)\n",
    "\n",
    "                # Save CIF\n",
    "                cif_name = f\"mp_li_la_zr_o_cifs/{doc.material_id}_{doc.formula_pretty}.cif\"\n",
    "                struct.to(fmt=\"cif\", filename=cif_name)\n",
    "\n",
    "# Save replay dataset\n",
    "write(\"replay_li_la_zr_o.xyz\", structures)\n",
    "print(f\"Saved {len(structures)} structures into replay_li_la_zr_o.xyz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef74717-4772-44b3-8df0-beec5f2a98bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mp-api\n",
      "Version: 0.45.8\n",
      "Summary: API Client for the Materials Project\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: The Materials Project <feedback@materialsproject.org>\n",
      "License: modified BSD\n",
      "Location: /home/phanim/harshitrawat/miniconda3/lib/python3.13/site-packages\n",
      "Requires: emmet-core, maggma, monty, msgpack, pymatgen, requests, setuptools, smart_open, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show mp-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b1c9c0-57d4-4252-8579-3e99101dafde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU mace_0.3.8)",
   "language": "python",
   "name": "mace_0.3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
